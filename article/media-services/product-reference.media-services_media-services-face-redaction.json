{"Title":"使用 Azure 媒体分析进行面部修订","Description":"本主题演示如何使用 Azure 媒体分析检测面部。","Content":"# <a name=\"redact-faces-with-azure-media-analytics\"></a>使用 Azure 媒体分析进行面部修订\r\n\r\n## <a name=\"overview\"></a>概述\r\n\r\n**Azure 媒体修订器**是一种 [Azure 媒体分析](media-services-analytics-overview.md)媒体处理器 (MP)，可用于在云中进行可缩放的面部修订。 使用面部修订，可对视频进行修改，使所选个人的面部模糊显示。 用户可能想要在公共安全和新闻媒体场景中使用面部修订服务。 对于时长仅几分钟但包含多张面孔的镜头，进行手动面部修订可能需要几个小时，但使用此服务仅需几个简单步骤即可完成该过程。 有关详细信息，请参阅[此](https://azure.microsoft.com/blog/azure-media-redactor/)博客。\r\n\r\n本主题提供有关 **Azure 媒体修订器**的详细信息，并演示如何通过适用于 .NET 的媒体服务 SDK 使用它。\r\n\r\n## <a name=\"face-redaction-modes\"></a>面部修订模式\r\n\r\n面部修订的工作方式是：检测每一帧视频中的面部，并跟踪之前和之后的面部对象，以便同一个人在其他角度也模糊显示。 自动修订过程非常复杂，并且无法始终产生 100% 符合要求的输出，因此，媒体分析提供了几种修改最终输出的方式。\r\n\r\n除了完全自动模式外，还可使用双步工作流通过 ID 列表选择/取消选找到的面部。 此外，为了对每一帧进行任意调整，MP 使用 JSON 格式的元数据文件。 此工作流拆分为“分析”和“修订”模式。 可将这两个模式组合为在一个作业中运行两项任务的单个过程；此模式称为“组合”。\r\n\r\n### <a name=\"combined-mode\"></a>组合模式\r\n\r\n这自动生成经过修订的 mp4，而无需任何手动输入。\r\n\r\n| 阶段 | 文件名 | 说明 |\r\n| --- | --- | --- |\r\n| 输入资产 |foo.bar |WMV、MOV 或 MP4 格式的视频 |\r\n| 输入配置 |作业配置预设 |{'version':'1.0', 'options': {'mode':'combined'}} |\r\n| 输出资产 |foo_redacted.mp4 |进行了模糊处理的视频 |\r\n\r\n#### <a name=\"input-example\"></a>输入示例：\r\n\r\n[观看此视频](http://ampdemo.azureedge.net/?url=http%3A%2F%2Freferencestream-samplestream.streaming.mediaservices.windows.net%2Fed99001d-72ee-4f91-9fc0-cd530d0adbbc%2FDancing.mp4)\r\n\r\n#### <a name=\"output-example\"></a>输出示例：\r\n\r\n[观看此视频](http://ampdemo.azureedge.net/?url=http%3A%2F%2Freferencestream-samplestream.streaming.mediaservices.windows.net%2Fc6608001-e5da-429b-9ec8-d69d8f3bfc79%2Fdance_redacted.mp4)\r\n\r\n### <a name=\"analyze-mode\"></a>分析模式\r\n\r\n双步工作流的 **分析** 步骤使用视频输入，并生成表示面部位置的 JSON 文件，以及显示每个检测到的面部的 jpg 图像。\r\n\r\n| 阶段 | 文件名 | 说明 |\r\n| --- | --- | --- |\r\n| 输入资产 |foo.bar |WMV、MPV 或 MP4 格式的视频 |\r\n| 输入配置 |作业配置预设 |{'version':'1.0', 'options': {'mode':'analyze'}} |\r\n| 输出资产 |foo_annotations.json |JSON 格式的面部位置批注数据。 用户可编辑此数据，以修改模糊边界框。 请查看以下示例。 |\r\n| 输出资产 |foo_thumb%06d.jpg [foo_thumb000001.jpg, foo_thumb000002.jpg] |裁剪后的 jpg 文件，显示每个检测到的面部，其中的数字指示面部的标签 ID |\r\n\r\n#### <a name=\"output-example\"></a>输出示例：\r\n\r\n    {\r\n      \"version\": 1,\r\n      \"timescale\": 24000,\r\n      \"offset\": 0,\r\n      \"framerate\": 23.976,\r\n      \"width\": 1280,\r\n      \"height\": 720,\r\n      \"fragments\": [\r\n        {\r\n          \"start\": 0,\r\n          \"duration\": 48048,\r\n          \"interval\": 1001,\r\n          \"events\": [\r\n            [],\r\n            [],\r\n            [],\r\n            [],\r\n            [],\r\n            [],\r\n            [],\r\n            [],\r\n            [],\r\n            [],\r\n            [],\r\n            [],\r\n            [],\r\n            [\r\n              {\r\n                \"index\": 13,\r\n                \"id\": 1138,\r\n                \"x\": 0.29537,\r\n                \"y\": -0.18987,\r\n                \"width\": 0.36239,\r\n                \"height\": 0.80335\r\n              },\r\n              {\r\n                \"index\": 13,\r\n                \"id\": 2028,\r\n                \"x\": 0.60427,\r\n                \"y\": 0.16098,\r\n                \"width\": 0.26958,\r\n                \"height\": 0.57943\r\n              }\r\n            ],\r\n\r\n    … truncated\r\n\r\n### <a name=\"redact-mode\"></a>修订模式\r\n工作流的第二步使用更大数量的输入，这些输入必须合并为单个资产。\r\n\r\n这包括要模糊处理的 ID 的列表、原始视频和批注 JSON。 此模式使用批注来对输入视频进行模糊处理。\r\n\r\n“分析”步骤的输出不包括原始视频。 需要将该视频上传到“修订”模式任务的输入资产中，并将其选作主文件。\r\n\r\n| 阶段 | 文件名 | 说明 |\r\n| --- | --- | --- |\r\n| 输入资产 |foo.bar |WMV、MPV 或 MP4 格式的视频。 与步骤 1 中相同的视频。 |\r\n| 输入资产 |foo_annotations.json |第一阶段中的批注元数据文件，包含可选的修改。 |\r\n| 输入资产 |foo_IDList.txt（可选） |要进行修订的可选面部 ID 列表，以新行进行分隔。 如果留空，则模糊所有面部。 |\r\n| 输入配置 |作业配置预设 |{'version':'1.0', 'options': {'mode':'redact'}} |\r\n| 输出资产 |foo_redacted.mp4 |基于批注进行了模糊处理的视频 |\r\n\r\n#### <a name=\"example-output\"></a>示例输出\r\n这是来自选择了一个 ID 的 ID 列表的输出。\r\n\r\n[观看此视频](http://ampdemo.azureedge.net/?url=http%3A%2F%2Freferencestream-samplestream.streaming.mediaservices.windows.net%2Fad6e24a2-4f9c-46ee-9fa7-bf05e20d19ac%2Fdance_redacted1.mp4)\r\n\r\n示例 foo_IDList.txt\r\n \r\n     1\r\n     2\r\n     3\r\n\r\n## <a name=\"blur-types\"></a>模糊类型\r\n\r\n在“组合”或“修订”模式下，可通过 JSON 输入配置在 5 种不同的模糊模式中选择：“低”、“中”、“高”、“框”和“黑色”。 默认情况下使用“中”。\r\n\r\n可以查找以下模糊类型的示例。\r\n\r\n### <a name=\"example-json\"></a>示例 JSON：\r\n\r\n    {'version':'1.0', 'options': {'Mode': 'Combined', 'BlurType': 'High'}}\r\n\r\n#### <a name=\"low\"></a>低\r\n\r\n![低](./media/media-services-face-redaction/blur1.png)\r\n \r\n#### <a name=\"med\"></a>中\r\n\r\n![中](./media/media-services-face-redaction/blur2.png)\r\n\r\n#### <a name=\"high\"></a>高\r\n\r\n![高](./media/media-services-face-redaction/blur3.png)\r\n\r\n#### <a name=\"box\"></a>Box\r\n\r\n![Box](./media/media-services-face-redaction/blur4.png)\r\n\r\n#### <a name=\"black\"></a>黑色\r\n\r\n![黑色](./media/media-services-face-redaction/blur5.png)\r\n\r\n## <a name=\"elements-of-the-output-json-file\"></a>输出 JSON 文件中的元素\r\n\r\n修订 MP 提供高精确度的面部位置检测和跟踪功能，可在一个视频帧中检测到最多 64 张人脸。 正面的面部可提供最佳效果，而检测和跟踪侧面的面部和较小的面部（小于或等于 24x24 像素）可能具有一定难度。\r\n\r\n[!INCLUDE [media-services-analytics-output-json](../../includes/media-services-analytics-output-json.md)]\r\n\r\n## <a name=\"net-sample-code\"></a>.NET 示例代码\r\n\r\n以下程序演示如何：\r\n\r\n1. 创建资产并将媒体文件上传到资产。\r\n2. 基于包含以下 json 预设的配置文件创建含有面部修订任务的作业。 \r\n   \r\n        {'version':'1.0', 'options': {'mode':'combined'}}\r\n3. 下载输出 JSON 文件。 \r\n\r\n#### <a name=\"create-and-configure-a-visual-studio-project\"></a>创建和配置 Visual Studio 项目\r\n\r\n设置开发环境，并根据[使用 .NET 进行媒体服务开发](media-services-dotnet-how-to-use.md)中所述，在 app.config 文件中填充连接信息。 \r\n\r\n#### <a name=\"example\"></a>示例\r\n\r\n    using System;\r\n    using System.Configuration;\r\n    using System.IO;\r\n    using System.Linq;\r\n    using Microsoft.WindowsAzure.MediaServices.Client;\r\n    using System.Threading;\r\n    using System.Threading.Tasks;\r\n\r\n    namespace FaceRedaction\r\n    {\r\n        class Program\r\n        {\r\n        // Read values from the App.config file.\r\n        private static readonly string _AADTenantDomain =\r\n            ConfigurationManager.AppSettings[\"AADTenantDomain\"];\r\n        private static readonly string _RESTAPIEndpoint =\r\n            ConfigurationManager.AppSettings[\"MediaServiceRESTAPIEndpoint\"];\r\n\r\n        // Field for service context.\r\n        private static CloudMediaContext _context = null;\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            var tokenCredentials = new AzureAdTokenCredentials(_AADTenantDomain, AzureEnvironments.AzureChinaCloudEnvironment);\r\n            var tokenProvider = new AzureAdTokenProvider(tokenCredentials);\r\n\r\n            _context = new CloudMediaContext(new Uri(_RESTAPIEndpoint), tokenProvider);\r\n\r\n            // Run the FaceRedaction job.\r\n            var asset = RunFaceRedactionJob(@\"C:\\supportFiles\\FaceRedaction\\SomeFootage.mp4\",\r\n                        @\"C:\\supportFiles\\FaceRedaction\\config.json\");\r\n\r\n            // Download the job output asset.\r\n            DownloadAsset(asset, @\"C:\\supportFiles\\FaceRedaction\\Output\");\r\n        }\r\n\r\n        static IAsset RunFaceRedactionJob(string inputMediaFilePath, string configurationFile)\r\n        {\r\n            // Create an asset and upload the input media file to storage.\r\n            IAsset asset = CreateAssetAndUploadSingleFile(inputMediaFilePath,\r\n            \"My Face Redaction Input Asset\",\r\n            AssetCreationOptions.None);\r\n\r\n            // Declare a new job.\r\n            IJob job = _context.Jobs.Create(\"My Face Redaction Job\");\r\n\r\n            // Get a reference to Azure Media Redactor.\r\n            string MediaProcessorName = \"Azure Media Redactor\";\r\n\r\n            var processor = GetLatestMediaProcessorByName(MediaProcessorName);\r\n\r\n            // Read configuration from the specified file.\r\n            string configuration = File.ReadAllText(configurationFile);\r\n\r\n            // Create a task with the encoding details, using a string preset.\r\n            ITask task = job.Tasks.AddNew(\"My Face Redaction Task\",\r\n            processor,\r\n            configuration,\r\n            TaskOptions.None);\r\n\r\n            // Specify the input asset.\r\n            task.InputAssets.Add(asset);\r\n\r\n            // Add an output asset to contain the results of the job.\r\n            task.OutputAssets.AddNew(\"My Face Redaction Output Asset\", AssetCreationOptions.None);\r\n\r\n            // Use the following event handler to check job progress.  \r\n            job.StateChanged += new EventHandler<JobStateChangedEventArgs>(StateChanged);\r\n\r\n            // Launch the job.\r\n            job.Submit();\r\n\r\n            // Check job execution and wait for job to finish.\r\n            Task progressJobTask = job.GetExecutionProgressTask(CancellationToken.None);\r\n\r\n            progressJobTask.Wait();\r\n\r\n            // If job state is Error, the event handling\r\n            // method for job progress should log errors.  Here we check\r\n            // for error state and exit if needed.\r\n            if (job.State == JobState.Error)\r\n            {\r\n            ErrorDetail error = job.Tasks.First().ErrorDetails.First();\r\n            Console.WriteLine(string.Format(\"Error: {0}. {1}\",\r\n                            error.Code,\r\n                            error.Message));\r\n            return null;\r\n            }\r\n\r\n            return job.OutputMediaAssets[0];\r\n        }\r\n\r\n        static IAsset CreateAssetAndUploadSingleFile(string filePath, string assetName, AssetCreationOptions options)\r\n        {\r\n            IAsset asset = _context.Assets.Create(assetName, options);\r\n\r\n            var assetFile = asset.AssetFiles.Create(Path.GetFileName(filePath));\r\n            assetFile.Upload(filePath);\r\n\r\n            return asset;\r\n        }\r\n\r\n        static void DownloadAsset(IAsset asset, string outputDirectory)\r\n        {\r\n            foreach (IAssetFile file in asset.AssetFiles)\r\n            {\r\n            file.Download(Path.Combine(outputDirectory, file.Name));\r\n            }\r\n        }\r\n\r\n        static IMediaProcessor GetLatestMediaProcessorByName(string mediaProcessorName)\r\n        {\r\n            var processor = _context.MediaProcessors\r\n            .Where(p => p.Name == mediaProcessorName)\r\n            .ToList()\r\n            .OrderBy(p => new Version(p.Version))\r\n            .LastOrDefault();\r\n\r\n            if (processor == null)\r\n            throw new ArgumentException(string.Format(\"Unknown media processor\",\r\n                                   mediaProcessorName));\r\n\r\n            return processor;\r\n        }\r\n\r\n        static private void StateChanged(object sender, JobStateChangedEventArgs e)\r\n        {\r\n            Console.WriteLine(\"Job state changed event:\");\r\n            Console.WriteLine(\"  Previous state: \" + e.PreviousState);\r\n            Console.WriteLine(\"  Current state: \" + e.CurrentState);\r\n\r\n            switch (e.CurrentState)\r\n            {\r\n            case JobState.Finished:\r\n                Console.WriteLine();\r\n                Console.WriteLine(\"Job is finished.\");\r\n                Console.WriteLine();\r\n                break;\r\n            case JobState.Canceling:\r\n            case JobState.Queued:\r\n            case JobState.Scheduled:\r\n            case JobState.Processing:\r\n                Console.WriteLine(\"Please wait...\\n\");\r\n                break;\r\n            case JobState.Canceled:\r\n            case JobState.Error:\r\n                // Cast sender as a job.\r\n                IJob job = (IJob)sender;\r\n                // Display or log error details as needed.\r\n                // LogJobStop(job.Id);\r\n                break;\r\n            default:\r\n                break;\r\n            }\r\n        }\r\n        }\r\n    }\r\n\r\n\r\n## <a name=\"related-links\"></a>相关链接\r\n\r\n[Azure 媒体服务分析概述](media-services-analytics-overview.md)\r\n\r\n[Azure Media Analytics demos（Azure 媒体分析演示）](http://azuremedialabs.azurewebsites.net/demos/Analytics.html)\r\n\r\n<!--Update_Description: wording update-->\r\n"}