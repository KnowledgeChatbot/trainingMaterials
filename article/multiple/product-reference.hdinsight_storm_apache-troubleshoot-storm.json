{"Title":"使用 Azure HDInsight 对 Storm 进行故障排除","Description":"获取有关在 Azure HDInsight 中使用 Apache Storm 时遇到的常见问题的解答。","Content":"# <a name=\"troubleshoot-storm-by-using-azure-hdinsight\"></a>使用 Azure HDInsight 对 Storm 进行故障排除\r\n\r\n了解处理 Apache Ambari 中的 Apache Storm 有效负载时的最常见问题及其解决方法。\r\n\r\n## <a name=\"how-do-i-access-the-storm-ui-on-a-cluster\"></a>如何在群集上访问 Storm UI？\r\n可以使用两个选项从浏览器访问 Storm UI：\r\n\r\n### <a name=\"ambari-ui\"></a>Ambari UI\r\n1. 转到 Ambari 仪表板。\r\n2. 在服务列表中，选择“Storm”。\r\n3. 在“快速链接”菜单中，选择“Storm UI”。\r\n\r\n### <a name=\"direct-link\"></a>直接链接\r\n可通过以下 URL 访问 Storm UI：\r\n\r\nhttps://\\<群集 DNS 名称\\>/stormui\r\n\r\n示例：\r\n\r\n https://stormcluster.azurehdinsight.cn/stormui\r\n\r\n## <a name=\"how-do-i-transfer-storm-event-hub-spout-checkpoint-information-from-one-topology-to-another\"></a>如何将 Storm 事件中心 Spout 检查点信息从一个拓扑传输到另一个拓扑？\r\n\r\n开发可使用 HDInsight Storm 事件中心 Spout .jar 文件从 Azure 事件中心读取数据的拓扑时，必须在新群集上部署同名的拓扑。 但是，必须在旧群集上保留已提交到 Apache ZooKeeper 的检查点数据。\r\n\r\n### <a name=\"where-checkpoint-data-is-stored\"></a>检查点数据的存储位置\r\n事件中心 Spout 将偏移检查点数据存储在 ZooKeeper 中的两个根路径下：\r\n- 非事务 Spout 检查点存储在 /eventhubspout 中。\r\n- 事务 Spout 检查点数据存储在 /transactional 中。\r\n\r\n### <a name=\"how-to-restore\"></a>如何还原\r\n若要获取可用于将数据导出 ZooKeeper 并使用新名称将其导入回到 ZooKeeper 的脚本和库，请参阅 [HDInsight Storm 示例](https://github.com/hdinsight/hdinsight-storm-examples/tree/master/tools/zkdatatool-1.0)。\r\n\r\nlib 文件夹中有一些 .Jar 文件，其中包含导出/导入操作的实现。 bash 文件夹包含一个示例脚本，该脚本演示如何从旧群集上的 ZooKeeper 服务器导出数据，并将数据导入回到新群集上的 ZooKeeper 服务器。\r\n\r\n在 ZooKeeper 节点中运行 [stormmeta.sh](https://github.com/hdinsight/hdinsight-storm-examples/blob/master/tools/zkdatatool-1.0/bash/stormmeta.sh) 脚本即可导出再导入数据。 需将该脚本更新为正确的 Hortonworks 数据平台 (HDP) 版本。 （我们正努力使这些脚本在 HDInsight 中通用化。 可以通过群集上的任何节点运行通用脚本，而无需用户进行修改。）\r\n\r\n导出命令会将元数据写入所设置位置中的 Apache Hadoop 分布式文件系统 (HDFS) 路径（在 Azure Blob 存储中）。\r\n\r\n### <a name=\"examples\"></a>示例\r\n\r\n#### <a name=\"export-offset-metadata\"></a>导出偏移元数据\r\n1. 使用 SSH 在需要从中导出检查点偏移数据的群集上转到 ZooKeeper 群集。\r\n2. （更新 HDP 版本字符串之后）运行以下命令，将 ZooKeeper 偏移数据导出到 /stormmetadta/zkdata HDFS 路径：\r\n\r\n    ```apache   \r\n    java -cp ./*:/etc/hadoop/conf/*:/usr/hdp/2.5.1.0-56/hadoop/*:/usr/hdp/2.5.1.0-56/hadoop/lib/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/lib/*:/etc/failover-controller/conf/*:/etc/hadoop/* com.microsoft.storm.zkdatatool.ZkdataImporter export /eventhubspout /stormmetadata/zkdata\r\n    ```\r\n\r\n#### <a name=\"import-offset-metadata\"></a>导入偏移元数据\r\n1. 使用 SSH 在需要从中导出检查点偏移数据的群集上转到 ZooKeeper 群集。\r\n2. （更新 HDP 版本字符串之后）运行以下命令，将 ZooKeeper 偏移数据从 HDFS 路径 /stormmetadata/zkdata 导入到目标群集上的 ZooKeeper 服务器：\r\n\r\n    ```apache\r\n    java -cp ./*:/etc/hadoop/conf/*:/usr/hdp/2.5.1.0-56/hadoop/*:/usr/hdp/2.5.1.0-56/hadoop/lib/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/lib/*:/etc/failover-controller/conf/*:/etc/hadoop/* com.microsoft.storm.zkdatatool.ZkdataImporter import /eventhubspout /home/sshadmin/zkdata\r\n    ```\r\n   \r\n#### <a name=\"delete-offset-metadata-so-that-topologies-can-start-processing-data-from-the-beginning-or-from-a-timestamp-that-the-user-chooses\"></a>删除偏移元数据，使拓扑能够从头开始或者从用户所选的时间戳开始处理数据\r\n1. 使用 SSH 在需要从中导出检查点偏移数据的群集上转到 ZooKeeper 群集。\r\n2. （更新 HDP 版本字符串之后）运行以下命令，删除当前群集中的所有 ZooKeeper 偏移数据：\r\n\r\n    ```apache\r\n       java -cp ./*:/etc/hadoop/conf/*:/usr/hdp/2.5.1.0-56/hadoop/*:/usr/hdp/2.5.1.0-56/hadoop/lib/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/lib/*:/etc/failover-controller/conf/*:/etc/hadoop/* com.microsoft.storm.zkdatatool.ZkdataImporter delete /eventhubspout\r\n    ```\r\n\r\n## <a name=\"how-do-i-locate-storm-binaries-on-a-cluster\"></a>如何在群集上查找 Storm 二进制文件？\r\n当前 HDP 堆栈的 Storm 二进制文件在 /usr/hdp/current/storm-client 中。 在头节点和工作节点上，此位置是相同的。\r\n \r\n/usr/hdp 中可能包含特定 HDP 版本的多个二进制文件（例如 /usr/hdp/2.5.0.1233/storm）。 /usr/hdp/current/storm-client 文件与群集上运行的最新版本建立了符号链接。\r\n\r\n有关详细信息，请参阅[使用 SSH 连接到 HDInsight 群集](../hdinsight-hadoop-linux-use-ssh-unix.md)和 [Storm](http://storm.apache.org/)。\r\n \r\n## <a name=\"how-do-i-determine-the-deployment-topology-of-a-storm-cluster\"></a>如何确定 Storm 群集的部署拓扑？\r\n首先，请识别连同 HDInsight Storm 一起安装的所有组件。 Storm 群集由四个节点类别组成：\r\n\r\n* 网关节点\r\n* 头节点\r\n* ZooKeeper 节点\r\n* 辅助角色节点\r\n \r\n### <a name=\"gateway-nodes\"></a>网关节点\r\n网关节点是一个网关和反向代理服务，可用于公开访问活动的 Ambari 管理服务。 它还处理 Ambari 群首选举。\r\n \r\n### <a name=\"head-nodes\"></a>头节点\r\nStorm 头节点运行以下服务：\r\n* Nimbus\r\n* Ambari 服务器\r\n* Ambari 指标服务器\r\n* Ambari 指标收集器\r\n \r\n### <a name=\"zookeeper-nodes\"></a>ZooKeeper 节点\r\nHDInsight 附带一个三节点 ZooKeeper 仲裁。 仲裁大小是固定的，不可重新配置。\r\n \r\n群集中的 Storm 服务配置为自动使用 ZooKeeper 仲裁。\r\n \r\n### <a name=\"worker-nodes\"></a>辅助角色节点\r\nStorm 工作节点运行以下服务：\r\n* 监督器\r\n* 用于运行拓扑的辅助角色 Java 虚拟机 (JVM)\r\n* Ambari 代理\r\n \r\n## <a name=\"how-do-i-locate-storm-event-hub-spout-binaries-for-development\"></a>如何查找用于开发的 Storm 事件中心 Spout 二进制文件？\r\n \r\n有关在拓扑中使用 Storm 事件中心 Spout .jar 文件的详细信息，请参阅以下资源。\r\n \r\n### <a name=\"java-based-topology\"></a>基于 Java 的拓扑\r\n[使用 Storm on HDInsight 从 Azure 事件中心处理事件 (Java)](./apache-storm-develop-java-topology.md)\r\n \r\n### <a name=\"c-based-topology-mono-on-hdinsight-34-linux-storm-clusters\"></a>基于 C# 的拓扑（HDInsight 3.4+ Linux Storm 群集上的 Mono）\r\n[使用 Storm on HDInsight 从 Azure 事件中心处理事件 (C#)](./apache-storm-develop-csharp-event-hub-topology.md)\r\n \r\n### <a name=\"latest-storm-event-hub-spout-binaries-for-hdinsight-35-linux-storm-clusters\"></a>HDInsight 3.5+ Linux Storm 群集的最新 Storm 事件中心 Spout 二进制文件\r\n若要了解如何使用适用于 HDInsight 3.5+ Linux Storm 群集的最新 Storm 事件中心 Spout，请参阅 mvn-repo [自述文件](https://github.com/hdinsight/mvn-repo/blob/master/README.md)。\r\n \r\n### <a name=\"source-code-examples\"></a>源代码示例\r\n参阅有关如何在 Azure HDInsight 群集上使用 Apache Storm 拓扑（以 Java 编写）从 Azure 事件中心读取和写入数据的[示例](https://github.com/Azure-Samples/hdinsight-java-storm-eventhub)。\r\n \r\n## <a name=\"how-do-i-locate-storm-log4j-configuration-files-on-clusters\"></a>如何在群集上查找 Storm Log4J 配置文件？\r\n \r\n识别 Storm 服务的 Apache Log4J 配置文件。\r\n \r\n### <a name=\"on-head-nodes\"></a>在头节点上\r\n从 /usr/hdp/\\<HDP version\\>/storm/log4j2/cluster.xml 读取 Nimbus Log4J 配置。\r\n \r\n### <a name=\"on-worker-nodes\"></a>在工作节点上\r\n从 /usr/hdp/\\<HDP version\\>/storm/log4j2/cluster.xml 读取监督器 Log4J 配置。\r\n \r\n从 /usr/hdp/\\<HDP version\\>/storm/log4j2/worker.xml 读取工作节点 Log4J 配置文件。\r\n \r\n示例：/usr/hdp/2.6.0.2-76/storm/log4j2/cluster.xml /usr/hdp/2.6.0.2-76/storm/log4j2/worker.xml\r\n\r\n### <a name=\"see-also\"></a>另请参阅\r\n[使用 Azure HDInsight 进行故障排除](../hdinsight-troubleshoot-guide.md)\r\n\r\n\r\n\r\n<!--Update_Description: update wording and link references-->"}