{"Title":"使用 Ambari 视图来操作 HDInsight (Hadoop) 上的 Hive - Azure","Description":"了解如何从 Web 浏览器中使用 Hive 视图来提交 Hive 查询。 Hive 视图是随基于 Linux 的 HDInsight 群集提供的 Ambari Web UI 的一部分。","Content":"# <a name=\"use-ambari-hive-view-with-hadoop-in-hdinsight\"></a>将 Ambari Hive 视图与 HDInsight 中的 Hadoop 配合使用\r \r [!INCLUDE [hive-selector](../../../includes/hdinsight-selector-use-hive.md)]\r \r 了解如何使用 Ambari Hive 视图运行 Hive 查询。 Ambari 是一个管理和监控实用程序，随基于 Linux 的 HDInsight 群集一起提供。 通过 Ambari 提供的功能之一是可用于运行 Hive 查询的 Web UI。\r \r > [!NOTE]\r > Ambari 还有许多本文档中未讨论的功能。 有关详细信息，请参阅[使用 Ambari Web UI 管理 HDInsight 群集](../hdinsight-hadoop-manage-ambari.md)。\r \r ## <a name=\"prerequisites\"></a>先决条件\r \r * 基于 Linux 的 HDInsight 群集。 有关创建群集的信息，请参阅[开始在 HDInsight 中使用 Hadoop](apache-hadoop-linux-tutorial-get-started.md)。\r \r > [!IMPORTANT]\r > 本文档中的步骤需要使用 Linux 的 Azure HDInsight 群集。 Linux 是 HDInsight 3.4 或更高版本上使用的唯一操作系统。 有关详细信息，请参阅 [HDInsight 在 Windows 上停用](../hdinsight-component-versioning.md#hdinsight-windows-retirement)。\r \r ## <a name=\"open-the-hive-view\"></a>打开 Hive 视图\r \r 可以从 Azure 门户打开 Ambari 视图。 选择 HDInsight 群集，然后从“快速链接”部分选择“Ambari 视图”。\r \r ![门户快速链接部分](./media/apache-hadoop-use-hive-ambari-view/quicklinks.png)\r \r 在视图列表中，选择“Hive 视图”。\r \r ![已选中 Hive 视图](./media/apache-hadoop-use-hive-ambari-view/select-hive-view.png)\r \r > [!NOTE]\r > 访问 Ambari 时，系统会提示向该站点进行身份验证。 输入在创建群集时使用的管理员（默认 `admin`）帐户名和密码。\r \r 应看到类似于下图的页面：\r \r ![Hive 视图查询工作表图像](./media/apache-hadoop-use-hive-ambari-view/ambari-hive-view.png)\r \r ## <a name=\"run-a-query\"></a>运行查询\r \r 若要运行 hive 查询，请使用 Hive 视图中的以下步骤。\r \r 1. 将以下 HiveQL 语句从“查询”选项卡粘贴到工作表中：\r \r     ```hiveql\r     DROP TABLE log4jLogs;\r     CREATE EXTERNAL TABLE log4jLogs(t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string)\r     ROW FORMAT DELIMITED FIELDS TERMINATED BY ' '\r     STORED AS TEXTFILE LOCATION '/example/data/';\r     SELECT t4 AS sev, COUNT(*) AS cnt FROM log4jLogs WHERE t4 = '[ERROR]' GROUP BY t4;\r     ```\r \r     这些语句可执行以下操作：\r \r    * `DROP TABLE`：删除表和数据文件（如果该表已存在）。\r \r    * `CREATE EXTERNAL TABLE`：在 Hive 中创建一个新的“外部”表。\r    外部表仅在 Hive 中存储表定义。 数据保留在原始位置。\r \r    * `ROW FORMAT`：演示如何设置数据格式。 在此情况下，每个日志中的字段以空格分隔。\r \r    * `STORED AS TEXTFILE LOCATION`：显示数据的存储位置，并且数据已存储为文本。\r \r    * `SELECT`：选择 t4 列包含值 [ERROR] 的所有行的计数。\r \r      > [!NOTE]\r      > 预期以外部源（例如自动化数据上传过程或其他 MapReduce 操作）更新基础数据时，请使用外部表。 删除外部表*不会*删除数据，只会删除表定义。\r \r     > [!IMPORTANT]\r     > 将“数据库”选择保留为“默认”。 本文档中的示例使用 HDInsight 附带的默认数据库。\r \r 2. 要启动查询，请使用工作表下方的“执行”按钮。 按钮变为橙色，文本更改为“停止”。\r \r 3. 完成查询后，“结果”选项卡显示操作结果。 以下文本是查询结果：\r \r         sev       cnt\r         [ERROR]   3\r \r     可使用“日志”选项卡查看作业创建的日志记录信息。\r \r    > [!TIP]\r    > 通过位于“查询处理结果”部分左上角的“保存结果”下拉对话框，可下载或保存结果。\r \r 4. 选择此查询的前四行，然后选择“执行”。 请注意，作业完成时不会有任何结果。 在选择了查询的一部分时使用“执行”  按钮只会运行所选语句。 在这种情况下，所选内容不包括会从表中检索行的最后一条语句。 如果只选择该行并使用“执行”，则应该会看到预期的结果。\r \r 5. 要添加工作表，请使用“查询编辑器”底部的“新建工作表”按钮。 在新工作表中，输入以下 Hive 语句：\r \r     ```hiveql\r     CREATE TABLE IF NOT EXISTS errorLogs (t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string) STORED AS ORC;\r     INSERT OVERWRITE TABLE errorLogs SELECT t1, t2, t3, t4, t5, t6, t7 FROM log4jLogs WHERE t4 = '[ERROR]';\r     ```\r \r   这些语句可执行以下操作：\r \r    * **CREATE TABLE IF NOT EXISTS**：创建表（如果尚不存在表）。 由于未使用 EXTERNAL 关键字，因此将创建一个内部表。 内部表存储在 Hive 数据仓库中，并完全由 Hive 管理。 与外部表不同，删除内部表会同时删除基础数据。\r \r    * **STORED AS ORC**：以优化行纵栏表 (ORC) 格式存储数据。 ORC 是高度优化且有效的 Hive 数据存储格式。\r \r    * **INSERT OVERWRITE ...SELECT**从包含 `[ERROR]` 的 log4jLogs 表中选择行，然后将数据插入 errorLogs 表中。\r \r 使用“执行”按钮运行此查询。 如果查询返回零行，则“结果”选项卡不包含任何信息。 查询完成后，状态应显示为“成功”。\r \r ### <a name=\"visual-explain\"></a>Visual explain\r \r 要显示查询计划的可视化效果，选择工作表下方的“可视化说明”选项卡。\r \r 查询的“可视化说明”视图可帮助理解复杂查询的流。 可使用查询编辑器上的“说明”按钮查看此视图的等效文本。\r \r ### <a name=\"tez-ui\"></a>Tez UI\r \r 要显示查询的 Tez UI，选择工作表下方的“Tez”选项卡。\r \r > [!IMPORTANT]\r > Tez 不用于解析所有查询。 无需使用 Tez 即可解析许多查询。 \r \r 如果使用 Tez 来解析查询，将显示有向无环图 (DAG)。 若要查看之前运行的查询的 DAG，或调试 Tez 进程，请改用 [Tez 视图](../hdinsight-debug-ambari-tez-view.md)。\r \r ## <a name=\"view-job-history\"></a>查看作业历史记录\r \r “作业”选项卡显示 Hive 查询的历史记录。\r \r ![作业历史记录图像](./media/apache-hadoop-use-hive-ambari-view/job-history.png)\r \r ## <a name=\"database-tables\"></a>数据库表\r \r 可使用“表”选项卡处理 Hive 数据库内的表。\r \r ![表选项卡图像](./media/apache-hadoop-use-hive-ambari-view/tables.png)\r \r ## <a name=\"saved-queries\"></a>已保存的查询\r \r 在“查询”选项卡中，可以按需要保存查询。 保存查询后，可通过“已保存的查询”选项卡对其重复进行使用。\r \r ![“保存的查询”选项卡图像](./media/apache-hadoop-use-hive-ambari-view/saved-queries.png)\r \r ## <a name=\"user-defined-functions\"></a>用户定义的函数\r \r 还可以通过用户定义函数 (UDF) 扩展 Hive。 使用 UDF 实现 HiveQL 中不容易建模的功能或逻辑。\r \r 使用 Hive 视图顶部的“UDF”选项卡，声明并保存一组 UDF。 可以在**查询编辑器**中使用这些 UDF。\r \r ![UDF 选项卡图像](./media/apache-hadoop-use-hive-ambari-view/user-defined-functions.png)\r \r 将 UDF 添加到 Hive 视图后，“插入 UDF”按钮将显示在“查询编辑器”底部。 选择此项将显示 Hive 视图中定义的 UDF 的下拉列表。 选择一个 UDF 可向查询添加 HiveQL 语句以启用 UDF。\r \r 例如，如果定义了一个具有以下属性的 UDF：\r \r * 资源名称：myudfs\r \r * 资源路径：/myudfs.jar\r \r * UDF 名称：myawesomeudf\r \r * UDF 类名称：com.myudfs.Awesome\r \r 使用“插入 UDF”按钮将显示名为 myudfs 的条目，以及为该资源定义的每个 UDF 的另一下拉列表。 本例中为 myawesomeudf。 选择此条目会在查询的开头添加以下内容：\r \r ```hiveql\r add jar /myudfs.jar;\r create temporary function myawesomeudf as 'com.myudfs.Awesome';\r ```\r \r 然后便可在查询中使用 UDF。 例如，`SELECT myawesomeudf(name) FROM people;`。\r \r 有关如何在 HDInsight 中将 UDF 与 Hive 配合使用的详细信息，请参阅以下文章：\r \r * [在 HDInsight 中将 Python 与 Hive 和 Pig 配合使用](python-udf-hdinsight.md)\r * [如何将自定义 Hive UDF 添加到 HDInsight](http://blogs.msdn.com/b/bigdatasupport/archive/2014/01/14/how-to-add-custom-hive-udfs-to-hdinsight.aspx)\r \r ## <a name=\"hive-settings\"></a>Hive 设置\r \r 可以更改各种 Hive 设置，例如将 Hive 的执行引擎从 Tez（默认）更改为 MapReduce。\r \r ## <a id=\"nextsteps\"></a>后续步骤\r \r 有关 HDInsight 中 Hive 的常规信息：\r \r * [将 Hive 与 Hadoop on HDInsight 配合使用](hdinsight-use-hive.md)\r \r 有关 HDInsight 上 Hadoop 的其他使用方法的信息：\r \r * [将 Pig 与 Hadoop on HDInsight 配合使用](hdinsight-use-pig.md)\r * [将 MapReduce 与 HDInsight 上的 Hadoop 配合使用](hdinsight-use-mapreduce.md)\r \r <!--Update_Description: update wording and link references-->"}