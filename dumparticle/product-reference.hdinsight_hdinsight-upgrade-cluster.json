{"Title":"将 HDInsight 群集升级到更新版本 - Azure","Description":"了解如何将 HDInsight 群集升级到较新版本。","Content":"# <a name=\"upgrade-hdinsight-cluster-to-a-newer-version\"></a>将 HDInsight 群集升级到更新版本\r 要利用最新的 HDInsight 功能，我们建议将 HDInsight 群集升级到最新版本。 按照以下准则升级 HDInsight 群集版本。\r \r > [!NOTE]\r > HDInsight 群集版本 3.2 和 3.3 即将停用。 有关支持的 HDInsight 版本的信息，请参阅 [HDInsight 组件版本](hdinsight-component-versioning.md#supported-hdinsight-versions)。\r >\r >\r \r ## <a name=\"upgrade-tasks\"></a>升级任务\r 升级 HDInsight 群集的工作流如下所示。\r \r ![升级工作流关系图](./media/hdinsight-upgrade-cluster/upgrade-workflow.png)\r \r 1. 请阅读本文档的每个部分，以了解升级 Linux 群集时可能需要进行的更改。\r 2. 创建群集作为测试/质量保证环境。 有关创建群集的详细信息，请参阅[了解如何创建基于 Linux 的 HDInsight 群集](hdinsight-hadoop-provision-linux-clusters.md)\r 3. 将现有作业、数据源及接收器复制到新环境。 有关详细信息，请参阅[将数据复制到测试环境](hdinsight-migrate-from-windows-to-linux.md#copy-data-to-the-test-environment)。\r 4. 执行验证测试，以确保作业在新群集上按预期工作。\r \r 验证一切都按预期工作后，请为迁移安排停机时间。 在此停机期间，请执行以下操作：\r \r 1.  备份所有存储在本地群集节点上的暂时性数据。 例如，如果数据直接存储在头节点上。\r 2.  删除现有的群集。\r 3.  使用以前群集使用的同一默认数据存储在与最新（或支持）的 HDI 版本相同的 VNET 子网中创建群集。 这样，新群集便可根据现有生产数据继续运行。\r 4.  导入任何已备份的暂时性数据。\r 5.  使用新群集启动作业/继续处理。\r \r ## <a name=\"next-steps\"></a>后续步骤\r * [了解如何创建基于 Linux 的 HDInsight 群集](hdinsight-hadoop-provision-linux-clusters.md)\r * [使用 SSH 连接到 HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md)\r * [使用 Ambari 管理基于 Linux 的群集](hdinsight-hadoop-manage-ambari.md)\r \r <!--Update_Description: update wording and link references-->"}