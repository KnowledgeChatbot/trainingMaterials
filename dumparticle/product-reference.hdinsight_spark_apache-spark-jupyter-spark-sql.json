{"Title":"在 Azure HDInsight 中创建 Apache Spark 群集","Description":"此 HDInsight Spark 快速入门介绍如何在 HDInsight 中创建 Apache Spark 群集。","Content":"# <a name=\"create-an-apache-spark-cluster-in-azure-hdinsight\"></a>在 Azure HDInsight 中创建 Apache Spark 群集\r \r 本文介绍如何在 Azure HDInsight 中创建 Apache Spark 群集，然后针对 Hive 表运行 Spark SQL 查询。 有关 Spark on HDInsight 的信息，请参阅[概述：Azure HDInsight 上的 Apache Spark](apache-spark-overview.md)。\r \r    ![快速入门示意图，其中描述了在 Azure HDInsight 上创建 Apache Spark 群集的步骤](./media/apache-spark-jupyter-spark-sql/hdinsight-spark-quickstart-interactive-spark-query-flow.png \"有关在 HDInsight 中使用 Apache Spark 的 Spark 快速入门。示意图中的步骤：创建群集；运行 Spark 交互式查询\")\r \r ## <a name=\"prerequisites\"></a>先决条件\r \r * **一个 Azure 订阅**。 在开始学习本教程之前，必须有一个 Azure 订阅。 请参阅[立即创建 Azure 试用帐户](https://www.azure.cn/pricing/1rmb-trial)。\r \r ## <a name=\"create-hdinsight-spark-cluster\"></a>创建 HDInsight Spark 群集\r \r 在本部分，你将使用 [Azure Resource Manager 模板](https://azure.microsoft.com/resources/templates/101-hdinsight-spark-linux/)创建 HDInsight Spark 群集。 有关其他群集创建方法，请参阅[创建 HDInsight 群集](../hdinsight-hadoop-provision-linux-clusters.md)。\r \r 1. 单击下面的图像即可在 Azure 门户中打开该模板。         \r \r     <a href=\"https://portal.azure.cn/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2FAzure%2Fazure-quickstart-templates%2Fmaster%2F101-hdinsight-spark-linux%2Fazuredeploy.json\" target=\"_blank\"><img src=\"./media/apache-spark-jupyter-spark-sql/deploy-to-azure.png\" alt=\"Deploy to Azure\"></a>\r \r 2. 输入以下值：\r \r     ![使用 Azure 资源管理器模板创建 HDInsight Spark 群集](./media/apache-spark-jupyter-spark-sql/create-spark-cluster-in-hdinsight-using-azure-resource-manager-template.png \"使用 Azure 资源管理器模板在 HDInsight 中创建 Spark 群集\")\r \r     * **订阅**：为此群集选择 Azure 订阅。\r     * **资源组**：创建资源组或选择现有的资源组。 使用资源组管理项目的 Azure 资源。\r     * **位置**：选择资源组的位置。 模板将此位置用于创建群集，以及用于默认群集存储。\r     * **ClusterName**：为要创建的 HDInsight 群集输入名称。\r     * **Spark 版本**：选择 **2.0** 作为要在群集上安装的版本。\r     * **群集登录名和密码**：默认登录名是 admin。\r     * **SSH 用户名和密码**。\r \r    请记下这些值。  本教程后面会用到它们。\r \r 3. 选择“我同意上述条款和条件”，选择“固定到仪表板”，并单击“购买”。 此时会出现一个标题为“为模板部署提交部署”的新磁贴。 创建群集大约需要 20 分钟时间。\r \r 如果在创建 HDInsight 群集时遇到问题，可能是因为没有这样做的适当权限。 有关详细信息，请参阅[访问控制要求](../hdinsight-administer-use-portal-linux.md#create-clusters)。\r \r > [!NOTE]\r > 本文创建使用 [Azure 存储 Blob 作为群集存储](../hdinsight-hadoop-use-blob-storage.md)的 Spark 群集。\r >\r >\r \r ## <a name=\"run-spark-sql-statements-on-a-hive-table\"></a>针对 Hive 表运行 Spark SQL 语句\r \r SQL（结构化查询语言）是用于查询和定义数据的最常见、最广泛使用的语言。 Spark 的创建者试图利用此知识，向更多想要处理 Hadoop 分布式文件系统 (HDFS) 中数据的分析人员受众，开放已知的数据查询语言。 Spark SQL 便是该产品。 它作为 Apache Spark 的扩展使用，可使用熟悉的 SQL 语法处理结构化数据。\r \r Spark SQL 同时支持将 SQL 和 HiveQL 作为查询语言。 其功能包括在 Python、Scala 和 Java 中绑定。 使用它，可以查询存储在多个位置的数据，例如外部数据库、结构化数据文件（示例：JSON）和 Hive 表。\r \r ### <a name=\"running-spark-sql-on-an-hdinsight-cluster\"></a>在 HDInsight 群集中运行 Spark SQL\r \r 使用为 HDInsight Spark 群集配置的 Jupyter Notebook 时，会获得一个预设的 `sqlContext`，可以使用它通过 Spark SQL 来运行 Hive 查询。 本部分介绍如何启动 Jupyter notebook，然后针对在所有 HDInsight 群集上都可用的现有 Hive 表 (**hivesampletable**) 运行基本 Spark SQL 查询。\r \r 1. 打开 [Azure 门户](https://portal.azure.cn/)。\r \r 2. 如果已选择将群集固定到仪表板，请单击仪表板中的群集磁贴，启动群集边栏选项卡。\r \r     如果未将群集固定到仪表板，则请单击左窗格中的“HDInsight 群集”，并单击已创建的群集。\r \r 3. 在“快速链接”中，单击“群集仪表板”，然后单击“Jupyter Notebook”。 出现提示时，请输入群集的管理员凭据。\r \r    ![打开 Jupyter Notebook 来运行交互式 Spark SQL 查询](./media/apache-spark-jupyter-spark-sql/hdinsight-spark-open-jupyter-interactive-spark-sql-query.png \"打开 Jupyter Notebook 来运行交互式 Spark SQL 查询\")\r \r    > [!NOTE]\r    > 也可以在浏览器中打开以下 URL 来访问群集的 Jupyter Notebook。 将 **CLUSTERNAME** 替换为群集的名称：\r    >\r    > `https://CLUSTERNAME.azurehdinsight.cn/jupyter`\r    >\r    >\r 3. 创建 Notebook。 单击“新建”，然后单击“PySpark”。\r \r    ![创建 Jupyter Notebook 来运行交互式 Spark SQL 查询](./media/apache-spark-jupyter-spark-sql/hdinsight-spark-create-jupyter-interactive-spark-sql-query.png \"创建 Jupyter Notebook 来运行交互式 Spark SQL 查询\")\r \r    新 Notebook 随即会创建，并以 Untitled(Untitled.pynb) 名称打开。\r \r 4. 在顶部单击笔记本名称，并输入一个友好名称（如果需要）。\r \r     ![为要从中运行交互式 Spark 查询的 Jupyter notebook 提供一个名称](./media/apache-spark-jupyter-spark-sql/hdinsight-spark-jupyter-notebook-name.png \"为要从中运行交互式 Spark 查询的 Jupyter notebook 提供一个名称\")\r \r 5.  将以下代码粘贴到一个空单元格中，然后按 **SHIFT + ENTER** 来运行这些代码。 在下面的代码中，`%%sql`（称为 sql magic）指示 Jupyter Notebook 使用预设 `sqlContext` 运行 Hive 查询。 该查询从默认情况下可以在所有 HDInsight 群集上使用的 Hive 表 (hivesampletable) 中检索前 10 行。\r \r         %%sql\r         SELECT * FROM hivesampletable LIMIT 10\r \r     ![HDInsight Spark 中的 Hive 查询](./media/apache-spark-jupyter-spark-sql/hdinsight-spark-get-started-hive-query.png \"HDInsight Spark 中的 Hive 查询\")\r \r     有关 `%%sql` magic 和预设上下文的详细信息，请参阅[适用于 HDInsight 群集的 Jupyter 内核](apache-spark-jupyter-notebook-kernels.md)。\r \r     > [!NOTE]\r     > 每次在 Jupyter 中运行查询时，Web 浏览器窗口标题中都会显示“(繁忙)”状态和 Notebook 标题。 右上角“PySpark”文本的旁边还会出现一个实心圆。 作业完成后，实心圆将变成空心圆。\r     >\r     >\r \r 6. 屏幕在刷新后会显示查询输出。\r \r     ![HDInsight Spark 中的 Hive 查询输出](./media/apache-spark-jupyter-spark-sql/hdinsight-spark-get-started-hive-query-output.png \"HDInsight Spark 中的 Hive 查询输出\")\r \r 7. 运行完应用程序后，可以关闭 Notebook 以释放资源。 为此，请在笔记本的“文件”菜单中，单击“关闭并停止”。\r \r 8. 如果计划稍后再完成后续步骤，请确保删除在本文中创建的 HDInsight 群集。 \r \r [!INCLUDE [delete-cluster-warning](../../../includes/hdinsight-delete-cluster-warning.md)]\r \r ## <a name=\"next-step\"></a>后续步骤 \r \r 本文介绍了如何创建 HDInsight Spark 群集并运行基本的 Spark SQL 查询。 转到下一文章，了解如何使用 HDInsight Spark 群集针对示例数据运行交互式查询。\r \r > [!div class=\"nextstepaction\"]\r >[在 HDInsight Spark 群集上运行交互式查询](apache-spark-load-data-run-query.md)\r \r \r \r <!--Update_Description: update wording and link references-->"}