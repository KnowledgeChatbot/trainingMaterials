{"Title":"将用于 IntelliJ 的 Azure 工具包与 Hortonworks 沙盒配合使用","Description":"了解如何将用于 IntelliJ 的 Azure 工具包中的 HDInsight 工具与 Hortonworks 沙盒配合使用。","Content":"# <a name=\"use-hdinsight-tools-for-intellij-with-hortonworks-sandbox\"></a>将用于 IntelliJ 的 HDInsight 工具与 Hortonworks 沙盒配合使用\r \r 了解如何通过用于 IntelliJ 的 HDInsight 工具开发 Apache Scala 应用程序，并在计算机上运行的 [Hortonworks 沙盒](http://hortonworks.com/products/sandbox/)上测试应用程序。 \r \r [IntelliJ IDEA](https://www.jetbrains.com/idea/) 是一种 Java 集成开发环境 (IDE)，用于开发计算机软件。 在 Hortonworks 沙盒上开发并测试应用程序以后，即可将应用程序移至 [Azure HDInsight](apache-hadoop-introduction.md)。\r \r ## <a name=\"prerequisites\"></a>先决条件\r \r 要阅读本教程，必须具备以下项：\r \r - 基于 Hortonworks 沙盒的 Hortonworks 数据平台 (HDP) 2.4，运行在本地计算机中。 若要设置 HDP，请参阅[通过虚拟机上的 Hadoop 沙盒了解 Hadoop 生态系统](apache-hadoop-emulator-get-started.md)。 \r \r     > [!NOTE]\r     > 用于 IntelliJ 的 HDInsight 工具只使用 HDP 2.4 测试过。 若要获取 HDP 2.4，请在 [Hortonworks 沙盒下载站点](http://hortonworks.com/downloads/#sandbox)中，展开 **Hortonworks 沙盒存档**。\r \r - [Java 开发人员工具包 (JDK) 1.8 或更高版本](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)。 用于 IntelliJ 的 Azure 工具包需要 JDK。\r \r - [IntelliJ IDEA 社区版](https://www.jetbrains.com/idea/download)，带 [Scala](https://plugins.jetbrains.com/idea/plugin/1347-scala) 插件和[用于 IntelliJ 的 Azure 工具包](../../azure-toolkit-for-intellij.md)插件。 用于 IntelliJ 的 HDInsight 工具作为用于 IntelliJ 的 Azure 工具包的一部分提供。 \r \r 安装插件的步骤：\r \r   1. 打开 IntelliJ IDEA。\r   2. 在“欢迎”页上，依次选择“配置”、“插件”。\r   3. 选择左下角的“安装 JetBrains 插件”。\r   4. 使用搜索功能搜索 **Scala**，并选择“安装”。\r   5. 若要完成安装，请选择“重启 IntelliJ IDEA”。\r   6. 重复步骤 4 和步骤 5，安装**用于 IntelliJ 的 Azure 工具包**。 有关详细信息，请参阅[安装用于 IntelliJ 的 Azure 工具包](../../azure-toolkit-for-intellij-installation.md)。\r \r ## <a name=\"create-a-spark-scala-application\"></a>创建 Spark Scala 应用程序\r \r 本部分使用 IntelliJ IDEA 创建示例 Scala 项目。 在下一部分，用户在提交项目之前，需将 IntelliJ IDEA 链接到 Hortonworks 沙盒（仿真程序）。\r \r 1. 在计算机上打开 IntelliJ IDEA。 在“新建项目”对话框中，完成以下步骤：\r \r    1. 选择“HDInsight” > “Spark on HDInsight (Scala)”\r    2. 在“生成工具”列表中，基于方案选择以下项之一：\r \r     * **Maven**：用于支持 Scala 项目创建向导。\r     * **SBT**：用于管理依赖项和生成 Scala 项目。\r \r    ![“新建项目”对话框](./media/hdinsight-tools-for-intellij-with-hortonworks-sandbox/intellij-create-scala-project.png)\r \r 2. 选择“**下一步**”。\r 3. 在接下来显示的“新建项目”对话框中，完成以下步骤：\r \r     1. 在“项目名称”框中输入项目名称。\r     2. 在“项目位置”框中输入项目位置。\r     3. 在“项目 SDK”下拉列表旁边，依次选择“新建”和“JDK”，并指定 Java JDK 1.7 或更高版本的文件夹。 为 Spark 2.x 群集选择 **Java 1.8**。 为 Spark 1.x 群集选择 **Java 1.7**。 默认位置为 C:\\Program Files\\Java\\jdk1.8.x_xxx。\r     4. 在“Spark 版本”下拉列表中，Scala 项目创建向导集成了 Spark SDK 和 Scala SDK 的正确版本。 如果 Spark 群集版本低于 2.0，请选择“Spark 1.x”。 否则，请选择“Spark 2.x”。 本示例使用“Spark 1.6.2 (Scala 2.10.5)”。 请确保使用标记为 Scala 2.10.x 的存储库。 不要使用标记为 Scala 2.11.x 的存储库。\r     \r     ![创建 IntelliJ Scala 项目属性](./media/hdinsight-tools-for-intellij-with-hortonworks-sandbox/intellij-create-scala-project-properties.png)\r \r \r 4. 选择“完成”。\r \r 5. 如果“项目”视图尚未打开，请按 **Alt+1** 将其打开。\r 6. 在“项目资源管理器”中展开项目，并选择“src”。\r 7. 右键单击“src”，指向“新建”，并选择“Scala 类”。\r 8. 在“名称”框中，输入名称。 在“类型”框中，选择“对象”。 选择“确定”。\r \r     ![“新建 Scala 类”对话框](./media/hdinsight-tools-for-intellij-with-hortonworks-sandbox/intellij-create-new-scala-class.png)\r \r 9. 在 .scala 文件中粘贴以下代码：\r \r         import java.util.Random\r         import org.apache.spark.{SparkConf, SparkContext}\r         import org.apache.spark.SparkContext._\r \r         /**\r         * Usage: GroupByTest [numMappers] [numKVPairs] [valSize] [numReducers]\r         */\r         object GroupByTest {\r             def main(args: Array[String]) {\r                 val sparkConf = new SparkConf().setAppName(\"GroupBy Test\")\r                 var numMappers = 3\r                 var numKVPairs = 10\r                 var valSize = 10\r                 var numReducers = 2\r \r                 val sc = new SparkContext(sparkConf)\r \r                 val pairs1 = sc.parallelize(0 until numMappers, numMappers).flatMap { p =>\r                 val ranGen = new Random\r                 var arr1 = new Array[(Int, Array[Byte])](numKVPairs)\r                 for (i <- 0 until numKVPairs) {\r                     val byteArr = new Array[Byte](valSize)\r                     ranGen.nextBytes(byteArr)\r                     arr1(i) = (ranGen.nextInt(Int.MaxValue), byteArr)\r                 }\r                 arr1\r                 }.cache\r                 // Enforce that everything has been calculated and in cache.\r                 pairs1.count\r \r                 println(pairs1.groupByKey(numReducers).count)\r             }\r         }\r \r 10. 在“生成”菜单中，选择“生成项目”。 确保编译成功完成。\r \r \r ## <a name=\"link-to-the-hortonworks-sandbox\"></a>Hortonworks 沙盒链接\r \r 必须先有 IntelliJ 应用程序，才能链接到 Hortonworks 沙盒（仿真器）。\r \r 若要链接到模拟器，请执行以下操作：\r \r 1. 在 IntelliJ 中打开项目。\r \r 2. 在“视图”菜单中，依次选择“工具窗口”、“Azure 资源管理器”。\r \r 3. 展开“Azure”，右键单击“HDInsight”，并选择“链接仿真器”。\r 4. 在“链接新模拟器”对话框中，输入为 Hortonworks 沙盒的根帐户设定的密码。 接下来，输入类似于以下屏幕截图中所使用的值。 选择“确定”。 \r \r    ![“链接新模拟器”对话框](./media/hdinsight-tools-for-intellij-with-hortonworks-sandbox/intellij-link-an-emulator.png)\r \r 5. 若要配置仿真器，请选择“是”。\r \r 成功连接模拟器后，模拟器（Hortonworks 沙盒）会列在 HDInsight 节点中。\r \r ## <a name=\"submit-the-spark-scala-application-to-the-hortonworks-sandbox\"></a>将 Spark Scala 应用程序提交到 Hortonworks 沙盒\r \r 将 IntelliJ IDEA 链接到仿真器之后，即可提交项目。\r \r 若要将项目提交到模拟器，请执行以下操作：\r \r 1. 在“项目资源管理器”中，右键单击项目，并选择“将 Spark 应用程序提交到 HDInsight”。\r 2. 完成以下步骤：\r \r     1. 在“Spark 群集(仅 Linux)”下拉列表中，选择本地 Hortonworks 沙盒。\r     2. 在“主类名”框中，选择或输入主类名。 对于本教程，该名称为 **GroupByTest**。\r \r 3. 选择“提交”。 作业提交日志显示在“Spark”提交工具窗口。\r \r ## <a name=\"next-steps\"></a>后续步骤\r \r - 了解如何[使用用于 IntelliJ 的 Azure 工具包中的 HDInsight 工具为 HDInsight Spark Linux 群集创建 Spark 应用程序](../spark/apache-spark-intellij-tool-plugin.md)。\r \r - 有关用于 IntelliJ 的 HDInsight 工具的视频，请参阅 [Introduce HDInsight Tools for IntelliJ for Spark development](https://www.youtube.com/watch?v=YTZzYVgut6c)（介绍如何通过用于 IntelliJ 的 HDInsight 工具进行 Spark 开发）。\r \r - 了解如何[使用用于 IntelliJ 的 Azure 工具包通过 SSH 远程调试 HDInsight 群集上的 Spark 应用程序](../spark/apache-spark-intellij-tool-debug-remotely-through-ssh.md)。\r \r - 了解如何[使用用于 IntelliJ 的 Azure 工具包中的 HDInsight 工具在 HDInsight Spark Linux 群集上远程调试 Spark 应用程序](../spark/apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)。\r \r - 了解如何[使用用于 Eclipse 的 Azure 工具包中的 HDInsight 工具创建 Spark 应用程序](../spark/apache-spark-eclipse-tool-plugin.md)。\r \r \r \r <!--Update_Description: update wording and link references-->"}