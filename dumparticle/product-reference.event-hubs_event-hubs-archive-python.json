{"Title":"Azure 事件中心存档演练","Description":"此示例使用 Azure Python SDK 来演示如何使用事件中心存档功能。","Content":"# 事件中心存档演练：Python\r <a name=\"event-hubs-archive-walkthrough-python\" ></a>\r 事件中心存档是事件中心的一项新功能，用户可借助该功能自动将事件中心内的流数据传送到所选的 Azure Blob 存储帐户。 这样易于对实时流数据执行批处理操作。 本文介绍如何通过 Python 使用事件中心存档功能。 有关事件中心存档的详细信息，请参阅[概述文章](event-hubs-archive-overview.md)。\r \r 此示例使用 [Azure Python SDK](/develop/python/) 演示如何使用存档功能。 Sender.py 程序以 JSON 格式将模拟的环境遥测数据发送到事件中心。 事件中心配置为使用存档功能将此数据成批地写入到 Blob 存储。 然后 archivereader.py 应用将读取这些 blob，并为每个设备创建一个附加文件，然后将数据写入到 .csv 文件中。\r \r 将要完成的任务\r \r 1. 使用 Azure 门户创建 Azure Blob 存储帐户及其中的 blob 容器。\r 2. 使用 Azure 门户创建事件中心命名空间。\r 3. 使用 Azure 门户创建启用了存档功能的事件中心。\r 4. 使用 Python 脚本将数据发送到事件中心。\r 5. 使用另一个 Python 脚本从存档中读取文件并处理这些文件。\r \r 先决条件\r \r - Python 2.7.x\r - Azure 订阅\r - 活动的[事件中心命名空间和事件中心](event-hubs-create.md)。\r \r [!INCLUDE [create-account-note](../../includes/create-account-note.md)]\r \r ## 创建 Azure 存储帐户\r <a name=\"create-an-azure-storage-account\" ></a>\r \r 1. 登录到 [Azure 门户][Azure portal]。\r 2. 在门户的左侧导航窗格中，依次单击“新建”、“存储”和“存储帐户”。\r 3. 完成“存储帐户”边栏选项卡中的字段，然后单击“创建”。\r \r    ![][1]\r 4. 看到“部署成功”消息后，单击新存储帐户名，然后在“概要”边栏选项卡中单击“Blob”。 “Blob 服务”边栏选项卡打开时，单击顶部的“+ 容器”。 将容器命名为“archive”，然后关闭“Blob 服务”边栏选项卡。\r 5. 单击左侧边栏选项卡中的“访问密钥”，复制存储帐户名称和 **key1** 的值。 将这些值保存到记事本或其他临时位置。\r \r ## 创建用于将事件发送到事件中心的 Python 脚本\r <a name=\"create-a-python-script-to-send-events-to-your-event-hub\" ></a>\r \r 1. 打开常用的 Python 编辑器，如 [Visual Studio Code][Visual Studio Code]。\r 2. 创建名为 **sender.py**的脚本。 此脚本将向事件中心发送 200 个事件。 它们是以 JSON 格式发送的简单环境读数。\r 3. 将以下代码粘贴到 sender.py 中：\r \r     ```python\r     import uuid\r     import datetime\r     import random\r     import json\r     from azure.servicebus import ServiceBusService\r \r     sbs = ServiceBusService(service_namespace='INSERT YOUR NAMESPACE NAME', shared_access_key_name='RootManageSharedAccessKey', shared_access_key_value='INSERT YOUR KEY')\r     devices = []\r     for x in range(0, 10):\r        devices.append(str(uuid.uuid4()))\r \r     for y in range(0,20):\r        for dev in devices:\r            reading = {'id': dev, 'timestamp': str(datetime.datetime.utcnow()), 'uv': random.random(), 'temperature': random.randint(70, 100), 'humidity': random.randint(70, 100)}\r            s = json.dumps(reading)\r            sbs.send_event('INSERT YOUR EVENT HUB NAME', s)\r        print y\r     ```\r 4. 更新前面的代码，使用在创建事件中心命名空间时获取的命名空间名称、密钥值和事件中心名称。\r \r ## 创建用于读取存档文件的 Python 脚本\r <a name=\"create-a-python-script-to-read-your-archive-files\" ></a>\r \r 1. 填写边栏选项卡，然后单击“创建” 。\r 2. 创建名为 **archivereader.py**的脚本。 此脚本将读取存档文件，并为每个设备创建一个文件，用于仅写入该设备的数据。\r 3. 将以下代码粘贴到 archivereader.py 中：\r \r     ```python\r     import os\r     import string\r     import json\r     import avro.schema\r     from avro.datafile import DataFileReader, DataFileWriter\r     from avro.io import DatumReader, DatumWriter\r     from azure.storage.blob import BlockBlobService\r \r     def processBlob(filename):\r        reader = DataFileReader(open(filename, 'rb'), DatumReader())\r        dict = {}\r        for reading in reader:\r            parsed_json = json.loads(reading[\"Body\"])\r            if not 'id' in parsed_json:\r                return\r            if not dict.has_key(parsed_json['id']):\r            list = []\r            dict[parsed_json['id']] = list\r        else:\r            list = dict[parsed_json['id']]\r            list.append(parsed_json)\r        reader.close()\r        for device in dict.keys():\r            deviceFile = open(device + '.csv', \"a\")\r            for r in dict[device]:\r                deviceFile.write(\", \".join([str(r[x]) for x in r.keys()])+'\\n')\r \r     def startProcessing(accountName, key, container):\r        print 'Processor started using path: ' + os.getcwd()\r        block_blob_service = BlockBlobService(account_name=accountName, account_key=key)\r        generator = block_blob_service.list_blobs(container)\r        for blob in generator:\r            if blob.properties.content_length != 0:\r                print('Downloaded a non empty blob: ' + blob.name)\r                cleanName = string.replace(blob.name, '/', '_')\r                block_blob_service.get_blob_to_path(container, blob.name, cleanName)\r                processBlob(cleanName)\r                os.remove(cleanName)\r            block_blob_service.delete_blob(container, blob.name)\r     startProcessing('YOUR STORAGE ACCOUNT NAME', 'YOUR KEY', 'archive')\r     ```\r 4. 请务必在调用 `startProcessing`时粘贴存储帐户名称和密钥的相应值。\r \r ## 运行脚本\r <a name=\"run-the-scripts\" ></a>\r \r 1. 打开其路径中包含 Python 的命令提示符，然后运行以下命令，安装 Python 必备组件包：\r \r     ```\r     pip install azure-storage\r     pip install azure-servicebus\r     pip install avro\r     ```\r \r     如果使用的是早期版本的 Azure 存储或 Azure，可能需要使用 **-upgrade** 选项\r \r     还可能需要运行以下命令（在大多数系统上不必要）：\r \r     ```\r     pip install cryptography\r     ```\r 2.  将目录更改到保存 sender.py 和 archivereader.py 的位置，然后运行以下命令：\r \r     ```\r     start python sender.py\r     ```\r \r     这将启动一个新的 Python 进程，用于运行发送程序。\r 3. 现在等待几分钟让存档运行。 然后，在原始命令窗口中键入以下命令：\r \r     ```\r     python archivereader.py\r     ```\r \r     此存档处理器使用本地目录下载存储帐户/容器中的所有 blob。 它将处理任何不为空的内容，并将结果以 .csv 文件形式写入到本地目录。\r \r ## 后续步骤\r <a name=\"next-steps\" ></a>\r \r 访问以下链接可以了解有关事件中心的详细信息：\r \r * [事件中心存档概述][Overview of Event Hubs Archive]\r * [使用事件中心的完整示例应用程序][sample application that uses Event Hubs]。\r * [使用事件中心扩大事件处理][Scale out Event Processing with Event Hubs] 示例。\r * [事件中心概述][Event Hubs overview]\r \r [Azure portal]: https://portal.azure.cn/\r [Overview of Event Hubs Archive]: event-hubs-archive-overview.md\r [1]: ./media/event-hubs-archive-python/event-hubs-python1.png\r [About Azure storage accounts]: ../storage/storage-create-storage-account.md\r [Visual Studio Code]: https://code.visualstudio.com/\r [Event Hubs overview]: event-hubs-overview.md\r [sample application that uses Event Hubs]: https://code.msdn.microsoft.com/Service-Bus-Event-Hub-286fd097\r [Scale out Event Processing with Event Hubs]: https://code.msdn.microsoft.com/Service-Bus-Event-Hub-45f43fc3"}