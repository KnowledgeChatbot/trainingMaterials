{"Title":"通过 JDBC 驱动程序查询 Hive - Azure HDInsight","Description":"使用 Java 应用程序中的 JDBC 驱动程序将 Hive 查询提交到 HDInsight 上的 Hadoop。 以编程方式以及通过 SQuirrel SQL 客户端进行连接。","Content":"# <a name=\"query-hive-through-the-jdbc-driver-in-hdinsight\"></a>在 HDInsight 中通过 JDBC 驱动程序查询 Hive\r \r [!INCLUDE [ODBC-JDBC-selector](../../../includes/hdinsight-selector-odbc-jdbc.md)]\r \r 了解如何使用 Java 应用程序中的 JDBC 驱动程序将 Hive 查询提交到 Azure HDInsight 中的 Hadoop。 本文档中的信息演示如何以编程方式从 SQuirrel SQL 客户端进行连接。\r \r 有关 Hive JDBC 接口的详细信息，请参阅 [HiveJDBCInterface](https://cwiki.apache.org/confluence/display/Hive/HiveJDBCInterface)。\r \r ## <a name=\"prerequisites\"></a>先决条件\r \r * HDInsight 群集上的 Hadoop。 可以使用基于 Linux 或基于 Windows 的群集。\r \r   > [!IMPORTANT]\r   > Linux 是在 HDInsight 3.4 版或更高版本上使用的唯一操作系统。 有关详细信息，请参阅 [HDInsight 3.3 停用](../hdinsight-component-versioning.md#hdinsight-windows-retirement)。\r \r * [SQuirreL SQL](http://squirrel-sql.sourceforge.net/)。 SQuirreL 是 JDBC 客户端应用程序。\r \r * [Java 开发人员工具包 (JDK) 版本 7](https://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html) 或更高版本。\r \r * [Apache Maven](https://maven.apache.org)。 Maven 是适用于 Java 项目的项目生成系统，可供与本文相关的项目使用。\r \r ## <a name=\"jdbc-connection-string\"></a>JDBC 连接字符串\r \r JDBC 通过 443 连接到 Azure 上的 HDInsight 群集，并使用 SSL 保护通信安全。 公用网关（群集位于其后）会将通信重定向到 HiveServer2 实际进行侦听的端口。 以下连接字符串显示要用于 HDInsight 的格式：\r \r     jdbc:hive2://CLUSTERNAME.azurehdinsight.cn:443/default;transportMode=http;ssl=true;httpPath=/hive2\r \r 将 `CLUSTERNAME` 替换为 HDInsight 群集的名称。\r \r ## <a name=\"authentication\"></a>身份验证\r \r 建立连接时，必须使用 HDInsight 群集管理员名称和密码对群集网关进行身份验证。 从 JDBC 客户端（如 SQuirreL SQL）进行连接时，必须在客户端设置中输入管理员名称和密码。\r \r 从 Java 应用程序建立连接时，必须使用该名称和密码。 例如，以下 Java 代码使用连接字符串、管理员名称和密码打开新连接：\r \r ```java\r DriverManager.getConnection(connectionString,clusterAdmin,clusterPassword);\r ```\r \r ## <a name=\"connect-with-squirrel-sql-client\"></a>使用 SQuirreL SQL 客户端进行连接\r \r SQuirreL SQL 是一个 JDBC 客户端，可用于通过 HDInsight 群集远程运行 Hive 查询。 以下步骤假设已安装 SQuirreL SQL。\r \r 1. 从 HDInsight 群集复制 Hive JDBC 驱动程序。\r \r     * 对于基于 Linux 的 HDInsight 群集版本 3.5 或 3.6，请使用以下步骤来下载需要的 jar 文件。\r \r         1. 创建一个用于包含文件的目录。 例如， `mkdir hivedriver`。\r \r         2. 从命令行，使用以下命令从 HDInsight 群集复制文件：\r \r             ```bash\r             scp USERNAME@CLUSTERNAME:/usr/hdp/current/hadoop-client/hadoop-common.jar .\r             scp USERNAME@CLUSTERNAME:/usr/hdp/current/hadoop-client/hadoop-auth.jar .\r             scp USERNAME@CLUSTERNAME:/usr/hdp/current/hadoop-client/lib/log4j-*.jar .\r             scp USERNAME@CLUSTERNAME:/usr/hdp/current/hadoop-client/lib/slf4j-*.jar .\r             scp USERNAME@CLUSTERNAME:/usr/hdp/current/hive-client/lib/hive-*-1.2*.jar .\r             scp USERNAME@CLUSTERNAME:/usr/hdp/current/hive-client/lib/httpclient-*.jar .\r             scp USERNAME@CLUSTERNAME:/usr/hdp/current/hive-client/lib/httpcore-*.jar .\r             scp USERNAME@CLUSTERNAME:/usr/hdp/current/hive-client/lib/libthrift-*.jar .\r             scp USERNAME@CLUSTERNAME:/usr/hdp/current/hive-client/lib/libfb*.jar .\r             scp USERNAME@CLUSTERNAME:/usr/hdp/current/hive-client/lib/commons-logging-*.jar .\r             ```\r \r             将 `USERNAME` 替换为群集的 SSH 用户帐户名。 将 `CLUSTERNAME` 替换为 HDInsight 群集名称。\r \r     * 对于 **基于 Windows 的 HDInsight**，请使用以下步骤下载 jar 文件。\r \r         1. 有 Azure 门户中，选择 HDInsight 群集，然后选择“远程桌面”图标。\r \r             ![“远程桌面”图标](./media/apache-hadoop-connect-hive-jdbc-driver/remotedesktopicon.png)\r \r         2. 在远程桌面部分中，选择“连接”按钮连接到群集。 如果未启用远程桌面，请使用表单提供用户名和密码，并选择“启用”为群集启用远程桌面  。\r \r             ![远程桌面部分](./media/apache-hadoop-connect-hive-jdbc-driver/remotedesktopblade.png)\r \r             选择“连接”后，会下载 .RDP 文件。 使用此文件来启动远程桌面客户端。 出现提示时，使用输入的用户名和密码进行远程桌面访问。\r \r         3. 连接后，将以下文件从远程桌面会话复制到本地计算机上。 将其置于名为 `hivedriver` 的本地目录中。\r \r             * C:\\apps\\dist\\hive-0.14.0.2.2.9.1-7\\lib\\hive-jdbc-0.14.0.2.2.9.1-7-standalone.jar\r             * C:\\apps\\dist\\hadoop-2.6.0.2.2.9.1-7\\share\\hadoop\\common\\hadoop-common-2.6.0.2.2.9.1-7.jar\r             * C:\\apps\\dist\\hadoop-2.6.0.2.2.9.1-7\\share\\hadoop\\common\\lib\\hadoop-auth-2.6.0.2.2.9.1-7.jar\r \r             > [!NOTE]\r             > 群集的路径和文件名中包含的版本号可能会有所不同。\r \r         4. 文件复制完成后，断开远程桌面会话的连接。\r \r 2. 启动 SQuirreL SQL 应用程序。 在窗口左侧中，选择“驱动程序”。\r \r     ![窗口左侧的“驱动程序”选项卡](./media/apache-hadoop-connect-hive-jdbc-driver/squirreldrivers.png)\r \r 3. 从“驱动程序”对话框顶部的图标中，选择 **+** 图标创建驱动程序。\r \r     ![驱动程序图标](./media/apache-hadoop-connect-hive-jdbc-driver/driversicons.png)\r \r 4. 在“添加驱动程序”对话框中，添加以下信息：\r \r     * **名称**：Hive\r     * **示例 URL**：`jdbc:hive2://localhost:443/default;transportMode=http;ssl=true;httpPath=/hive2`\r     * **额外类路径**：使用“添加”按钮添加之前下载的 jar 文件\r     * **类名**：org.apache.hive.jdbc.HiveDriver\r \r    ![添加驱动程序对话框](./media/apache-hadoop-connect-hive-jdbc-driver/adddriver.png)\r \r    单击“确定”保存这些设置。\r \r 5. 在 SQuirreL SQL 窗口左侧，选择“别名”。 然后单击 **+** 图标创建连接别名。\r \r     ![添加新的别名](./media/apache-hadoop-connect-hive-jdbc-driver/aliases.png)\r \r 6. 将以下值用于“添加别名”对话框。\r \r     * **名称**：Hive on HDInsight\r \r     * **驱动程序**：使用下拉列表选择 **Hive** 驱动程序\r \r     * **URL**：jdbc:hive2://CLUSTERNAME.azurehdinsight.cn:443/default;transportMode=http;ssl=true;httpPath=/hive2\r \r         将 **CLUSTERNAME** 替换为 HDInsight 群集名。\r \r     * **用户名**：HDInsight 群集的群集登录帐户名。 默认为 `admin`。\r \r     * **密码**：群集登录帐户的密码。\r \r  ![添加别名对话框](./media/apache-hadoop-connect-hive-jdbc-driver/addalias.png)\r \r     使用“测试”按钮验证连接是否有效。 出现“连接到: Hive on HDInsight”对话框时，选择“连接”执行测试。 如果测试成功，将会显示“连接成功”对话框。 如果发生错误，请参阅[故障排除](#troubleshooting)。\r \r     若要保存连接别名，请使用“添加别名”对话框底部的“确定”按钮。\r \r 7. 在 SQuirreL SQL 顶部的“连接到”下拉列表中，选择“Hive on HDInsight”。 出现提示时，选择“连接”。\r \r     ![连接对话框](./media/apache-hadoop-connect-hive-jdbc-driver/connect.png)\r \r 8. 连接后，在 SQL 查询对话框中输入以下查询，然后选择“运行”图标。 结果区域会显示查询的结果。\r \r         select * from hivesampletable limit 10;\r \r     ![sql 查询对话框，其中包括结果](./media/apache-hadoop-connect-hive-jdbc-driver/sqlquery.png)\r \r ## <a name=\"connect-from-an-example-java-application\"></a>从 Java 应用程序示例进行连接\r \r 使用 Java 客户端查询 Hive on HDInsight 的示例位于 [https://github.com/Azure-Samples/hdinsight-java-hive-jdbc](https://github.com/Azure-Samples/hdinsight-java-hive-jdbc)。 按照存储库中的说明生成并运行该示例。\r \r >[!NOTE]\r > 此示例是针对全球 Azure 编写。 对于 Azure 中国区，需要在连接字符串中将“azurehdinsight.net”替换为“azurehdinsight.cn”。\r \r ## <a name=\"troubleshooting\"></a>故障排除\r \r ### <a name=\"unexpected-error-occurred-attempting-to-open-an-sql-connection\"></a>尝试打开 SQL 连接时发生意外错误\r \r [!INCLUDE [hdinsight-linux-acn-version.md](../../../includes/hdinsight-linux-acn-version.md)]\r \r **症状**：连接到 HDInsight 群集版本 3.3 或更高版本时，可能会遇到意外错误。 此错误的堆栈跟踪的开头为以下行：\r \r ```java\r java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.NoSuchMethodError: org.apache.commons.codec.binary.Base64.<init>(I)V\r at java.util.concurrent.FutureTas...(FutureTask.java:122)\r at java.util.concurrent.FutureTask.get(FutureTask.java:206)\r ```\r \r **可能的原因**：此错误由 SQuirreL 随附的较旧版本 commons-codec.jar 文件引起。\r \r **解决方法**：若要解决此错误，请使用以下步骤：\r \r 1. 从 HDInsight 群集下载 commons-codec jar 文件。\r \r         scp USERNAME@CLUSTERNAME:/usr/hdp/current/hive-client/lib/commons-codec*.jar ./commons-codec.jar\r \r 2. 退出 SQuirreL，并转到系统上安装 SQuirreL 的目录。 在 SquirreL 目录的 `lib` 目录下，将现有的 commons-codec.jar 替换为从 HDInsight 群集下载的文件。\r \r 3. 重新启动 SQuirreL。 连接到 HDInsight 上的 Hive 时，应不再会出现该错误。\r \r ## <a name=\"next-steps\"></a>后续步骤\r \r 现在，已了解如何将 JDBC 与 Hive 配合使用，请使用以下链接学习 Azure HDInsight 的其他用法。\r \r * [在 Azure HDInsight 中使用 Zeppelin 运行 Hive 查询](../hdinsight-connect-hive-zeppelin.md)。\r * [使用 Microsoft Hive ODBC 驱动程序将 Excel 连接到 HDInsight](apache-hadoop-connect-excel-hive-odbc-driver.md)。\r * [使用 Power Query 将 Excel 连接到 Hadoop](apache-hadoop-connect-excel-power-query.md)。\r * [使用针对 Visual Studio 的 Data Lake 工具连接到 Azure HDInsight 并运行 Hive 查询](apache-hadoop-visual-studio-tools-get-started.md)。\r * [使用用于 Visual Studio Code 的 Azure HDInsight 工具](../hdinsight-for-vscode.md)。\r * [将数据上传到 HDInsight](../hdinsight-upload-data.md)\r * [将 Hive 与 HDInsight 配合使用](hdinsight-use-hive.md)\r * [将 Pig 与 HDInsight 配合使用](hdinsight-use-pig.md)\r * [将 MapReduce 作业与 HDInsight 配合使用](hdinsight-use-mapreduce.md)\r \r \r \r <!--Update_Description: update wording and link references-->"}