{"Title":"人脸 API C# 教程","Description":"创建一个使用认知服务情感 API 并通过定格图像中的人脸来检测人脸的简单 Windows 应用。","Content":"# <a name=\"getting-started-with-face-api-in-c35-tutorial\"></a>C&#35; 中的人脸 API 入门教程\r \r 在本教程中，我们将创建一个使用人脸 API 的 WPF Windows 应用程序。 该应用程序可检测图像中的人脸，围绕每个人脸绘制一个框架，并在状态栏上显示人脸的说明。\r \r ![GettingStartCSharpScreenshot](../Images/getting-started-cs-detected.png)\r \r ## <a name=\"Preparation\"></a>准备工作\r \r 若要使用本教程，需满足以下先决条件：\r \r - 确保已安装 Visual Studio 2015 或更高版本。\r \r ## <a name=\"step1\"></a>步骤 1：订阅人脸 API 并获取订阅密钥\r \r 在使用人脸 API 之前，必须在 Azure 门户中注册以订阅人脸 API。 在本教程中，可以使用主要或辅助订阅密钥。\r \r ## <a name=\"step2\"></a>步骤 2：创建 Visual Studio 解决方案\r \r 此步骤创建一个 Windows WPF 应用程序项目，以创建一个基本应用程序来选择和显示图像。 按照以下说明操作：\r \r 1. 打开 Visual Studio。\r 1. 在“文件”菜单中，依次单击“新建”、“项目”。\r 1. 在“新建项目”对话框中为应用程序选择“WPF”。\r \r    在 Visual Studio 2015 中，展开“已安装”&gt;“模板”&gt;“Visual C#”&gt;“Windows”&gt;“经典桌面”，&gt; 选择“WPF 应用程序”。\r \r    在 Visual Studio 2017 中，展开“已安装”&gt;“模板”&gt;“Visual C#”&gt;“Windows经典桌面”，&gt; 选择“WPF 应用(.NET Framework)”。\r 1. 将应用程序命名为 **FaceTutorial**，单击“确定”。\r \r    ![“新建项目”对话框，其中已选择“WPF 应用程序”](../Images/vs2017-new-project.png)\r \r 1. 找到“解决方案资源管理器”，右键单击自己的项目（在本例中为 **FaceTutorial**），再单击“管理 NuGet 包”。\r 1. 在“NuGet 包管理器”窗口中，选择“nuget.org”作为包源。\r 1. 搜索 **Newtonsoft.Json**，单击“安装”。 （在 Visual Studio 2017 中，请先单击“浏览”选项卡，再单击“搜索”）。\r \r    ![GettingStartCSharpPackageManager](../Images/install-nsoft-json.png)\r \r ## <a name=\"step3\"></a>步骤 3：配置人脸 API 客户端库\r \r 人脸 API 是可以通过 HTTPS REST 请求调用的云 API。 为了便于在 .NET 应用程序中使用，有一个 .NET 客户端库可封装人脸 API REST 请求。 此示例使用客户端库来简化操作。\r \r 遵照以下说明配置客户端库：\r \r 1. 在“解决方案资源管理器”中，右键单击自己的项目（在本例中为 **FaceTutorial**），再单击“管理 NuGet 包”。\r 1. 在“NuGet 包管理器”窗口中，选择“nuget.org”作为包源。\r 1. 搜索 **Microsoft.ProjectOxford.Face**，单击“安装”。 （在 Visual Studio 2017 中，请先单击“浏览”选项卡，再单击“搜索”）。\r \r    ![GettingStartCSharpPackageManagerSDK](../Images/install-project-oxford-face.png)\r \r 1. 在“解决方案资源管理器”中检查项目引用。 安装成功时，会自动添加引用 **Microsoft.ProjectOxford.Common**、**Microsoft.ProjectOxford.Face** 和 **Newtonsoft.Json**。\r \r    ![GetStartedCSharp-CheckInstrallation.png](../Images/GetStartedCSharp-CheckInstallation.png)\r \r ## <a name=\"step3\"></a>步骤 4：复制并粘贴初始代码\r \r 1. 打开 MainWindow.xaml，将现有代码替换为以下代码，以创建窗口 UI：\r \r     ```xml\r     <Window x:Class=\"FaceTutorial.MainWindow\"\r             xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\r             xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\r             Title=\"MainWindow\" Height=\"700\" Width=\"960\">\r         <Grid x:Name=\"BackPanel\">\r             <Image x:Name=\"FacePhoto\" Stretch=\"Uniform\" Margin=\"0,0,0,50\" MouseMove=\"FacePhoto_MouseMove\" />\r             <DockPanel DockPanel.Dock=\"Bottom\">\r                 <Button x:Name=\"BrowseButton\" Width=\"72\" Height=\"20\" VerticalAlignment=\"Bottom\" HorizontalAlignment=\"Left\"\r                         Content=\"Browse...\"\r                         Click=\"BrowseButton_Click\" />\r                 <StatusBar VerticalAlignment=\"Bottom\">\r                     <StatusBarItem>\r                         <TextBlock Name=\"faceDescriptionStatusBar\" />\r                     </StatusBarItem>\r                 </StatusBar>\r             </DockPanel>\r         </Grid>\r     </Window>\r     ```\r \r 1. 打开 MainWindow.xaml.cs，将现有代码替换为以下代码：\r \r     ```csharp\r     using System;\r     using System.Collections.Generic;\r     using System.IO;\r     using System.Text;\r     using System.Threading.Tasks;\r     using System.Windows;\r     using System.Windows.Input;\r     using System.Windows.Media;\r     using System.Windows.Media.Imaging;\r     using Microsoft.ProjectOxford.Common.Contract;\r     using Microsoft.ProjectOxford.Face;\r     using Microsoft.ProjectOxford.Face.Contract;\r \r     namespace FaceTutorial\r     {\r         public partial class MainWindow : Window\r         {\r             // Replace the first parameter with your valid subscription key.\r   \r             private readonly IFaceServiceClient faceServiceClient =\r                 new FaceServiceClient(\"_key_\", \"https://api.cognitive.azure.cn/face/v1.0\");\r \r             Face[] faces;                   // The list of detected faces.\r             String[] faceDescriptions;      // The list of descriptions for the detected faces.\r             double resizeFactor;            // The resize factor for the displayed image.\r             \r             public MainWindow()\r             {\r                 InitializeComponent();\r             }\r             \r             // Displays the image and calls Detect Faces.\r \r             private void BrowseButton_Click(object sender, RoutedEventArgs e)\r             {\r                 // Get the image file to scan from the user.\r                 var openDlg = new Microsoft.Win32.OpenFileDialog();\r \r                 openDlg.Filter = \"JPEG Image(*.jpg)|*.jpg\";\r                 bool? result = openDlg.ShowDialog(this);\r \r                 // Return if canceled.\r                 if (!(bool)result)\r                 {\r                     return;\r                 }\r \r                 // Display the image file.\r                 string filePath = openDlg.FileName;\r \r                 Uri fileUri = new Uri(filePath);\r                 BitmapImage bitmapSource = new BitmapImage();\r \r                 bitmapSource.BeginInit();\r                 bitmapSource.CacheOption = BitmapCacheOption.None;\r                 bitmapSource.UriSource = fileUri;\r                 bitmapSource.EndInit();\r \r                 FacePhoto.Source = bitmapSource;\r             }\r             \r             // Displays the face description when the mouse is over a face rectangle.\r \r             private void FacePhoto_MouseMove(object sender, MouseEventArgs e)\r             {\r             }\r         }\r     }\r     ```\r \r 1. 插入订阅密钥并验证区域。\r \r     在 MainWindow.xaml.cs 文件中找到此行（第 28 和 29 行）：\r \r     ```csharp\r     private readonly IFaceServiceClient faceServiceClient =\r             new FaceServiceClient(\"_key_\", \"https://api.cognitive.azure.cn/face/v1.0\");\r     ```\r \r     将第一个参数中的 `_key_` 替换为在步骤 1 中获取的人脸 API 订阅密钥。\r \r 现在，应用可以浏览并在窗口中显示照片。\r \r ![GettingStartCSharpUI](../Images/getting-started-cs-ui.png)\r \r ## <a name=\"step4\"></a>步骤 5：上传图像以检测人脸\r \r 检测人脸的最简便方法是上传图像文件后直接调用[人脸 - 检测](https://dev.cognitive.azure.cn/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236) API。\r 使用客户端库时，可以使用 FaceServiceClient 的异步方法 DetectAsync 实现此目的。\r 每个返回的人脸包含一个指示人脸位置的矩形，以及一系列可选人脸属性。\r \r 在 **MainWindow** 类中插入以下代码：\r \r ```csharp\r // Uploads the image file and calls Detect Faces.\r \r private async Task<Face[]> UploadAndDetectFaces(string imageFilePath)\r {\r     // The list of Face attributes to return.\r     IEnumerable<FaceAttributeType> faceAttributes =\r         new FaceAttributeType[] { FaceAttributeType.Gender, FaceAttributeType.Age, FaceAttributeType.Smile, FaceAttributeType.Emotion, FaceAttributeType.Glasses, FaceAttributeType.Hair };\r \r     // Call the Face API.\r     try\r     {\r         using (Stream imageFileStream = File.OpenRead(imageFilePath))\r         {\r             Face[] faces = await faceServiceClient.DetectAsync(imageFileStream, returnFaceId: true, returnFaceLandmarks:false, returnFaceAttributes: faceAttributes);\r             return faces;\r         }\r     }\r     // Catch and display Face API errors.\r     catch (FaceAPIException f)\r     {\r         MessageBox.Show(f.ErrorMessage, f.ErrorCode);\r         return new Face[0];\r     }\r     // Catch and display all other errors.\r     catch (Exception e)\r     {\r         MessageBox.Show(e.Message, \"Error\");\r         return new Face[0];\r     }\r }\r ```\r \r ## <a name=\"step5\"></a>步骤 6：标记图像中的人脸\r \r 此步骤将前面的所有步骤合并，并标记图像中检测到的人脸。\r \r 在 **MainWindow.xaml.cs** 中，将“async”修饰符添加到 **BrowseButton_Click** 方法：\r \r ```csharp\r private async void BrowseButton_Click(object sender, RoutedEventArgs e)\r ```\r \r 在 **BrowseButton_Click** 事件处理程序的末尾插入以下代码：\r \r ```csharp\r // Detect any faces in the image.\r Title = \"Detecting...\";\r faces = await UploadAndDetectFaces(filePath);\r Title = String.Format(\"Detection Finished. {0} face(s) detected\", faces.Length);\r \r if (faces.Length > 0)\r {\r     // Prepare to draw rectangles around the faces.\r     DrawingVisual visual = new DrawingVisual();\r     DrawingContext drawingContext = visual.RenderOpen();\r     drawingContext.DrawImage(bitmapSource,\r         new Rect(0, 0, bitmapSource.Width, bitmapSource.Height));\r     double dpi = bitmapSource.DpiX;\r     resizeFactor = 96 / dpi;\r     faceDescriptions = new String[faces.Length];\r \r     for (int i = 0; i < faces.Length; ++i)\r     {\r         Face face = faces[i];\r \r         // Draw a rectangle on the face.\r         drawingContext.DrawRectangle(\r             Brushes.Transparent,\r             new Pen(Brushes.Red, 2),\r             new Rect(\r                 face.FaceRectangle.Left * resizeFactor,\r                 face.FaceRectangle.Top * resizeFactor,\r                 face.FaceRectangle.Width * resizeFactor,\r                 face.FaceRectangle.Height * resizeFactor\r                 )\r         );\r \r         // Store the face description.\r         faceDescriptions[i] = FaceDescription(face);\r     }\r \r     drawingContext.Close();\r \r     // Display the image with the rectangle around the face.\r     RenderTargetBitmap faceWithRectBitmap = new RenderTargetBitmap(\r         (int)(bitmapSource.PixelWidth * resizeFactor),\r         (int)(bitmapSource.PixelHeight * resizeFactor),\r         96,\r         96,\r         PixelFormats.Pbgra32);\r \r     faceWithRectBitmap.Render(visual);\r     FacePhoto.Source = faceWithRectBitmap;\r \r     // Set the status bar text.\r     faceDescriptionStatusBar.Text = \"Place the mouse pointer over a face to see the face description.\";\r }\r ```\r \r ## <a name=\"step6\"></a>步骤 7：描述图像中的人脸\r \r 此步骤检查人脸属性，并生成一个用于描述人脸的字符串。 将鼠标指针悬停在人脸矩形上时，会显示此字符串。\r \r 将以下方法添加到 **MainWindow** 类，以便将人脸详细信息转换为字符串：\r \r ```csharp\r // Returns a string that describes the given face.\r \r private string FaceDescription(Face face)\r {\r     StringBuilder sb = new StringBuilder();\r \r     sb.Append(\"Face: \");\r \r     // Add the gender, age, and smile.\r     sb.Append(face.FaceAttributes.Gender);\r     sb.Append(\", \");\r     sb.Append(face.FaceAttributes.Age);\r     sb.Append(\", \");\r     sb.Append(String.Format(\"smile {0:F1}%, \", face.FaceAttributes.Smile * 100));\r \r     // Add the emotions. Display all emotions over 10%.\r     sb.Append(\"Emotion: \");\r     EmotionScores emotionScores = face.FaceAttributes.Emotion;\r     if (emotionScores.Anger     >= 0.1f) sb.Append(String.Format(\"anger {0:F1}%, \",     emotionScores.Anger * 100));\r     if (emotionScores.Contempt  >= 0.1f) sb.Append(String.Format(\"contempt {0:F1}%, \",  emotionScores.Contempt * 100));\r     if (emotionScores.Disgust   >= 0.1f) sb.Append(String.Format(\"disgust {0:F1}%, \",   emotionScores.Disgust * 100));\r     if (emotionScores.Fear      >= 0.1f) sb.Append(String.Format(\"fear {0:F1}%, \",      emotionScores.Fear * 100));\r     if (emotionScores.Happiness >= 0.1f) sb.Append(String.Format(\"happiness {0:F1}%, \", emotionScores.Happiness * 100));\r     if (emotionScores.Neutral   >= 0.1f) sb.Append(String.Format(\"neutral {0:F1}%, \",   emotionScores.Neutral * 100));\r     if (emotionScores.Sadness   >= 0.1f) sb.Append(String.Format(\"sadness {0:F1}%, \",   emotionScores.Sadness * 100));\r     if (emotionScores.Surprise  >= 0.1f) sb.Append(String.Format(\"surprise {0:F1}%, \",  emotionScores.Surprise * 100));\r \r     // Add glasses.\r     sb.Append(face.FaceAttributes.Glasses);\r     sb.Append(\", \");\r \r     // Add hair.\r     sb.Append(\"Hair: \");\r \r     // Display baldness confidence if over 1%.\r     if (face.FaceAttributes.Hair.Bald >= 0.01f)\r         sb.Append(String.Format(\"bald {0:F1}% \", face.FaceAttributes.Hair.Bald * 100));\r \r     // Display all hair color attributes over 10%.\r     HairColor[] hairColors = face.FaceAttributes.Hair.HairColor;\r     foreach (HairColor hairColor in hairColors)\r     {\r         if (hairColor.Confidence >= 0.1f)\r         {\r             sb.Append(hairColor.Color.ToString());\r             sb.Append(String.Format(\" {0:F1}% \", hairColor.Confidence * 100));\r         }\r     }\r \r     // Return the built string.\r     return sb.ToString();\r }\r ```\r \r ## <a name=\"step6\"></a>步骤 8：显示人脸说明\r \r 将 **FacePhoto_MouseMove** 方法替换为以下代码：\r \r ```csharp\r private void FacePhoto_MouseMove(object sender, MouseEventArgs e)\r {\r     // If the REST call has not completed, return from this method.\r     if (faces == null)\r         return;\r \r     // Find the mouse position relative to the image.\r     Point mouseXY = e.GetPosition(FacePhoto);\r \r     ImageSource imageSource = FacePhoto.Source;\r     BitmapSource bitmapSource = (BitmapSource)imageSource;\r \r     // Scale adjustment between the actual size and displayed size.\r     var scale = FacePhoto.ActualWidth / (bitmapSource.PixelWidth / resizeFactor);\r \r     // Check if this mouse position is over a face rectangle.\r     bool mouseOverFace = false;\r \r     for (int i = 0; i < faces.Length; ++i)\r     {\r         FaceRectangle fr = faces[i].FaceRectangle;\r         double left = fr.Left * scale;\r         double top = fr.Top * scale;\r         double width = fr.Width * scale;\r         double height = fr.Height * scale;\r \r         // Display the face description for this face if the mouse is over this face rectangle.\r         if (mouseXY.X >= left && mouseXY.X <= left + width && mouseXY.Y >= top && mouseXY.Y <= top + height)\r         {\r             faceDescriptionStatusBar.Text = faceDescriptions[i];\r             mouseOverFace = true;\r             break;\r         }\r     }\r \r     // If the mouse is not over a face rectangle.\r     if (!mouseOverFace)\r         faceDescriptionStatusBar.Text = \"Place the mouse pointer over a face to see the face description.\";\r }\r ```\r \r 运行此应用程序并浏览包含人脸的图像。 等待几秒钟，让云 API 做出响应。 之后，会看到图像中人脸上出现一个红色矩形。 将鼠标移到人脸矩形上时，状态栏上会显示人脸的说明：\r \r ![GettingStartCSharpScreenshot](../Images/getting-started-cs-detected.png)\r \r ## <a name=\"summary\"></a>摘要\r \r 本教程已介绍人脸 API 的基本使用过程，并创建了一个应用程序来显示图像中的人脸标记。 有关人脸 API 的详细信息，请参阅操作说明和 [API 参考](https://dev.cognitive.azure.cn/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236)。\r \r ## <a name=\"fullsource\"></a>完整源代码\r \r 此处提供了 WPF Windows 应用程序的完整源代码。\r \r MainWindow.xaml：\r \r ```xml\r <Window x:Class=\"FaceTutorial.MainWindow\"\r          xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\r          xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\r          Title=\"MainWindow\" Height=\"700\" Width=\"960\">\r     <Grid x:Name=\"BackPanel\">\r         <Image x:Name=\"FacePhoto\" Stretch=\"Uniform\" Margin=\"0,0,0,50\" MouseMove=\"FacePhoto_MouseMove\" />\r         <DockPanel DockPanel.Dock=\"Bottom\">\r             <Button x:Name=\"BrowseButton\" Width=\"72\" Height=\"20\" VerticalAlignment=\"Bottom\" HorizontalAlignment=\"Left\"\r                      Content=\"Browse...\"\r                      Click=\"BrowseButton_Click\" />\r             <StatusBar VerticalAlignment=\"Bottom\">\r                 <StatusBarItem>\r                     <TextBlock Name=\"faceDescriptionStatusBar\" />\r                 </StatusBarItem>\r             </StatusBar>\r         </DockPanel>\r     </Grid>\r </Window>\r ```\r \r MainWindow.xaml.cs：\r \r ```csharp\r using System;\r using System.Collections.Generic;\r using System.IO;\r using System.Text;\r using System.Threading.Tasks;\r using System.Windows;\r using System.Windows.Input;\r using System.Windows.Media;\r using System.Windows.Media.Imaging;\r using Microsoft.ProjectOxford.Common.Contract;\r using Microsoft.ProjectOxford.Face;\r using Microsoft.ProjectOxford.Face.Contract;\r \r namespace FaceTutorial\r {\r     public partial class MainWindow : Window\r     {\r         // Replace the first parameter with your valid subscription key.\r         \r         private readonly IFaceServiceClient faceServiceClient =\r             new FaceServiceClient(\"7ab0aa443a5d4b83a017a438418f21de\", \"https://api.cognitive.azure.cn/face/v1.0\");\r \r         Face[] faces;                   // The list of detected faces.\r         String[] faceDescriptions;      // The list of descriptions for the detected faces.\r         double resizeFactor;            // The resize factor for the displayed image.\r \r         public MainWindow()\r         {\r             InitializeComponent();\r         }\r \r         // Displays the image and calls Detect Faces.\r \r         private async void BrowseButton_Click(object sender, RoutedEventArgs e)\r         {\r             // Get the image file to scan from the user.\r             var openDlg = new Microsoft.Win32.OpenFileDialog();\r \r             openDlg.Filter = \"JPEG Image(*.jpg)|*.jpg\";\r             bool? result = openDlg.ShowDialog(this);\r \r             // Return if canceled.\r             if (!(bool)result)\r             {\r                 return;\r             }\r \r             // Display the image file.\r             string filePath = openDlg.FileName;\r \r             Uri fileUri = new Uri(filePath);\r             BitmapImage bitmapSource = new BitmapImage();\r \r             bitmapSource.BeginInit();\r             bitmapSource.CacheOption = BitmapCacheOption.None;\r             bitmapSource.UriSource = fileUri;\r             bitmapSource.EndInit();\r \r             FacePhoto.Source = bitmapSource;\r \r             // Detect any faces in the image.\r             Title = \"Detecting...\";\r             faces = await UploadAndDetectFaces(filePath);\r             Title = String.Format(\"Detection Finished. {0} face(s) detected\", faces.Length);\r \r             if (faces.Length > 0)\r             {\r                 // Prepare to draw rectangles around the faces.\r                 DrawingVisual visual = new DrawingVisual();\r                 DrawingContext drawingContext = visual.RenderOpen();\r                 drawingContext.DrawImage(bitmapSource,\r                     new Rect(0, 0, bitmapSource.Width, bitmapSource.Height));\r                 double dpi = bitmapSource.DpiX;\r                 resizeFactor = 96 / dpi;\r                 faceDescriptions = new String[faces.Length];\r \r                 for (int i = 0; i < faces.Length; ++i)\r                 {\r                     Face face = faces[i];\r \r                     // Draw a rectangle on the face.\r                     drawingContext.DrawRectangle(\r                         Brushes.Transparent,\r                         new Pen(Brushes.Red, 2),\r                         new Rect(\r                             face.FaceRectangle.Left * resizeFactor,\r                             face.FaceRectangle.Top * resizeFactor,\r                             face.FaceRectangle.Width * resizeFactor,\r                             face.FaceRectangle.Height * resizeFactor\r                             )\r                     );\r \r                     // Store the face description.\r                     faceDescriptions[i] = FaceDescription(face);\r                 }\r \r                 drawingContext.Close();\r \r                 // Display the image with the rectangle around the face.\r                 RenderTargetBitmap faceWithRectBitmap = new RenderTargetBitmap(\r                     (int)(bitmapSource.PixelWidth * resizeFactor),\r                     (int)(bitmapSource.PixelHeight * resizeFactor),\r                     96,\r                     96,\r                     PixelFormats.Pbgra32);\r \r                 faceWithRectBitmap.Render(visual);\r                 FacePhoto.Source = faceWithRectBitmap;\r \r                 // Set the status bar text.\r                 faceDescriptionStatusBar.Text = \"Place the mouse pointer over a face to see the face description.\";\r             }\r         }\r \r         // Displays the face description when the mouse is over a face rectangle.\r \r         private void FacePhoto_MouseMove(object sender, MouseEventArgs e)\r         {\r             // If the REST call has not completed, return from this method.\r             if (faces == null)\r                 return;\r \r             // Find the mouse position relative to the image.\r             Point mouseXY = e.GetPosition(FacePhoto);\r \r             ImageSource imageSource = FacePhoto.Source;\r             BitmapSource bitmapSource = (BitmapSource)imageSource;\r \r             // Scale adjustment between the actual size and displayed size.\r             var scale = FacePhoto.ActualWidth / (bitmapSource.PixelWidth / resizeFactor);\r \r             // Check if this mouse position is over a face rectangle.\r             bool mouseOverFace = false;\r \r             for (int i = 0; i < faces.Length; ++i)\r             {\r                 FaceRectangle fr = faces[i].FaceRectangle;\r                 double left = fr.Left * scale;\r                 double top = fr.Top * scale;\r                 double width = fr.Width * scale;\r                 double height = fr.Height * scale;\r \r                 // Display the face description for this face if the mouse is over this face rectangle.\r                 if (mouseXY.X >= left && mouseXY.X <= left + width && mouseXY.Y >= top && mouseXY.Y <= top + height)\r                 {\r                     faceDescriptionStatusBar.Text = faceDescriptions[i];\r                     mouseOverFace = true;\r                     break;\r                 }\r             }\r \r             // If the mouse is not over a face rectangle.\r             if (!mouseOverFace)\r                 faceDescriptionStatusBar.Text = \"Place the mouse pointer over a face to see the face description.\";\r         }\r \r         // Uploads the image file and calls Detect Faces.\r \r         private async Task<Face[]> UploadAndDetectFaces(string imageFilePath)\r         {\r             // The list of Face attributes to return.\r             IEnumerable<FaceAttributeType> faceAttributes =\r                 new FaceAttributeType[] { FaceAttributeType.Gender, FaceAttributeType.Age, FaceAttributeType.Smile, FaceAttributeType.Emotion, FaceAttributeType.Glasses, FaceAttributeType.Hair };\r \r             // Call the Face API.\r             try\r             {\r                 using (Stream imageFileStream = File.OpenRead(imageFilePath))\r                 {\r                     Face[] faces = await faceServiceClient.DetectAsync(imageFileStream, returnFaceId: true, returnFaceLandmarks: false, returnFaceAttributes: faceAttributes);\r                     return faces;\r                 }\r             }\r             // Catch and display Face API errors.\r             catch (FaceAPIException f)\r             {\r                 MessageBox.Show(f.ErrorMessage, f.ErrorCode);\r                 return new Face[0];\r             }\r             // Catch and display all other errors.\r             catch (Exception e)\r             {\r                 MessageBox.Show(e.Message, \"Error\");\r                 return new Face[0];\r             }\r         }\r \r         // Returns a string that describes the given face.\r \r         private string FaceDescription(Face face)\r         {\r             StringBuilder sb = new StringBuilder();\r \r             sb.Append(\"Face: \");\r \r             // Add the gender, age, and smile.\r             sb.Append(face.FaceAttributes.Gender);\r             sb.Append(\", \");\r             sb.Append(face.FaceAttributes.Age);\r             sb.Append(\", \");\r             sb.Append(String.Format(\"smile {0:F1}%, \", face.FaceAttributes.Smile * 100));\r \r             // Add the emotions. Display all emotions over 10%.\r             sb.Append(\"Emotion: \");\r             EmotionScores emotionScores = face.FaceAttributes.Emotion;\r             if (emotionScores.Anger >= 0.1f) sb.Append(String.Format(\"anger {0:F1}%, \", emotionScores.Anger * 100));\r             if (emotionScores.Contempt >= 0.1f) sb.Append(String.Format(\"contempt {0:F1}%, \", emotionScores.Contempt * 100));\r             if (emotionScores.Disgust >= 0.1f) sb.Append(String.Format(\"disgust {0:F1}%, \", emotionScores.Disgust * 100));\r             if (emotionScores.Fear >= 0.1f) sb.Append(String.Format(\"fear {0:F1}%, \", emotionScores.Fear * 100));\r             if (emotionScores.Happiness >= 0.1f) sb.Append(String.Format(\"happiness {0:F1}%, \", emotionScores.Happiness * 100));\r             if (emotionScores.Neutral >= 0.1f) sb.Append(String.Format(\"neutral {0:F1}%, \", emotionScores.Neutral * 100));\r             if (emotionScores.Sadness >= 0.1f) sb.Append(String.Format(\"sadness {0:F1}%, \", emotionScores.Sadness * 100));\r             if (emotionScores.Surprise >= 0.1f) sb.Append(String.Format(\"surprise {0:F1}%, \", emotionScores.Surprise * 100));\r \r             // Add glasses.\r             sb.Append(face.FaceAttributes.Glasses);\r             sb.Append(\", \");\r \r             // Add hair.\r             sb.Append(\"Hair: \");\r \r             // Display baldness confidence if over 1%.\r             if (face.FaceAttributes.Hair.Bald >= 0.01f)\r                 sb.Append(String.Format(\"bald {0:F1}% \", face.FaceAttributes.Hair.Bald * 100));\r \r             // Display all hair color attributes over 10%.\r             HairColor[] hairColors = face.FaceAttributes.Hair.HairColor;\r             foreach (HairColor hairColor in hairColors)\r             {\r                 if (hairColor.Confidence >= 0.1f)\r                 {\r                     sb.Append(hairColor.Color.ToString());\r                     sb.Append(String.Format(\" {0:F1}% \", hairColor.Confidence * 100));\r                 }\r             }\r \r             // Return the built string.\r             return sb.ToString();\r         }\r     }\r }\r ```\r \r ## <a name=\"related\"></a> 后续步骤\r \r - [Java for Android 中的人脸 API 入门](FaceAPIinJavaForAndroidTutorial.md)\r - [Python 中的人脸 API 入门](FaceAPIinPythonTutorial.md)\r \r "}