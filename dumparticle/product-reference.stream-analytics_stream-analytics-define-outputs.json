{"Title":"流分析输出：存储、分析选项","Description":"了解有关设定流分析数据输出选项（包括 Power BI）目标，用于分析结果的信息。","Content":"# <a name=\"stream-analytics-outputs-options-for-storage-analysis\"></a>流分析输出：存储、分析选项\r 创作流分析作业时，需考虑如何使用生成的数据。 如何查看流分析作业的结果？流分析作业的结果存储在何处？\r \r 为了启用多种应用程序模式，Azure 流分析提供了不同的选项来存储输出和查看分析结果。 这样可以轻松地查看作业输出，并可灵活地使用和存储作业输出，以便进行数据仓库操作和其他操作。 必须先存在作业中配置的输出，才能启动作业并开始事件的流动。 例如，如果使用 Blob 存储作为输出，该作业不会自动创建存储帐户。 在启动 ASA 作业之前，需要由用户创建该存储帐户。\r <!-- Not Available ## Azure Data Lake Store-->\r <!-- Not Available ### Authorize an Azure Data Lake Store -->\r <!-- Not Available ### Renew Data Lake Store Authorization -->\r \r ## <a name=\"sql-database\"></a>SQL 数据库\r 可以将 [Azure SQL 数据库](https://www.azure.cn/home/features/sql-database/)用作本质上为关系型数据的输出，也可以将其用于所依赖的内容在关系数据库中托管的应用程序。 流分析作业将写入到 Azure SQL 数据库的现有表中。  请注意表架构必须与字段及其正从作业输出的类型完全匹配。 [Azure SQL 数据仓库](/sql-data-warehouse/)也可以通过 SQL 数据库输出选项指定为输出（此项为预览功能）。 下表列出了属性名称和用于创建 SQL 数据库输出的属性说明。\r \r | 属性名称 | 说明 |\r | --- | --- |\r | 输出别名 |该名称是在查询中使用的友好名称，用于将查询输出定向到此数据库。 |\r | 数据库 |数据库的名称（正在向该数据库发送输出） |\r | 服务器名称 |SQL 数据库服务器名称 |\r | 用户名 |有权写入到数据库的用户名 |\r | 密码 |用于连接到数据库的密码 |\r | 表 |将写入输出的表名称。 表名称区分大小写，并且该表的架构应与字段数量以及作业输出正在生成的字段类型完全匹配。 |\r \r > [!NOTE]\r > 目前，流分析中的作业输出支持 Azure SQL 数据库产品/服务。 但是，不支持附加了数据库，运行 SQL Server 的 Azure 虚拟机。 这在将来的版本中可能会有所改变。\r > \r > \r \r ## <a name=\"blob-storage\"></a>Blob 存储\r Blob 存储提供了一种经济高效且可缩放的解决方案，用于在云中存储大量非结构化数据。  有关 Azure Blob 存储及其用法的简介，请参阅[如何使用 Blob](../storage/blobs/storage-dotnet-how-to-use-blobs.md) 处的文档。\r \r 下表列出了用于创建 blob 输出的属性名称及其说明。\r \r <table>\r <tbody>\r <tr>\r <td>属性名称</td>\r <td>说明</td>\r </tr>\r <tr>\r <td>输出别名</td>\r <td>该名称是在查询中使用的友好名称，用于将查询输出定向到此 blob 存储。</td>\r </tr>\r <tr>\r <td>存储帐户</td>\r <td>存储帐户的名称（正在向该存储帐户发送输出）。</td>\r </tr>\r <tr>\r <td>存储帐户密钥</td>\r <td>与存储帐户关联的密钥。</td>\r </tr>\r <tr>\r <td>存储容器</td>\r <td>容器对存储在 Azure Blob 服务中的 blob 进行逻辑分组。 将 blob 上传到 Blob 服务时，必须为该 blob 指定一个容器。</td>\r </tr>\r <tr>\r <td>路径前缀模式 [可选]</td>\r <td>用于编写指定容器中的 blob 的文件路径模式。 <BR> 在路径模式中，可以选择使用以下 2 个变量的一个或多个实例指定 blob 写入的频率： <BR> {date}、{time} <BR> 示例 1：cluster1/logs/{date}/{time} <BR> 示例 2：cluster1/logs/{date} <BR> <BR> 文件命名将遵循以下约定： <BR> {路径前缀模式}/schemaHashcode_Guid_Number.extension <BR> <BR> 示例输出文件： <BR> Myoutput/20170901/00/45434_gguid_1.csv <BR> Myoutput/20170901/01/45434_gguid_1.csv <BR> <BR> 另外还存在已创建新文件的情况： <BR> 1. 当前文件超出了允许的最大块数（目前为 50,000） <BR> 2. 在输出架构中进行更改 <BR> 3. 在外部或内部重启作业  </td>\r </tr>\r <tr>\r <td>日期格式 [可选]</td>\r <td>如果在前缀路径中使用日期令牌，可以选择组织文件所采用的日期格式。 示例：YYYY/MM/DD</td>\r </tr>\r <tr>\r <td>时间格式 [可选]</td>\r <td>如果在前缀路径中使用时间令牌，可指定组织文件所采用的时间格式。 目前唯一支持的值是 HH。</td>\r </tr>\r <tr>\r <td>事件序列化格式</td>\r <td>输出数据的序列化格式。  支持 JSON、CSV 和 Avro。</td>\r </tr>\r <tr>\r <td>编码</td>\r <td>如果是 CSV 或 JSON 格式，则必须指定一种编码格式。 目前只支持 UTF-8 这种编码格式。</td>\r </tr>\r <tr>\r <td>分隔符</td>\r <td>仅适用于 CSV 序列化。 流分析支持大量的常见分隔符以对 CSV 数据进行序列化。 支持的值为逗号、分号、空格、制表符和竖线。</td>\r </tr>\r <tr>\r <td>格式</td>\r <td>仅适用于 JSON 序列化。 分隔行指定了通过新行分隔各个 JSON 对象，从而格式化输出。 数组指定输出会被格式化为 JSON 对象的数组。 仅当作业停止或流分析移动到下个时间段时，才关闭此数组。 一般而言，最好使用分隔行 JSON，因为在继续写入输出文件时，无需任何特殊处理。</td>\r </tr>\r </tbody>\r </table>\r \r ## <a name=\"event-hub\"></a>事件中心\r [事件中心](https://www.azure.cn/home/features/event-hubs/)是具有高扩展性的发布-订阅事件引入器。 事件中心每秒可收集数百万个事件。  当流分析作业的输出将要成为另一个流式处理作业的输入时，可以将事件中心用作输出。\r \r 将事件中心数据流配置成输出时，需要使用几个参数。\r \r | 属性名称 | 说明 |\r | --- | --- |\r | 输出别名 |该名称是在查询中使用的友好名称，用于将查询输出定向到此事件中心。 |\r | 服务总线命名空间 |服务总线命名空间是包含一组消息传递实体的容器。 创建新的事件中心后，还创建了服务总线命名空间 |\r | 事件中心 |事件中心输出的名称 |\r | 事件中心策略名称 |可以在事件中心的“配置”选项卡上创建的共享访问策略。每个共享访问策略都有名称、所设权限以及访问密钥 |\r | 事件中心策略密钥 |用于验证对服务总线命名空间的访问权限的共享访问密钥 |\r | 分区键列 [可选] |此列包含事件中心输出的分区键。 |\r | 事件序列化格式 |输出数据的序列化格式。  支持 JSON、CSV 和 Avro。 |\r | 编码 |对于 CSV 和 JSON，目前只支持 UTF-8 这种编码格式 |\r | 分隔符 |仅适用于 CSV 序列化。 流分析支持大量的常见分隔符以对 CSV 格式的数据进行序列化。 支持的值为逗号、分号、空格、制表符和竖线。 |\r | 格式 |仅适用于 JSON 序列化。 分隔行指定了通过新行分隔各个 JSON 对象，从而格式化输出。 数组指定输出会被格式化为 JSON 对象的数组。 仅当作业停止或流分析移动到下个时间段时，才关闭此数组。 一般而言，最好使用分隔行 JSON，因为在继续写入输出文件时，无需任何特殊处理。 |\r \r \r <!-- Not Available ## Power BI-->\r \r ## <a name=\"table-storage\"></a>表存储\r [Azure 表存储](../storage/common/storage-introduction.md)提供了具有高可用性且可大规模缩放的存储，因此应用程序可以自动缩放以满足用户需求。 表存储是 Microsoft 推出的 NoSQL 键/属性存储，适用于对架构的约束性较少的结构化数据。 Azure 表存储可用于持久地存储数据，方便进行高效的检索。\r \r 下表列出了用于创建表输出的属性名称及其说明。\r \r | 属性名称 | 说明 |\r | --- | --- |\r | 输出别名 |该名称是在查询中使用的友好名称，用于将查询输出定向到此表存储。 |\r | 存储帐户 |存储帐户的名称（正在向该存储帐户发送输出）。 |\r | 存储帐户密钥 |与存储帐户关联的访问密钥。 |\r | 表名称 |表的名称。 如果表不存在，则会创建表。 |\r | 分区键 |包含分区键的输出列的名称。 分区键是某个给定表中分区的唯一标识符，分区键构成了实体主键的第一部分。 分区键是一个最大为 1 KB 的字符串值。 |\r | 行键 |包含行键的输出列的名称。 行键是某个给定分区中实体的唯一标识符。 行键构成了实体主键的第二部分。 行键是一个最大为 1 KB 的字符串值。 |\r | 批大小 |批处理操作的记录数。 通常情况下，默认值对于大多数作业来说已经足够；若要修改此设置，请参阅[表批处理操作规范](https://msdn.microsoft.com/library/microsoft.windowsazure.storage.table.tablebatchoperation.aspx)以获取详细信息。 |\r \r ## <a name=\"service-bus-queues\"></a>服务总线队列\r [服务总线队列](../service-bus-messaging/service-bus-queues-topics-subscriptions.md)为一个或多个竞争使用方提供先入先出 (FIFO) 消息传递方式。 通常情况下，接收方会按照消息添加到队列中的临时顺序来接收并处理消息，并且每条消息仅由一个消息使用方接收并处理。\r \r 下表列出了用于创建队列输出的属性名称及其说明。\r \r | 属性名称 | 说明 |\r | --- | --- |\r | 输出别名 |该名称是在查询中使用的友好名称，用于将查询输出定向到此服务总线队列。 |\r | 服务总线命名空间 |服务总线命名空间是包含一组消息传递实体的容器。 |\r | 队列名称 |服务总线队列的名称。 |\r | 队列策略名称 |在创建队列时，还可以在“队列配置”选项卡上创建共享的访问策略。每个共享访问策略都有名称、所设权限以及访问密钥。 |\r | 队列策略密钥 |用于验证对服务总线命名空间的访问权限的共享访问密钥 |\r | 事件序列化格式 |输出数据的序列化格式。  支持 JSON、CSV 和 Avro。 |\r | 编码 |对于 CSV 和 JSON，目前只支持 UTF-8 这种编码格式 |\r | 分隔符 |仅适用于 CSV 序列化。 流分析支持大量的常见分隔符以对 CSV 格式的数据进行序列化。 支持的值为逗号、分号、空格、制表符和竖线。 |\r | 格式 |仅适用于 JSON 类型。 分隔行指定了通过新行分隔各个 JSON 对象，从而格式化输出。 数组指定输出会被格式化为 JSON 对象的数组。 |\r \r ## <a name=\"service-bus-topics\"></a>服务总线主题\r 服务总线队列提供的是从发送方到接收方的一对一通信方法，而[服务总线主题](../service-bus-messaging/service-bus-queues-topics-subscriptions.md)提供的则是一对多形式的通信。\r \r 下表列出了用于创建表输出的属性名称及其说明。\r \r | 属性名称 | 说明 |\r | --- | --- |\r | 输出别名 |这个名称是在查询中使用的友好名称，用于将查询输出定向到此服务总线主题。 |\r | 服务总线命名空间 |服务总线命名空间是包含一组消息传递实体的容器。 创建新的事件中心后，还创建了服务总线命名空间 |\r | 主题名称 |主题是消息传递实体，类似于事件中心和队列。 设计用于从多个不同的设备和服务收集事件流。 在创建主题时，还会为其提供特定的名称。 发送到主题的消息在创建订阅后才会提供给用户，因此请确保主题下存在一个或多个订阅 |\r | 主题策略名称 |创建主题时，还可以在“主题配置”选项卡上创建共享的访问策略。每个共享访问策略都有名称、所设权限以及访问密钥 |\r | 主题策略密钥 |用于验证对服务总线命名空间的访问权限的共享访问密钥 |\r | 事件序列化格式 |输出数据的序列化格式。  支持 JSON、CSV 和 Avro。 |\r | 编码 |如果是 CSV 或 JSON 格式，则必须指定一种编码格式。 目前只支持 UTF-8 这种编码格式 |\r | 分隔符 |仅适用于 CSV 序列化。 流分析支持大量的常见分隔符以对 CSV 格式的数据进行序列化。 支持的值为逗号、分号、空格、制表符和竖线。 |\r \r <!-- Not Available ## Cosmos DB till 1st Sep 2017-->\r <!-- Not Available ## Azure Functions (In Preview) -->\r ## <a name=\"get-help\"></a>获取帮助\r 如需进一步的帮助，请尝试我们的 [Azure 流分析论坛](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics)\r \r ## <a name=\"next-steps\"></a>后续步骤\r 我们已经向你介绍了流分析，这是一种托管服务，适用于对物联网的数据进行流式分析。 若要了解有关此服务的详细信息，请参阅：\r \r * [Azure 流分析入门](stream-analytics-real-time-fraud-detection.md)\r * [缩放 Azure 流分析作业](stream-analytics-scale-jobs.md)\r * [Azure 流分析查询语言参考](https://msdn.microsoft.com/library/azure/dn834998.aspx)\r * [Azure 流分析管理 REST API 参考](https://msdn.microsoft.com/library/azure/dn835031.aspx)\r \r <!--Link references-->\r [stream.analytics.developer.guide]: ../stream-analytics-developer-guide.md\r [stream.analytics.scale.jobs]: stream-analytics-scale-jobs.md\r [stream.analytics.introduction]: stream-analytics-introduction.md\r [stream.analytics.get.started]: stream-analytics-real-time-fraud-detection.md\r [stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299\r [stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301\r \r <!--Update_Description: update link, wroding update-->"}