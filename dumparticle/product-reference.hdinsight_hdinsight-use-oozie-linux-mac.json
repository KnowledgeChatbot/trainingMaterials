{"Title":"在基于 Linux 的 HDInsight 中使用 Hadoop Oozie 工作流","Description":"在基于 Linux 的 HDInsight 中使用 Hadoop Oozie。 了解如何定义 Oozie 工作流，并提交 Oozie 作业。","Content":"# <a name=\"use-oozie-with-hadoop-to-define-and-run-a-workflow-on-linux-based-azure-hdinsight\"></a>在基于 Linux 的 Azure HDInsight 中将 Oozie 与 Hadoop 配合使用以定义和运行工作流\r \r [!INCLUDE [oozie-selector](../../includes/hdinsight-oozie-selector.md)]\r \r 了解如何将 Apache Oozie 与 Azure HDInsight 上的 Hadoop 配合使用。 Oozie 是一个管理 Hadoop 作业的工作流和协调系统。 Oozie 与 Hadoop 堆栈集成，并支持以下作业：\r \r * Apache MapReduce\r * Apache Pig\r * Apache Hive\r * Apache Sqoop\r \r 还可以使用 Oozie 来计划特定于某系统的作业，例如 Java 程序或 shell 脚本\r \r ## <a name=\"prerequisites\"></a>先决条件\r \r * **HDInsight 群集**：请参阅[Linux 上的 HDInsight 入门](hadoop/apache-hadoop-linux-tutorial-get-started.md)\r \r > [!IMPORTANT]\r > 本文档中的步骤需要使用 Linux 的 HDInsight 群集。 Linux 是 HDInsight 3.4 或更高版本上使用的唯一操作系统。 有关详细信息，请参阅 [HDInsight 在 Windows 上停用](hdinsight-component-versioning.md#hdinsight-windows-retirement)。\r \r ## <a name=\"example-workflow\"></a>示例工作流\r \r 本文档中使用的工作流包含两个操作。 操作是任务的定义，例如运行 Hive、Sqoop、MapReduce 或其他进程：\r \r ![工作流关系图][img-workflow-diagram]\r \r 1. Hive 操作运行 HiveQL 脚本，以从 HDInsight 随附的 **hivesampletable** 中提取记录。 每个数据行描述特定移动设备的访问。 显示的记录格式如下文所示：\r \r         8       18:54:20        en-US   Android Samsung SCH-i500        California     United States    13.9204007      0       0\r         23      19:19:44        en-US   Android HTC     Incredible      Pennsylvania   United States    NULL    0       0\r         23      19:19:46        en-US   Android HTC     Incredible      Pennsylvania   United States    1.4757422       0       1\r \r     本文档中使用的 Hive 脚本将统计每个平台（例如 Android 或 iPhone）的总访问次数，并将计数存储到新的 Hive 表中。\r \r     有关 Hive 的详细信息，请参阅[将 Hive 与 HDInsight 配合使用][hdinsight-use-hive]。\r \r 2. Sqoop 操作将新 Hive 表的内容导出到在 Azure SQL 数据库中创建的表。 有关 Sqoop 的详细信息，请参阅[将 Hadoop Sqoop 与 HDInsight 配合使用][hdinsight-use-sqoop]。\r \r > [!NOTE]\r > 有关在 HDInsight 群集上支持的 Oozie 版本，请参阅 [HDInsight 提供的 Hadoop 群集版本有哪些新增功能？][hdinsight-versions]。\r \r ## <a name=\"create-the-working-directory\"></a>创建工作目录\r \r Oozie 希望将作业所需的所有资源存储在同一个目录中。 此示例使用 wasb:///tutorials/useoozie。 若要创建此目录，请完成以下步骤：\r \r 1. 使用 SSH 连接到 HDInsight 群集：\r \r     ```bash\r     ssh sshuser@clustername-ssh.azurehdinsight.cn\r     ```\r \r     将 `sshuser` 替换为群集的 SSH 用户名。 将 `clustername` 替换为群集的名称。 有关详细信息，请参阅 [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md)（对 HDInsight 使用 SSH）。\r \r 2. 若要创建此目录，请使用以下命令：\r \r     ```bash\r     hdfs dfs -mkdir -p /tutorials/useoozie/data\r     ```\r \r     > [!NOTE]\r     > `-p` 参数用于在路径中创建所有目录。 **data** 目录用于保存 **useooziewf.hql** 脚本使用的数据。\r \r 3. 若要确保 Oozie 可以模拟用户帐户，请使用以下命令：\r \r     ```bash\r     sudo adduser username users\r     ```\r \r     将 `username` 替换为 SSH 用户名。\r \r     > [!NOTE]\r     > 可以忽略指出用户已是 `users` 组的成员的错误。\r \r ## <a name=\"add-a-database-driver\"></a>添加数据库驱动程序\r \r 由于此工作流使用 Sqoop 将数据导出到 SQL 数据库，因此必须提供用来与 SQL 数据库交互的 JDBC 驱动程序的副本。 若要将 JDBC 驱动程序复制到工作目录，请在 SSH 会话中使用以下命令：\r \r ```bash\r hdfs dfs -put /usr/share/java/sqljdbc_4.1/enu/sqljdbc*.jar /tutorials/useoozie/\r ```\r \r 如果工作流使用了其他资源，例如包含 MapReduce 应用程序的 jar，则还需要添加这些资源。\r \r ## <a name=\"define-the-hive-query\"></a>定义 Hive 查询\r \r 使用以下步骤创建用于定义查询的 Hive 查询语言 (HiveQL) 脚本。 在本文档稍后的 Oozie 工作流中要使用此查询。\r \r 1. 在 SSH 连接中，使用以下命令创建名为 `useooziewf.hql` 的文件：\r \r     ```bash\r     nano useooziewf.hql\r     ```\r \r 3. 打开 GNU nano 编辑器后，使用以下查询作为该文件的内容：\r \r     ```hiveql\r     DROP TABLE ${hiveTableName};\r     CREATE EXTERNAL TABLE ${hiveTableName}(deviceplatform string, count string) ROW FORMAT DELIMITED\r     FIELDS TERMINATED BY '\\t' STORED AS TEXTFILE LOCATION '${hiveDataFolder}';\r     INSERT OVERWRITE TABLE ${hiveTableName} SELECT deviceplatform, COUNT(*) as count FROM hivesampletable GROUP BY deviceplatform;\r     ```\r \r     脚本中使用了两个变量：\r \r     * `${hiveTableName}`：包含要创建的表的名称。\r \r     * `${hiveDataFolder}`：包含存储表数据文件的位置。\r \r     工作流定义文件（本教程中的 workflow.xml）在运行时会这些值传递到此 HiveQL 脚本。\r \r 4. 若要退出编辑器，请按 Ctrl+X。 出现提示时，请选择 `Y` 保存文件，输入 `useooziewf.hql` 作为文件名，并按 **Enter**。\r \r 5. 使用以下命令将 `useooziewf.hql` 复制到 `wasb:///tutorials/useoozie/useooziewf.hql`：\r \r     ```bash\r     hdfs dfs -put useooziewf.hql /tutorials/useoozie/useooziewf.hql\r     ```\r \r     此命令将 `useooziewf.hql` 文件存储在群集的 HDFS 兼容存储上。\r \r ## <a name=\"define-the-workflow\"></a>定义工作流\r \r Oozie 工作流定义以 Hadoop 过程定义语言（缩写为 hPDL，一种 XML 过程定义语言）编写。 使用以下步骤定义工作流：\r \r 1. 使用以下语句创建并编辑新文件：\r \r     ```bash\r     nano workflow.xml\r     ```\r \r 2. 打开 nano 编辑器后，输入以下 XML 作为文件内容：\r \r     ```xml\r     <workflow-app name=\"useooziewf\" xmlns=\"uri:oozie:workflow:0.2\">\r         <start to = \"RunHiveScript\"/>\r         <action name=\"RunHiveScript\">\r         <hive xmlns=\"uri:oozie:hive-action:0.2\">\r             <job-tracker>${jobTracker}</job-tracker>\r             <name-node>${nameNode}</name-node>\r             <configuration>\r             <property>\r                 <name>mapred.job.queue.name</name>\r                 <value>${queueName}</value>\r             </property>\r             </configuration>\r             <script>${hiveScript}</script>\r             <param>hiveTableName=${hiveTableName}</param>\r             <param>hiveDataFolder=${hiveDataFolder}</param>\r         </hive>\r         <ok to=\"RunSqoopExport\"/>\r         <error to=\"fail\"/>\r         </action>\r         <action name=\"RunSqoopExport\">\r         <sqoop xmlns=\"uri:oozie:sqoop-action:0.2\">\r             <job-tracker>${jobTracker}</job-tracker>\r             <name-node>${nameNode}</name-node>\r             <configuration>\r             <property>\r                 <name>mapred.compress.map.output</name>\r                 <value>true</value>\r             </property>\r             </configuration>\r             <arg>export</arg>\r             <arg>--connect</arg>\r             <arg>${sqlDatabaseConnectionString}</arg>\r             <arg>--table</arg>\r             <arg>${sqlDatabaseTableName}</arg>\r             <arg>--export-dir</arg>\r             <arg>${hiveDataFolder}</arg>\r             <arg>-m</arg>\r             <arg>1</arg>\r             <arg>--input-fields-terminated-by</arg>\r             <arg>\"\\t\"</arg>\r             <archive>sqljdbc41.jar</archive>\r             </sqoop>\r         <ok to=\"end\"/>\r         <error to=\"fail\"/>\r         </action>\r         <kill name=\"fail\">\r         <message>Job failed, error message[${wf:errorMessage(wf:lastErrorNode())}] </message>\r         </kill>\r         <end name=\"end\"/>\r     </workflow-app>\r     ```\r \r     该工作流中定义了两个操作：\r \r    * `RunHiveScript`：此操作是启动操作，运行 `useooziewf.hql` Hive 脚本。\r \r    * `RunSqoopExport`：此操作使用 Sqoop 将创建的数据从 Hive 脚本导出到 SQL 数据库。 仅当 `RunHiveScript` 操作成功时才运行此操作。\r \r      工作流包含多个条目，例如 `${jobTracker}`。 这些条目将替换为在作业定义中使用的值。 稍后会在本文档中创建作业定义。\r \r      另请注意 Sqoop 节中的 `<archive>sqljdbc4.jar</archive>` 条目。 该条目指示在运行此操作时 Oozie 要将此存档提供给 Sqoop 使用。\r \r 3. 若要保存文件，请按 Ctrl+X，输入 `Y`，再按 **Enter**。 \r \r 4. 使用以下命令将 `workflow.xml` 文件复制到 `/tutorials/useoozie/workflow.xml`：\r \r     ```bash\r     hdfs dfs -put workflow.xml /tutorials/useoozie/workflow.xml\r     ```\r \r ## <a name=\"create-the-database\"></a>创建数据库\r \r 若要创建 SQL 数据库，请遵循[创建 SQL 数据库](../sql-database/sql-database-get-started.md)文档中的步骤操作。 创建数据库时，请使用 `oozietest` 作为数据库名称。 此外请记下数据库服务器的名称。\r \r ### <a name=\"create-the-table\"></a>创建表\r \r > [!NOTE]\r > 有多种方法可连接到 SQL 数据库以创建表。 以下步骤从 HDInsight 群集使用 [FreeTDS](http://www.freetds.org/) 。\r \r \r 1. 使用以下命令在 HDInsight 群集上安装 FreeTDS：\r \r     ```bash\r     sudo apt-get --assume-yes install freetds-dev freetds-bin\r     ```\r \r 2. 安装 FreeTDS 后，使用以下命令连接到先前创建的 SQL 数据库服务器：\r \r     ```bash\r     TDSVER=8.0 tsql -H <serverName>.database.chinacloudapi.cn -U <sqlLogin> -P <sqlPassword> -p 1433 -D oozietest\r     ```\r \r     会收到类似于以下文本的输出：\r \r         locale is \"en_US.UTF-8\"\r         locale charset is \"UTF-8\"\r         using default charset \"UTF-8\"\r         Default database being set to oozietest\r         1>\r \r 3. 在 `1>` 提示符下，输入以下行：\r \r     ```sql\r     CREATE TABLE [dbo].[mobiledata](\r     [deviceplatform] [nvarchar](50),\r     [count] [bigint])\r     GO\r     CREATE CLUSTERED INDEX mobiledata_clustered_index on mobiledata(deviceplatform)\r     GO\r     ```\r \r     输入 `GO` 语句后，会评估前面的语句。 这些语句创建一个名为 **mobiledata** 的表，供工作流使用。\r \r     若要验证是否已创建该表，请使用以下命令：\r \r     ```sql\r     SELECT * FROM information_schema.tables\r     GO\r     ```\r \r     会看到类似于以下文本的输出：\r \r     ```\r     TABLE_CATALOG   TABLE_SCHEMA    TABLE_NAME      TABLE_TYPE\r     oozietest       dbo     mobiledata      BASE TABLE\r     ```\r \r 4. 若要退出 tsql 实用工具，请在 `1>` 提示符下输入 `exit`。\r \r ## <a name=\"create-the-job-definition\"></a>创建作业定义\r \r 作业定义说明了可在何处找到 workflow.xml。 它还说明可在何处找到工作流使用的其他文件（例如 `useooziewf.hql`）。 此外，它还定义工作流中使用的属性值以及关联的文件。\r \r 1. 若要获取默认存储的完整地址，请使用以下命令。 在下一步骤中创建的配置文件中会使用此地址。\r \r     ```bash\r     sed -n '/<name>fs.default/,/<\\/value>/p' /etc/hadoop/conf/core-site.xml\r     ```\r \r     此命令将返回类似以下 XML 的信息：\r \r     ```xml\r     <name>fs.defaultFS</name>\r     <value>wasb://mycontainer@mystorageaccount.blob.core.chinacloudapi.cn</value>\r     ```\r \r     > [!NOTE]\r     > 如果 HDInsight 群集使用 Azure 存储作为默认存储，则 `<value>` 元素内容以 `wasb://` 开头。\r \r     保存 `<value>` 元素的内容，因为下一个步骤中将使用该内容。\r \r 2. 若要创建 Oozie 作业定义配置，请使用以下命令：\r \r     ```bash\r     nano job.xml\r     ```\r \r 3. 打开 nano 编辑器后，使用以下 XML 作为该文件的内容：\r \r     ```xml\r     <?xml version=\"1.0\" encoding=\"UTF-8\"?>\r     <configuration>\r \r         <property>\r         <name>nameNode</name>\r         <value>wasb://mycontainer@mystorageaccount.blob.core.chinacloudapi.cn</value>\r         </property>\r \r         <property>\r         <name>jobTracker</name>\r         <value>headnodehost:8050</value>\r         </property>\r \r         <property>\r         <name>queueName</name>\r         <value>default</value>\r         </property>\r \r         <property>\r         <name>oozie.use.system.libpath</name>\r         <value>true</value>\r         </property>\r \r         <property>\r         <name>hiveScript</name>\r         <value>wasb://mycontainer@mystorageaccount.blob.core.chinacloudapi.cn/tutorials/useoozie/useooziewf.hql</value>\r         </property>\r \r         <property>\r         <name>hiveTableName</name>\r         <value>mobilecount</value>\r         </property>\r \r         <property>\r         <name>hiveDataFolder</name>\r         <value>wasb://mycontainer@mystorageaccount.blob.core.chinacloudapi.cn/tutorials/useoozie/data</value>\r         </property>\r \r         <property>\r         <name>sqlDatabaseConnectionString</name>\r         <value>\"jdbc:sqlserver://serverName.database.chinacloudapi.cn;user=adminLogin;password=adminPassword;database=oozietest\"</value>\r         </property>\r \r         <property>\r         <name>sqlDatabaseTableName</name>\r         <value>mobiledata</value>\r         </property>\r \r         <property>\r         <name>user.name</name>\r         <value>YourName</value>\r         </property>\r \r         <property>\r         <name>oozie.wf.application.path</name>\r         <value>wasb://mycontainer@mystorageaccount.blob.core.chinacloudapi.cn/tutorials/useoozie</value>\r         </property>\r     </configuration>\r     ```\r \r    * 将 **wasb://mycontainer@mystorageaccount.blob.core.chinacloudapi.cn** 的所有实例替换为前面收到的默认存储的值。\r \r      > [!WARNING]\r      > 如果该路径是 `wasb` 路径，则必须使用完整路径。 不要将其缩短为 `wasb:///`。\r \r    * 将 `YourName` 替换为 HDInsight 群集的登录名。\r    * 将 `serverName`、`adminLogin` 和 `adminPassword` 替换为 SQL 数据库的信息。\r \r      此文件中的大多数信息用于填充 workflow.xml 或 ooziewf.hql 文件中使用的值（例如 `${nameNode}`）。\r \r      > [!NOTE]\r      > `oozie.wf.application.path` 条目定义查找 workflow.xml 文件的位置。 此文件包含此作业运行的工作流。\r \r 5. 若要保存文件，请按 Ctrl+X，输入 `Y`，再按 **Enter**。\r \r ## <a name=\"submit-and-manage-the-job\"></a>提交和管理作业\r \r 以下步骤使用 Oozie 命令提交和管理群集上的 Oozie 工作流。 Oozie 命令是基于 [Oozie REST API](https://oozie.apache.org/docs/4.1.0/WebServicesAPI.html)的友好界面。\r \r > [!IMPORTANT]\r > 使用 Oozie 命令时，必须使用 HDInsight 头节点的 FQDN。 只能从群集访问此 FQDN，如果群集位于 Azure 虚拟网络中，则必须从同一个网络中的其他计算机来访问它。\r \r \r 1. 若要获取 Oozie 服务的 URL，请使用以下命令：\r \r     ```bash\r     sed -n '/<name>oozie.base.url/,/<\\/value>/p' /etc/oozie/conf/oozie-site.xml\r     ```\r \r     此命令返回类似以下 XML 的信息：\r \r     ```xml\r     <name>oozie.base.url</name>\r     <value>http://hn0-CLUSTERNAME.randomcharacters.cx.internal.chinacloudapp.cn:11000/oozie</value>\r     ```\r \r     `http://hn0-CLUSTERNAME.randomcharacters.cx.internal.chinacloudapp.cn:11000/oozie` 部分是要配合 Oozie 命令使用的 URL。\r \r 2. 若要创建 URL 的环境变量，请使用以下命令，这样就不需要为每个命令输入该 URL：\r \r     ```bash\r     export OOZIE_URL=http://HOSTNAMEt:11000/oozie\r     ```\r \r     将 URL 替换为前面收到的 URL。\r 3. 若要提交作业，请使用以下命令：\r \r     ```bash\r     oozie job -config job.xml -submit\r     ```\r \r     此命令从 `job.xml` 加载作业信息，并将作业信息提交到 Oozie，但不运行该作业。\r \r     命令完成后，应返回作业的 ID，例如 `0000005-150622124850154-oozie-oozi-W`。 此 ID 用于管理作业。\r \r 4. 若要查看作业的状态，请使用以下命令：\r \r     ```bash\r     oozie job -info <JOBID>\r     ```\r \r     > [!NOTE]\r     > 将 `<JOBID>` 替换为上一步骤返回的 ID。\r \r     此命令返回类似于以下文本的信息：\r \r     ```\r     Job ID : 0000005-150622124850154-oozie-oozi-W\r     ------------------------------------------------------------------------------------------------------------------------------------\r     Workflow Name : useooziewf\r     App Path      : wasb:///tutorials/useoozie\r     Status        : PREP\r     Run           : 0\r     User          : USERNAME\r     Group         : -\r     Created       : 2015-06-22 15:06 GMT\r     Started       : -\r     Last Modified : 2015-06-22 15:06 GMT\r     Ended         : -\r     CoordAction ID: -\r     ------------------------------------------------------------------------------------------------------------------------------------\r     ```\r \r     此作业的状态为 `PREP`。 此状态指示作业已创建，但是未启动。\r \r 5. 若要启动作业，请使用以下命令：\r \r     ```bash\r     oozie job -start JOBID\r     ```\r \r     > [!NOTE]\r     > 将 `<JOBID>` 替换为之前返回的 ID。\r \r     如果在运行此命令后检查状态，会发现作业处于正在运行状态，并且返回了作业中操作的信息。\r \r 6. 任务成功完成后，可以使用以下命令验证是否已生成数据并且已将导出到 SQL 数据库表：\r \r     ```bash\r     TDSVER=8.0 tsql -H <serverName>.database.chinacloudapi.cn -U <adminLogin> -P <adminPassword> -p 1433 -D oozietest\r     ```\r \r     在 `1>` 提示符下，输入以下查询：\r \r     ```sql\r     SELECT * FROM mobiledata\r     GO\r     ```\r \r     返回的信息类似于以下文本：\r \r         deviceplatform  count\r         Android 31591\r         iPhone OS       22731\r         proprietary development 3\r         RIM OS  3464\r         Unknown 213\r         Windows Phone   1791\r         (6 rows affected)\r \r 有关 Oozie 命令的详细信息，请参阅 [Oozie 命令行工具](https://oozie.apache.org/docs/4.1.0/DG_CommandLineTool.html)。\r \r ## <a name=\"oozie-rest-api\"></a>Oozie REST API\r \r 借助 Oozie REST API 可以构建自己的工具来使用 Oozie。 下面是有关在 HDInsight 中使用 Oozie REST API 的具体信息：\r \r * **URI**：可从群集（位于 `https://CLUSTERNAME.azurehdinsight.cn/oozie`）外部访问 REST API。\r \r * **身份验证**：若要进行身份验证，请结合群集 HTTP 帐户（管理员）和密码使用该 API。 例如：\r \r     ```bash\r     curl -u admin:PASSWORD https://CLUSTERNAME.azurehdinsight.cn/oozie/versions\r     ```\r \r 有关如何使用 Oozie REST API 的详细信息，请参阅 [Oozie Web 服务 API](https://oozie.apache.org/docs/4.1.0/WebServicesAPI.html)。\r \r ## <a name=\"oozie-web-ui\"></a>Oozie Web UI\r \r Oozie Web UI 提供基于 Web 的视图来显示群集上 Oozie 作业的状态。 使用 Web UI 可查看以下信息：\r \r * 作业状态\r * 作业定义\r * 配置\r * 作业中操作的关系图\r * 作业的日志\r \r 还可以查看作业中操作的详细信息。\r \r 若要访问 Oozie Web UI，请完成以下步骤：\r \r 1. 与 HDInsight 群集建立 SSH 隧道。 有关详细信息，请参阅[将 SSH 隧道与 HDInsight 配合使用](hdinsight-linux-ambari-ssh-tunnel.md)。\r \r 2. 创建隧道后，请在 Web 浏览器中打开 Ambari Web UI。 Ambari 网站的 URI 是 `https://CLUSTERNAME.azurehdinsight.cn`。 请将 `CLUSTERNAME` 替换为基于 Linux 的 HDInsight 群集的名称。\r \r 3. 在页面左侧，选择“Oozie” > “快速链接” > “Oozie Web UI”。\r \r     ![菜单图像](./media/hdinsight-use-oozie-linux-mac/ooziewebuisteps.png)\r \r 4. Oozie Web UI 默认显示正在运行的工作流作业。 若要查看所有工作流作业，请选择“所有作业”。\r \r     ![显示了所有作业](./media/hdinsight-use-oozie-linux-mac/ooziejobs.png)\r \r 5. 若要查看有关某个作业的详细信息，请选择该作业。\r \r     ![作业信息](./media/hdinsight-use-oozie-linux-mac/jobinfo.png)\r \r 6. 可以在“作业信息”选项卡中查看基本作业信息，以及作业中的各个操作。 可以使用顶部的选项卡查看“作业定义”和“作业配置”，访问“作业日志”，或者在“作业 DAG”下查看作业的有向无环图 (DAG)。\r \r    * **作业日志**：选择“获取日志”按钮获取作业的所有日志，或使用“输入搜索条件”字段来筛选日志。\r \r        ![作业日志](./media/hdinsight-use-oozie-linux-mac/joblog.png)\r \r    * **作业 DAG**：DAG 是整个工作流中使用的数据路径的图形概览。\r \r        ![作业 DAG](./media/hdinsight-use-oozie-linux-mac/jobdag.png)\r \r 7. 如果在“作业信息”选项卡中选择一个操作，会显示有关该操作的信息。 例如，选择 **RunSqoopExport** 操作。\r \r     ![操作信息](./media/hdinsight-use-oozie-linux-mac/action.png)\r \r 8. 可以看到操作的详细信息，例如**控制台 URL** 的链接。 使用此链接可查看作业的作业跟踪器信息。\r \r ## <a name=\"schedule-jobs\"></a>计划作业\r \r 可以使用协调器指定作业的开始时间、结束时间和发生频率。 若要定义工作流的计划，请完成以下步骤：\r \r 1. 使用以下命令创建名为 **coordinator.xml** 的文件：\r \r     ```bash\r     nano coordinator.xml\r     ```\r \r     将以下 XML 用作该文件的内容：\r \r     ```xml\r     <coordinator-app name=\"my_coord_app\" frequency=\"${coordFrequency}\" start=\"${coordStart}\" end=\"${coordEnd}\" timezone=\"${coordTimezone}\" xmlns=\"uri:oozie:coordinator:0.4\">\r         <action>\r         <workflow>\r             <app-path>${workflowPath}</app-path>\r         </workflow>\r         </action>\r     </coordinator-app>\r     ```\r \r     > [!NOTE]\r     > `${...}` 变量在运行时会替换为作业定义中的值。 变量包括：\r     >\r     > * `${coordFrequency}`：运行作业实例的间隔时间。\r     > * `${coordStart}`：作业开始时间。\r     > * `${coordEnd}`：作业结束时间。\r     > * `${coordTimezone}`：在没有夏时制的固定时区（通常用 UTC 表示）处理协调器作业。 此时区被称为“Oozie 处理时区”。\r     > * `${wfPath}`：workflow.xml 的路径。\r \r 2. 若要保存文件，请按 Ctrl+X，输入 `Y`，再按 **Enter**。\r \r 3. 若要将该文件复制到此作业的工作目录，请使用以下命令：\r \r     ```bash\r     hadoop fs -put coordinator.xml /tutorials/useoozie/coordinator.xml\r     ```\r \r 4. 若要修改 `job.xml` 文件，请使用以下命令：\r \r     ```\r     nano job.xml\r     ```\r \r     进行以下更改：\r \r    * 若要指示 Oozie 运行协调器文件而不是工作流，请将 `<name>oozie.wf.application.path</name>` 更改为 `<name>oozie.coord.application.path</name>`。\r \r    * 若要设置协调器使用的 `workflowPath` 变量，请添加以下 XML：\r \r         ```xml\r         <property>\r             <name>workflowPath</name>\r             <value>wasb://mycontainer@mystorageaccount.blob.core.chinacloudapi.cn/tutorials/useoozie</value>\r         </property>\r         ```\r \r        将 `wasb://mycontainer@mystorageaccount.blob.core.windows` 文本替换为 job.xml 文件中的其他条目使用的值。\r \r    * 若要定义协调器的开始时间、结束时间和频率，请添加以下 XML：\r \r         ```xml\r         <property>\r             <name>coordStart</name>\r             <value>2017-05-10T12:00Z</value>\r         </property>\r \r         <property>\r             <name>coordEnd</name>\r             <value>2017-05-12T12:00Z</value>\r         </property>\r \r         <property>\r             <name>coordFrequency</name>\r             <value>1440</value>\r         </property>\r \r         <property>\r             <name>coordTimezone</name>\r             <value>UTC</value>\r         </property>\r         ```\r \r        这些值将开始时间设置为 2017 年 5 月 10 日中午 12:00，将结束时间设置为 2017 年 5 月 12 日。 此作业的运行时间间隔已设置为“每日”。 频率以分钟为单位，因此 24 小时 x 60 分钟 = 1440 分钟。 最后，将时区设置为 UTC。\r \r 5. 若要保存文件，请按 Ctrl+X，输入 `Y`，再按 **Enter**。\r \r 6. 若要运行作业，请使用以下命令：\r \r     ```\r     oozie job -config job.xml -run\r     ```\r \r     此命令将提交并启动作业。\r \r 7. 如果转到 Oozie Web UI 并选择“协调器作业”选项卡，会看到下图所示的信息：\r \r     ![协调器作业选项卡](./media/hdinsight-use-oozie-linux-mac/coordinatorjob.png)\r \r     “下一次具体化”条目包含下次运行作业的时间。\r \r 8. 与前面的工作流作业一样，在 Web UI 中选择作业条目会显示有关该作业的信息：\r \r     ![协调器作业信息](./media/hdinsight-use-oozie-linux-mac/coordinatorjobinfo.png)\r \r     > [!NOTE]\r     > 此图像只显示了作业的成功运行结果，而未显示计划工作流中的单个操作。 若要查看单个操作，请选择某个“操作”条目。\r \r     ![操作信息](./media/hdinsight-use-oozie-linux-mac/coordinatoractionjob.png)\r \r ## <a name=\"troubleshooting\"></a>故障排除\r \r 使用 Oozie UI 可查看 Oozie 日志。 Oozie UI 还包含一些链接，指向工作流启动的 MapReduce 任务的 JobTracker 日志。 故障排除的模式应为：\r \r 1. 在 Oozie Web UI 中查看作业。\r \r 2. 如果特定的操作出错或失败，请选择该操作，以查看“错误消息”字段是否提供了有关失败的详细信息。\r \r    3. 如果已提供，请使用操作中的 URL 查看该操作的更多详细信息（例如 JobTracker 日志）。\r \r 下面是可能会遇到的特定错误及其解决方法。\r \r ### <a name=\"ja009-cannot-initialize-cluster\"></a>JA009: 无法初始化群集\r \r **症状**：作业状态变为“SUSPENDED”。 作业详细信息中的 RunHiveScript 状态显示为“START_MANUAL”。 选择该操作会显示以下错误消息：\r \r     JA009: Cannot initialize Cluster. Please check your configuration for map\r \r **原因**：**job.xml** 文件中使用的 Azure Blob 存储地址不包含存储容器或存储帐户名。 Blob 存储地址格式必须是 `wasb://containername@storageaccountname.blob.core.chinacloudapi.cn`。\r \r **解决方法**：更改作业使用的 Blob 存储地址。\r \r ### <a name=\"ja002-oozie-is-not-allowed-to-impersonate-ltuser\"></a>JA002: 不允许 Oozie 模拟&lt;用户>\r \r **症状**：作业状态变为“SUSPENDED”。 作业详细信息中的 `RunHiveScript` 状态显示为“START_MANUAL”。 选择操作会显示以下错误消息：\r \r     JA002: User: oozie is not allowed to impersonate <USER>\r \r **原因**：当前的权限设置不允许 Oozie 模拟指定的用户帐户。\r \r **解决方法**：允许 Oozie 模拟“用户”组中的用户。 使用 `groups USERNAME` 查看用户帐户所属的组。 如果该用户不是**用户**组的成员，请使用以下命令将该用户添加到该组：\r \r     sudo adduser USERNAME users\r \r > [!NOTE]\r > 可能需要几分钟，HDInsight 才能识别用户已添加到该组。\r \r ### <a name=\"launcher-error-sqoop\"></a>启动器错误 (Sqoop)\r \r **症状**：作业状态变为“KILLED”。 作业详细信息中的 `RunSqoopExport` 状态显示为“ERROR”。 选择操作会显示以下错误消息：\r \r     Launcher ERROR, reason: Main class [org.apache.oozie.action.hadoop.SqoopMain], exit code [1]\r \r **原因**：Sqoop 无法加载访问数据库时所需的数据库驱动程序。\r \r **解决方法**：从 Oozie 作业使用 Sqoop 时，必须同时包含数据库驱动程序和作业使用的其他资源（例如 workflow.xml）。 此外，通过 workflow.xml 的 `<sqoop>...</sqoop>` 节引用包含数据库驱动程序的存档。\r \r 例如，可以针对本文档中的作业使用以下步骤：\r \r 1. 将 `sqljdbc4.1.jar` 文件复制到 **/tutorials/useoozie** 目录：\r \r     ```bash\r     hdfs dfs -put /usr/share/java/sqljdbc_4.1/enu/sqljdbc41.jar /tutorials/useoozie/sqljdbc41.jar\r     ```\r \r 2. 修改 `workflow.xml`，在 `</sqoop>` 上方的新行中添加以下 XML：\r \r     ```xml\r     <archive>sqljdbc41.jar</archive>\r     ```\r \r ## <a name=\"next-steps\"></a>后续步骤\r \r 在本教程中，已经学习了如何定义 Oozie 工作流，以及如何运行 Oozie 作业。 若要详细了解如何使用 HDInsight，请参阅以下文章：\r \r * [将基于时间的 Oozie 协调器与 HDInsight 配合使用][hdinsight-oozie-coordinator-time]\r * [在 HDInsight 中上传 Hadoop 作业的数据][hdinsight-upload-data]\r * [将 Sqoop 与 HDInsight 中的 Hadoop 配合使用][hdinsight-use-sqoop]\r * [将 Hive 与 Hadoop on HDInsight 配合使用][hdinsight-use-hive]\r * [将 Pig 与 Hadoop on HDInsight 配合使用][hdinsight-use-pig]\r * [为 HDInsight 开发 Java MapReduce 程序][hdinsight-develop-mapreduce]\r \r [hdinsight-cmdlets-download]: http://go.microsoft.com/fwlink/?LinkID=325563\r [hdinsight-oozie-coordinator-time]: hdinsight-use-oozie-coordinator-time.md\r [hdinsight-versions]:  hdinsight-component-versioning.md\r [hdinsight-storage]: hdinsight-hadoop-use-blob-storage.md\r [hdinsight-get-started]: hadoop/apache-hadoop-linux-tutorial-get-started.md\r [hdinsight-use-sqoop]:hadoop/apache-hadoop-use-sqoop-mac-linux.md\r [hdinsight-provision]: hdinsight-hadoop-provision-linux-clusters.md\r [hdinsight-upload-data]: hdinsight-upload-data.md\r [hdinsight-use-mapreduce]:hadoop/hdinsight-use-mapreduce.md\r [hdinsight-use-hive]:hadoop/hdinsight-use-hive.md\r [hdinsight-use-pig]:hadoop/hdinsight-use-pig.md\r [hdinsight-storage]: hdinsight-hadoop-use-blob-storage.md\r [hdinsight-get-started-emulator]: hadoop/apache-hadoop-emulator-get-started.md\r [hdinsight-develop-mapreduce]:hadoop/apache-hadoop-develop-deploy-java-mapreduce-linux.md\r \r \r [sqldatabase-get-started]: ../sql-database/sql-database-get-started.md\r \r [azure-create-storageaccount]:../storage/common/storage-create-storage-account.md\r \r [apache-hadoop]: http://hadoop.apache.org/\r [apache-oozie-400]: http://oozie.apache.org/docs/4.0.0/\r [apache-oozie-332]: http://oozie.apache.org/docs/3.3.2/\r \r [powershell-download]: /downloads/\r [powershell-about-profiles]: http://go.microsoft.com/fwlink/?LinkID=113729\r [powershell-install-configure]: https://docs.microsoft.com/powershell/azureps-cmdlets-docs\r [powershell-start]: http://technet.microsoft.com/library/hh847889.aspx\r [powershell-script]: https://technet.microsoft.com/library/ee176961.aspx\r \r [cindygross-hive-tables]: http://blogs.msdn.com/b/cindygross/archive/2013/02/06/hdinsight-hive-internal-and-external-tables-intro.aspx\r \r [img-workflow-diagram]: ./media/hdinsight-use-oozie/HDI.UseOozie.Workflow.Diagram.png\r [img-preparation-output]: ./media/hdinsight-use-oozie/HDI.UseOozie.Preparation.Output1.png\r [img-runworkflow-output]: ./media/hdinsight-use-oozie/HDI.UseOozie.RunWF.Output.png\r \r [technetwiki-hive-error]: http://social.technet.microsoft.com/wiki/contents/articles/23047.hdinsight-hive-error-unable-to-rename.aspx\r \r \r <!--Update_Description: update wording and link references-->\r "}