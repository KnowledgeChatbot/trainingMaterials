{"Title":"在 HDInsight 中使用 Hadoop Oozie","Description":"在 HDInsight 中使用大数据服务 Hadoop Oozie。 了解如何定义 Oozie 工作流和提交 Oozie 作业。","Content":"# <a name=\"use-oozie-with-hadoop-to-define-and-run-a-workflow-in-hdinsight\"></a>在 HDInsight 中将 Oozie 与 Hadoop 配合使用以定义和运行工作流\r [!INCLUDE [oozie-selector](../../includes/hdinsight-oozie-selector.md)]\r \r [!INCLUDE [azure-sdk-developer-differences](../../includes/azure-sdk-developer-differences.md)]\r \r 了解如何使用 Apache Oozie 定义工作流以及如何在 HDInsight 上运行工作流。 要了解 Oozie 协调器，请参阅[将基于时间的 Hadoop Oozie 协调器与 HDInsight 配合使用][hdinsight-oozie-coordinator-time]。\r \r Apache Oozie 是一个管理 Hadoop 作业的工作流/协调系统。 它与 Hadoop 堆栈集成，支持 Apache MapReduce、Apache Pig、Apache Hive 和 Apache Sqoop 的 Hadoop 作业。 它也能用于安排特定于某系统的作业，例如 Java 程序或 shell 脚本。\r \r 你根据本教程中的说明实现的工作流包含两个操作：\r \r ![工作流关系图][img-workflow-diagram]\r \r 1. Hive 操作运行 HiveQL 脚本，统计 log4j 文件中每个日志级类型的出现次数。 每个 log4j 文件都包含一行字段，其中包含用于显示类型和严重性的 [LOG LEVEL] 字段，例如：\r \r         2012-02-03 18:35:34 SampleClass6 [INFO] everything normal for id 577725851\r         2012-02-03 18:35:34 SampleClass4 [FATAL] system problem at id 1991281254\r         2012-02-03 18:35:34 SampleClass3 [DEBUG] detail for id 1304807656\r         ...\r \r     Hive 脚本的输出结果类似如下：\r \r         [DEBUG] 434\r         [ERROR] 3\r         [FATAL] 1\r         [INFO]  96\r         [TRACE] 816\r         [WARN]  4\r \r     有关 Hive 的详细信息，请参阅[将 Hive 与 HDInsight 配合使用][hdinsight-use-hive]。\r 2. Sqoop 操作将 HiveQL 输出结果导出到 Azure SQL 数据库中的表。 有关 Sqoop 的详细信息，请参阅[将 Hadoop Sqoop 与 HDInsight 配合使用][hdinsight-use-sqoop]。\r \r > [!NOTE]\r > 有关在 HDInsight 群集上支持的 Oozie 版本，请参阅 [HDInsight 提供的 Hadoop 群集版本有哪些新增功能？][hdinsight-versions]。\r > \r > \r \r ### <a name=\"prerequisites\"></a>先决条件\r 开始学习本教程之前，必须具备以下项：\r \r * **配备 Azure PowerShell 的工作站**。 \r \r [!INCLUDE [upgrade-powershell](../../includes/hdinsight-use-latest-powershell.md)]\r \r ## <a name=\"define-oozie-workflow-and-the-related-hiveql-script\"></a>定义 Oozie 工作流及相关 HiveQL 脚本\r Oozie 工作流定义是用 hPDL（一种 XML 过程定义语言）编写的。 默认的工作流文件名为 *workflow.xml*。 以下是本教程中使用的工作流文件。\r \r     <workflow-app name=\"useooziewf\" xmlns=\"uri:oozie:workflow:0.2\">\r         <start to = \"RunHiveScript\"/>\r \r         <action name=\"RunHiveScript\">\r             <hive xmlns=\"uri:oozie:hive-action:0.2\">\r                 <job-tracker>${jobTracker}</job-tracker>\r                 <name-node>${nameNode}</name-node>\r                 <configuration>\r                     <property>\r                         <name>mapred.job.queue.name</name>\r                         <value>${queueName}</value>\r                     </property>\r                 </configuration>\r                 <script>${hiveScript}</script>\r                 <param>hiveTableName=${hiveTableName}</param>\r                 <param>hiveDataFolder=${hiveDataFolder}</param>\r                 <param>hiveOutputFolder=${hiveOutputFolder}</param>\r             </hive>\r             <ok to=\"RunSqoopExport\"/>\r             <error to=\"fail\"/>\r         </action>\r \r         <action name=\"RunSqoopExport\">\r             <sqoop xmlns=\"uri:oozie:sqoop-action:0.2\">\r                 <job-tracker>${jobTracker}</job-tracker>\r                 <name-node>${nameNode}</name-node>\r                 <configuration>\r                     <property>\r                         <name>mapred.compress.map.output</name>\r                         <value>true</value>\r                     </property>\r                 </configuration>\r             <arg>export</arg>\r             <arg>--connect</arg>\r             <arg>${sqlDatabaseConnectionString}</arg>\r             <arg>--table</arg>\r             <arg>${sqlDatabaseTableName}</arg>\r             <arg>--export-dir</arg>\r             <arg>${hiveOutputFolder}</arg>\r             <arg>-m</arg>\r             <arg>1</arg>\r             <arg>--input-fields-terminated-by</arg>\r             <arg>\"\\001\"</arg>\r             </sqoop>\r             <ok to=\"end\"/>\r             <error to=\"fail\"/>\r         </action>\r \r         <kill name=\"fail\">\r             <message>Job failed, error message[${wf:errorMessage(wf:lastErrorNode())}] </message>\r         </kill>\r \r         <end name=\"end\"/>\r     </workflow-app>\r \r 该工作流中定义了两个操作。 start-to 操作是 *RunHiveScript*。 如果该操作成功运行，则下一个操作是 *RunSqoopExport*。\r \r RunHiveScript 有几个变量。 在使用 Azure PowerShell 从工作站提交 Oozie 作业时，会传递值。\r \r <table border = \"1\">\r <tr><th>工作流变量</th><th>说明</th></tr>\r <tr><td>${jobTracker}</td><td>指定 Hadoop 作业跟踪器的 URL。 在 HDInsight 版本 3.0 和 2.1 中使用 jobtrackerhost:9010<strong></strong>。</td></tr>\r <tr><td>${nameNode}</td><td>指定 Hadoop 名称节点的 URL。 使用默认的文件系统地址，例如 <i>wasb://&lt;containerName&gt;@&lt;storageAccountName&gt;.blob.core.chinacloudapi.cn</i>。</td></tr>\r <tr><td>${queueName}</td><td>指定作业将提交到的队列名称。 使用默认值<strong></strong>。</td></tr>\r </table>\r \r <table border = \"1\">\r <tr><th>Hive 操作变量</th><th>说明</th></tr>\r <tr><td>${hiveDataFolder}</td><td>指定 Hive Create Table 命令的源目录。</td></tr>\r <tr><td>${hiveOutputFolder}</td><td>指定 INSERT OVERWRITE 语句的输出文件夹。</td></tr>\r <tr><td>${hiveTableName}</td><td>指定引用 log4j 数据文件的 Hive 表的名称。</td></tr>\r </table>\r \r <table border = \"1\">\r <tr><th>Sqoop 操作变量</th><th>说明</th></tr>\r <tr><td>${sqlDatabaseConnectionString}</td><td>指定 Azure SQL 数据库连接字符串。</td></tr>\r <tr><td>${sqlDatabaseTableName}</td><td>指定数据将导出到的 Azure SQL 数据库表。</td></tr>\r <tr><td>${hiveOutputFolder}</td><td>指定 Hive INSERT OVERWRITE 语句的输出文件夹。 这是用于 Sqoop 导出 (export-dir) 的同一个文件夹。</td></tr>\r </table>\r \r 有关 Oozie 工作流和使用工作流操作的详细信息，请参阅 [Apache Oozie 4.0 文档][apache-oozie-400]（适用于 HDInsight 3.0 版）或 [Apache Oozie 3.3.2 文档][apache-oozie-332]（适用于 HDInsight 2.1 版）。\r \r 工作流中的 Hive 操作调用 HiveQL 脚本文件。 此脚本文件包含三个 HiveQL 语句：\r \r     DROP TABLE ${hiveTableName};\r     CREATE EXTERNAL TABLE ${hiveTableName}(t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ' ' STORED AS TEXTFILE LOCATION '${hiveDataFolder}';\r     INSERT OVERWRITE DIRECTORY '${hiveOutputFolder}' SELECT t4 AS sev, COUNT(*) AS cnt FROM ${hiveTableName} WHERE t4 LIKE '[%' GROUP BY t4;\r \r 1. **DROP TABLE 语句** 删除 log4j Hive 表（如果存在）。\r 2. **CREATE TABLE 语句** 创建指向 log4j 日志文件位置的 log4j Hive 外部表。 字段分隔符为“,”。 默认分行符为“\\n”。 如果想要多次运行 Oozie 工作流，可使用 Hive 外部表来避免从原始位置删除数据文件。\r 3. \r             **INSERT OVERWRITE 语句**可从 log4j Hive 表中计算每个日志级别类型的出现次数，并将输出保存到 Azure 存储中的 Blob。\r \r 该脚本中使用了三个变量：\r \r * ${hiveTableName}\r * ${hiveDataFolder}\r * ${hiveOutputFolder}\r \r 工作流定义文件（本教程中的 workflow.xml）在运行时会将三个值传递到这个 HiveQL 脚本。\r \r 工作流文件和 HiveQL 文件同时存储在 Blob 容器中。  本教程后面要使用的 PowerShell 脚本会将这两个文件复制到默认存储帐户。 \r \r ## <a name=\"submit-oozie-jobs-using-powershell\"></a>使用 PowerShell 提交 Oozie 作业\r Azure PowerShell 目前不提供任何用于定义 Oozie 作业的 cmdlet。 可以使用 **Invoke-RestMethod** cmdlet 调用 Oozie Web 服务。 Oozie Web 服务 API 是 HTTP REST JSON API。 有关 Oozie Web 服务 API 的详细信息，请参阅 [Apache Oozie 4.0 文档][apache-oozie-400]（用于 HDInsight 版本 3.0）或 [Apache Oozie 3.3.2 文档][apache-oozie-332]（用于 HDInsight 版本 2.1）。\r \r 本部分中的 PowerShell 脚本将执行以下步骤：\r \r 1. 连接到 Azure。\r 2. 创建 Azure 资源组。 有关详细信息，请参阅[将 Azure PowerShell 与 Azure 资源管理器配合使用](../powershell-azure-resource-manager.md)。\r 3. 创建一个 Azure SQL 数据库服务器、一个 Azure SQL 数据库和两个表。 工作流中的 Sqoop 操作将使用这些项。\r \r     表的名称为 *log4jLogCount*。\r 4. 创建用于运行 Oozie 作业的 HDInsight 群集。\r \r     若要检查群集，可以使用 Azure 门户或 Azure PowerShell。\r 5. 将 Oozie 工作流文件和 HiveQL 脚本文件复制到默认文件系统。\r \r     这两个文件将存储在公共 Blob 容器中。\r \r    * 将 HiveQL 脚本 (useoozie.hql) 复制到 Azure 存储 (wasb:///tutorials/useoozie/useoozie.hql)。\r    * 将 workflow.xml 复制到 wasb:///tutorials/useoozie/workflow.xml。\r    * 将数据文件 (/example/data/sample.log) 复制到 wasb:///tutorials/useoozie/data/sample.log。\r 6. 提交 Oozie 作业。\r \r     若要检查 OOzie 作业结果，请使用 Visual Studio 或其他工具连接到 Azure SQL 数据库。\r \r 脚本如下。  可以通过 Windows PowerShell ISE 运行该脚本。 只需配置前 7 个变量。\r \r     #region - provide the following values\r \r     $subscriptionID = \"<Enter your Azure subscription ID>\"\r \r     # SQL Database server login credentials used for creating and connecting\r     $sqlDatabaseLogin = \"<Enter SQL Database Login Name>\"\r     $sqlDatabasePassword = \"<Enter SQL Database Login Password>\"\r \r     # HDInsight cluster HTTP user credential used for creating and connectin\r     $httpUserName = \"admin\"  # The default name is \"admin\"\r     $httpPassword = \"<Enter HDInsight Cluster HTTP User Password>\"\r \r     # Used for creating Azure service names\r     $nameToken = \"<Enter an Alias>\"\r     $namePrefix = $nameToken.ToLower() + (Get-Date -Format \"MMdd\")\r     #endregion\r \r     #region - variables\r \r     # Resource group variables\r     $resourceGroupName = $namePrefix + \"rg\"\r     $location = \"China East\" # used by all Azure services defined in this tutorial\r \r     # SQL database varialbes\r     $sqlDatabaseServerName = $namePrefix + \"sqldbserver\"\r     $sqlDatabaseName = $namePrefix + \"sqldb\"\r     $sqlDatabaseConnectionString = \"Data Source=$sqlDatabaseServerName.database.chinacloudapi.cn;Initial Catalog=$sqlDatabaseName;User ID=$sqlDatabaseLogin;Password=$sqlDatabasePassword;Encrypt=true;Trusted_Connection=false;\"\r     $sqlDatabaseMaxSizeGB = 10\r \r     # Used for retrieving external IP address and creating firewall rules\r     $ipAddressRestService = \"http://bot.whatismyipaddress.com\"\r     $fireWallRuleName = \"UseSqoop\"\r \r     # HDInsight variables\r     $hdinsightClusterName = $namePrefix + \"hdi\"\r     $defaultStorageAccountName = $namePrefix + \"store\"\r     $defaultBlobContainerName = $hdinsightClusterName\r     #endregion\r \r     # Treat all errors as terminating\r     $ErrorActionPreference = \"Stop\"\r \r     #region - Connect to Azure subscription\r     Write-Host \"`nConnecting to your Azure subscription ...\" -ForegroundColor Green\r     try{Get-AzureRmContext}\r     catch{\r         Login-AzureRmAccount -EnvironmentName AzureChinaCloud\r         Select-AzureRmSubscription -SubscriptionId $subscriptionID\r     }\r     #endregion\r \r     #region - Create Azure resouce group\r     Write-Host \"`nCreating an Azure resource group ...\" -ForegroundColor Green\r     try{\r         Get-AzureRmResourceGroup -Name $resourceGroupName\r     }\r     catch{\r         New-AzureRmResourceGroup -Name $resourceGroupName -Location $location\r     }\r     #endregion\r \r     #region - Create Azure SQL database server\r     Write-Host \"`nCreating an Azure SQL Database server ...\" -ForegroundColor Green\r     try{\r         Get-AzureRmSqlServer -ServerName $sqlDatabaseServerName -ResourceGroupName $resourceGroupName}\r     catch{\r         Write-Host \"`nCreating SQL Database server ...\"  -ForegroundColor Green\r \r         $sqlDatabasePW = ConvertTo-SecureString -String $sqlDatabasePassword -AsPlainText -Force\r         $sqlLoginCredentials = New-Object System.Management.Automation.PSCredential($sqlDatabaseLogin,$sqlDatabasePW)\r \r         $sqlDatabaseServerName = (New-AzureRmSqlServer `\r                                     -ResourceGroupName $resourceGroupName `\r                                     -ServerName $sqlDatabaseServerName `\r                                     -SqlAdministratorCredentials $sqlLoginCredentials `\r                                     -Location $location).ServerName\r         Write-Host \"`tThe new SQL database server name is $sqlDatabaseServerName.\" -ForegroundColor Cyan\r \r         Write-Host \"`nCreating firewall rule, $fireWallRuleName ...\" -ForegroundColor Green\r         $workstationIPAddress = Invoke-RestMethod $ipAddressRestService\r         New-AzureRmSqlServerFirewallRule `\r             -ResourceGroupName $resourceGroupName `\r             -ServerName $sqlDatabaseServerName `\r             -FirewallRuleName \"$fireWallRuleName-workstation\" `\r             -StartIpAddress $workstationIPAddress `\r             -EndIpAddress $workstationIPAddress\r \r         #To allow other Azure services to access the server add a firewall rule and set both the StartIpAddress and EndIpAddress to 0.0.0.0. \r         #Note that this allows Azure traffic from any Azure subscription to access the server.\r         New-AzureRmSqlServerFirewallRule `\r             -ResourceGroupName $resourceGroupName `\r             -ServerName $sqlDatabaseServerName `\r             -FirewallRuleName \"$fireWallRuleName-Azureservices\" `\r             -StartIpAddress \"0.0.0.0\" `\r             -EndIpAddress \"0.0.0.0\"\r     }\r     #endregion\r \r     #region - Create and validate Azure SQL database\r     Write-Host \"`nCreating SQL Database, $sqlDatabaseName ...\"  -ForegroundColor Green\r \r     try {\r         Get-AzureRmSqlDatabase `\r             -ResourceGroupName $resourceGroupName `\r             -ServerName $sqlDatabaseServerName `\r             -DatabaseName $sqlDatabaseName\r     }\r     catch {\r         New-AzureRMSqlDatabase `\r             -ResourceGroupName $resourceGroupName `\r             -ServerName $sqlDatabaseServerName `\r             -DatabaseName $sqlDatabaseName `\r             -Edition \"Standard\" `\r             -RequestedServiceObjectiveName \"S1\"\r     }\r     #endregion\r \r     #region - Create SQL database tables\r     Write-Host \"Creating the log4jlogs table  ...\" -ForegroundColor Green\r \r     $sqlDatabaseTableName = \"log4jLogsCount\"\r     $cmdCreateLog4jCountTable = \" CREATE TABLE [dbo].[$sqlDatabaseTableName](\r             [Level] [nvarchar](10) NOT NULL,\r             [Total] float,\r         CONSTRAINT [PK_$sqlDatabaseTableName] PRIMARY KEY CLUSTERED\r         (\r         [Level] ASC\r         )\r         )\"\r \r     $conn = New-Object System.Data.SqlClient.SqlConnection\r     $conn.ConnectionString = $sqlDatabaseConnectionString\r     $conn.Open()\r \r     # Create the log4jlogs table and index\r     $cmd = New-Object System.Data.SqlClient.SqlCommand\r     $cmd.Connection = $conn\r     $cmd.CommandText = $cmdCreateLog4jCountTable\r     $cmd.ExecuteNonQuery()\r \r     $conn.close()\r     #endregion\r \r     #region - Create HDInsight cluster\r \r     Write-Host \"Creating the HDInsight cluster and the dependent services ...\" -ForegroundColor Green\r \r     # Create the default storage account\r     New-AzureRmStorageAccount `\r         -ResourceGroupName $resourceGroupName `\r         -Name $defaultStorageAccountName `\r         -Location $location `\r         -Type Standard_LRS\r \r     # Create the default Blob container\r     $defaultStorageAccountKey = (Get-AzureRmStorageAccountKey `\r                                     -ResourceGroupName $resourceGroupName `\r                                     -Name $defaultStorageAccountName)[0].Value\r     $defaultStorageAccountContext = New-AzureStorageContext `\r                                         -StorageAccountName $defaultStorageAccountName `\r                                         -StorageAccountKey $defaultStorageAccountKey \r     New-AzureStorageContainer `\r         -Name $defaultBlobContainerName `\r         -Context $defaultStorageAccountContext \r \r     # Create the HDInsight cluster\r     $pw = ConvertTo-SecureString -String $httpPassword -AsPlainText -Force\r     $httpCredential = New-Object System.Management.Automation.PSCredential($httpUserName,$pw)\r \r     New-AzureRmHDInsightCluster `\r         -ResourceGroupName $resourceGroupName `\r         -ClusterName $HDInsightClusterName `\r         -Location $location `\r         -ClusterType Hadoop `\r         -OSType Windows `\r         -ClusterSizeInNodes 2 `\r         -HttpCredential $httpCredential `\r         -DefaultStorageAccountName \"$defaultStorageAccountName.blob.core.chinacloudapi.cn\" `\r         -DefaultStorageAccountKey $defaultStorageAccountKey `\r         -DefaultStorageContainer $defaultBlobContainerName \r \r     # Validate the cluster\r     Get-AzureRmHDInsightCluster -ClusterName $hdinsightClusterName\r     #endregion\r \r     #region - copy Oozie workflow and HiveQL files\r \r     Write-Host \"Copy workflow definition and HiveQL script file ...\" -ForegroundColor Green\r \r     # Both files are stored in a public Blob\r     $publicBlobContext = New-AzureStorageContext -StorageAccountName \"hditutorialdata\" -Anonymous\r \r     # WASB folder for storing the Oozie tutorial files.\r     $destFolder = \"tutorials/useoozie\"  # Do NOT use the long path here\r \r     Start-CopyAzureStorageBlob `\r         -Context $publicBlobContext `\r         -SrcContainer \"useoozie\" `\r         -SrcBlob \"useooziewf.hql\"  `\r         -DestContext $defaultStorageAccountContext `\r         -DestContainer $defaultBlobContainerName `\r         -DestBlob \"$destFolder/useooziewf.hql\" `\r         -Force\r \r     Start-CopyAzureStorageBlob `\r         -Context $publicBlobContext `\r         -SrcContainer \"useoozie\" `\r         -SrcBlob \"workflow.xml\"  `\r         -DestContext $defaultStorageAccountContext `\r         -DestContainer $defaultBlobContainerName `\r         -DestBlob \"$destFolder/workflow.xml\" `\r         -Force\r \r     #validate the copy\r     Get-AzureStorageBlob `\r         -Context $defaultStorageAccountContext `\r         -Container $defaultBlobContainerName `\r         -Blob $destFolder/workflow.xml\r \r     Get-AzureStorageBlob `\r         -Context $defaultStorageAccountContext `\r         -Container $defaultBlobContainerName `\r         -Blob $destFolder/useooziewf.hql\r \r     #endregion\r \r     #region - copy the sample.log file\r \r     Write-Host \"Make a copy of the sample.log file ... \" -ForegroundColor Green\r \r     Start-CopyAzureStorageBlob `\r         -Context $defaultStorageAccountContext `\r         -SrcContainer $defaultBlobContainerName `\r         -SrcBlob \"example/data/sample.log\"  `\r         -DestContext $defaultStorageAccountContext `\r         -DestContainer $defaultBlobContainerName `\r         -destBlob \"$destFolder/data/sample.log\" \r \r     #validate the copy\r     Get-AzureStorageBlob `\r         -Context $defaultStorageAccountContext `\r         -Container $defaultBlobContainerName `\r         -Blob $destFolder/data/sample.log\r \r     #endregion\r \r     #region - submit Oozie job\r \r     $storageUri=\"wasb://$defaultBlobContainerName@$defaultStorageAccountName.blob.core.chinacloudapi.cn\"\r \r     $oozieJobName = $namePrefix + \"OozieJob\"\r \r     #Oozie WF variables\r     $oozieWFPath=\"$storageUri/tutorials/useoozie\"  # The default name is workflow.xml. And you don't need to specify the file name.\r     $waitTimeBetweenOozieJobStatusCheck=10\r \r     #Hive action variables\r     $hiveScript = \"$storageUri/tutorials/useoozie/useooziewf.hql\"\r     $hiveTableName = \"log4jlogs\"\r     $hiveDataFolder = \"$storageUri/tutorials/useoozie/data\"\r     $hiveOutputFolder = \"$storageUri/tutorials/useoozie/output\"\r \r     #Sqoop action variables\r     $sqlDatabaseConnectionString = \"jdbc:sqlserver://$sqlDatabaseServerName.database.chinacloudapi.cn;user=$sqlDatabaseLogin@$sqlDatabaseServerName;password=$sqlDatabasePassword;database=$sqlDatabaseName\"\r \r     $OoziePayload =  @\"\r     <?xml version=\"1.0\" encoding=\"UTF-8\"?>\r     <configuration>\r \r     <property>\r         <name>nameNode</name>\r         <value>$storageUrI</value>\r     </property>\r \r     <property>\r         <name>jobTracker</name>\r         <value>jobtrackerhost:9010</value>\r     </property>\r \r     <property>\r         <name>queueName</name>\r         <value>default</value>\r     </property>\r \r     <property>\r         <name>oozie.use.system.libpath</name>\r         <value>true</value>\r     </property>\r \r     <property>\r         <name>hiveScript</name>\r         <value>$hiveScript</value>\r     </property>\r \r     <property>\r         <name>hiveTableName</name>\r         <value>$hiveTableName</value>\r     </property>\r \r     <property>\r         <name>hiveDataFolder</name>\r         <value>$hiveDataFolder</value>\r     </property>\r \r     <property>\r         <name>hiveOutputFolder</name>\r         <value>$hiveOutputFolder</value>\r     </property>\r \r     <property>\r         <name>sqlDatabaseConnectionString</name>\r         <value>&quot;$sqlDatabaseConnectionString&quot;</value>\r     </property>\r \r     <property>\r         <name>sqlDatabaseTableName</name>\r         <value>$SQLDatabaseTableName</value>\r     </property>\r \r     <property>\r         <name>user.name</name>\r         <value>$httpUserName</value>\r     </property>\r \r     <property>\r         <name>oozie.wf.application.path</name>\r         <value>$oozieWFPath</value>\r     </property>\r \r     </configuration>\r     \"@\r \r     Write-Host \"Checking Oozie server status...\" -ForegroundColor Green\r     $clusterUriStatus = \"https://$hdinsightClusterName.azurehdinsight.cn:443/oozie/v2/admin/status\"\r     $response = Invoke-RestMethod -Method Get -Uri $clusterUriStatus -Credential $httpCredential -OutVariable $OozieServerStatus\r \r     $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\r     $oozieServerSatus = $jsonResponse[0].(\"systemMode\")\r     Write-Host \"Oozie server status is $oozieServerSatus.\"\r \r     # create Oozie job\r     Write-Host \"Sending the following Payload to the cluster:\" -ForegroundColor Green\r     Write-Host \"`n--------`n$OoziePayload`n--------\"\r     $clusterUriCreateJob = \"https://$hdinsightClusterName.azurehdinsight.cn:443/oozie/v2/jobs\"\r     $response = Invoke-RestMethod -Method Post -Uri $clusterUriCreateJob -Credential $httpCredential -Body $OoziePayload -ContentType \"application/xml\" -OutVariable $OozieJobName #-debug\r \r     $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\r     $oozieJobId = $jsonResponse[0].(\"id\")\r     Write-Host \"Oozie job id is $oozieJobId...\"\r \r     # start Oozie job\r     Write-Host \"Starting the Oozie job $oozieJobId...\" -ForegroundColor Green\r     $clusterUriStartJob = \"https://$hdinsightClusterName.azurehdinsight.cn:443/oozie/v2/job/\" + $oozieJobId + \"?action=start\"\r     $response = Invoke-RestMethod -Method Put -Uri $clusterUriStartJob -Credential $httpCredential | Format-Table -HideTableHeaders #-debug\r \r     # get job status\r     Write-Host \"Sleeping for $waitTimeBetweenOozieJobStatusCheck seconds until the job metadata is populated in the Oozie metastore...\" -ForegroundColor Green\r     Start-Sleep -Seconds $waitTimeBetweenOozieJobStatusCheck\r \r     Write-Host \"Getting job status and waiting for the job to complete...\" -ForegroundColor Green\r     $clusterUriGetJobStatus = \"https://$hdinsightClusterName.azurehdinsight.cn:443/oozie/v2/job/\" + $oozieJobId + \"?show=info\"\r     $response = Invoke-RestMethod -Method Get -Uri $clusterUriGetJobStatus -Credential $httpCredential\r     $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\r     $JobStatus = $jsonResponse[0].(\"status\")\r \r     while($JobStatus -notmatch \"SUCCEEDED|KILLED\")\r     {\r         Write-Host \"$(Get-Date -format 'G'): $oozieJobId is in $JobStatus state...waiting $waitTimeBetweenOozieJobStatusCheck seconds for the job to complete...\"\r         Start-Sleep -Seconds $waitTimeBetweenOozieJobStatusCheck\r         $response = Invoke-RestMethod -Method Get -Uri $clusterUriGetJobStatus -Credential $httpCredential\r         $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\r         $JobStatus = $jsonResponse[0].(\"status\")\r         $jobStatus\r     }\r \r     Write-Host \"$(Get-Date -format 'G'): $oozieJobId is in $JobStatus state!\" -ForegroundColor Green\r \r     #endregion\r \r **重新运行教程**\r \r 若要重新运行该工作流，必须删除以下项：\r \r * Hive 脚本输出文件\r * log4jLogsCount 表中的数据\r \r 以下是可以使用的一个示例 PowerShell 脚本：\r \r     $resourceGroupName = \"<AzureResourceGroupName>\"\r \r     $defaultStorageAccountName = \"<AzureStorageAccountName>\"\r     $defaultBlobContainerName = \"<ContainerName>\"\r \r     #SQL database variables\r     $sqlDatabaseServerName = \"<SQLDatabaseServerName>\"\r     $sqlDatabaseLogin = \"<SQLDatabaseLoginName>\"\r     $sqlDatabasePassword = \"<SQLDatabaseLoginPassword>\"\r     $sqlDatabaseName = \"<SQLDatabaseName>\"\r     $sqlDatabaseTableName = \"log4jLogsCount\"\r \r     Write-host \"Delete the Hive script output file ...\" -ForegroundColor Green\r     $defaultStorageAccountKey = (Get-AzureRmStorageAccountKey `\r                                 -ResourceGroupName $resourceGroupName `\r                                 -Name $defaultStorageAccountName)[0].Value\r     $destContext = New-AzureStorageContext -StorageAccountName $defaultStorageAccountName -StorageAccountKey $defaultStorageAccountKey\r     Remove-AzureStorageBlob -Context $destContext -Blob \"tutorials/useoozie/output/000000_0\" -Container $defaultBlobContainerName\r \r     Write-host \"Delete all the records from the log4jLogsCount table ...\" -ForegroundColor Green\r     $conn = New-Object System.Data.SqlClient.SqlConnection\r     $conn.ConnectionString = \"Data Source=$sqlDatabaseServerName.database.chinacloudapi.cn;Initial Catalog=$sqlDatabaseName;User ID=$sqlDatabaseLogin;Password=$sqlDatabasePassword;Encrypt=true;Trusted_Connection=false;\"\r     $conn.open()\r     $cmd = New-Object System.Data.SqlClient.SqlCommand\r     $cmd.connection = $conn\r     $cmd.commandtext = \"delete from $sqlDatabaseTableName\"\r     $cmd.executenonquery()\r \r     $conn.close()\r \r ## <a name=\"next-steps\"></a>后续步骤\r 本教程已经介绍了如何定义 Oozie 工作流以及如何使用 PowerShell 运行 Oozie 作业。 若要了解更多信息，请参阅下列文章：\r \r * [将基于时间的 Oozie 协调器与 HDInsight 配合使用][hdinsight-oozie-coordinator-time]\r * [将 Hadoop 与 HDInsight 中的 Hive 配合使用以分析手机使用情况][hdinsight-get-started]\r * [将 Azure Blob 存储与 HDInsight 配合使用][hdinsight-storage]\r * [使用 PowerShell 管理 HDInsight][hdinsight-admin-powershell]\r * [在 HDInsight 中上传 Hadoop 作业的数据][hdinsight-upload-data]\r * [将 Sqoop 与 HDInsight 中的 Hadoop 配合使用][hdinsight-use-sqoop]\r * [将 Hive 与 Hadoop on HDInsight 配合使用][hdinsight-use-hive]\r * [将 Pig 与 Hadoop on HDInsight 配合使用][hdinsight-use-pig]\r * [为 HDInsight 开发 Java MapReduce 程序][hdinsight-develop-mapreduce]\r \r [hdinsight-cmdlets-download]: http://go.microsoft.com/fwlink/?LinkID=325563\r \r [hdinsight-oozie-coordinator-time]: hdinsight-use-oozie-coordinator-time.md\r [hdinsight-versions]:  hdinsight-component-versioning.md\r [hdinsight-storage]: hdinsight-hadoop-use-blob-storage.md\r [hdinsight-get-started]:hadoop/apache-hadoop-linux-tutorial-get-started.md\r [hdinsight-admin-portal]: hdinsight-administer-use-management-portal.md\r \r \r [hdinsight-use-sqoop]:hadoop/hdinsight-use-sqoop.md\r [hdinsight-provision]: hdinsight-hadoop-provision-linux-clusters.md\r [hdinsight-admin-powershell]: hdinsight-administer-use-powershell.md\r [hdinsight-upload-data]: hdinsight-upload-data.md\r [hdinsight-use-mapreduce]:hadoop/hdinsight-use-mapreduce.md\r [hdinsight-use-hive]:hadoop/hdinsight-use-hive.md\r [hdinsight-use-pig]:hadoop/hdinsight-use-pig.md\r [hdinsight-storage]: hdinsight-hadoop-use-blob-storage.md\r \r [hdinsight-develop-mapreduce]:hadoop/apache-hadoop-develop-deploy-java-mapreduce-linux.md\r \r \r [sqldatabase-get-started]: ../sql-database/sql-database-get-started.md\r \r [azure-management-portal]: https://portal.azure.cn/\r [azure-create-storageaccount]:../storage/common/storage-create-storage-account.md\r \r [apache-hadoop]: http://hadoop.apache.org/\r [apache-oozie-400]: http://oozie.apache.org/docs/4.0.0/\r [apache-oozie-332]: http://oozie.apache.org/docs/3.3.2/\r \r [powershell-download]: /downloads/\r [powershell-about-profiles]: http://go.microsoft.com/fwlink/?LinkID=113729\r [powershell-install-configure]: https://docs.microsoft.com/powershell/azureps-cmdlets-docs\r [powershell-start]: http://technet.microsoft.com/library/hh847889.aspx\r [powershell-script]: https://technet.microsoft.com/en-us/library/ee176961.aspx\r \r [cindygross-hive-tables]: http://blogs.msdn.com/b/cindygross/archive/2013/02/06/hdinsight-hive-internal-and-external-tables-intro.aspx\r \r [img-workflow-diagram]: ./media/hdinsight-use-oozie/HDI.UseOozie.Workflow.Diagram.png\r [img-preparation-output]: ./media/hdinsight-use-oozie/HDI.UseOozie.Preparation.Output1.png  \r [img-runworkflow-output]: ./media/hdinsight-use-oozie/HDI.UseOozie.RunWF.Output.png\r \r [technetwiki-hive-error]: http://social.technet.microsoft.com/wiki/contents/articles/23047.hdinsight-hive-error-unable-to-rename.aspx\r \r \r <!--Update_Description: update wording and link references-->"}