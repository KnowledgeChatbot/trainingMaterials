{"Title":"使用 Azure 媒体分析进行面部修订","Description":"本主题演示如何使用 Azure 媒体分析检测面部。","Content":"# <a name=\"redact-faces-with-azure-media-analytics\"></a>使用 Azure 媒体分析进行面部修订\r \r ## <a name=\"overview\"></a>概述\r \r **Azure 媒体修订器**是一种 [Azure 媒体分析](media-services-analytics-overview.md)媒体处理器 (MP)，可用于在云中进行可缩放的面部修订。 使用面部修订，可对视频进行修改，使所选个人的面部模糊显示。 用户可能想要在公共安全和新闻媒体场景中使用面部修订服务。 对于时长仅几分钟但包含多张面孔的镜头，进行手动面部修订可能需要几个小时，但使用此服务仅需几个简单步骤即可完成该过程。 有关详细信息，请参阅[此](https://azure.microsoft.com/blog/azure-media-redactor/)博客。\r \r 本主题提供有关 **Azure 媒体修订器**的详细信息，并演示如何通过适用于 .NET 的媒体服务 SDK 使用它。\r \r ## <a name=\"face-redaction-modes\"></a>面部修订模式\r \r 面部修订的工作方式是：检测每一帧视频中的面部，并跟踪之前和之后的面部对象，以便同一个人在其他角度也模糊显示。 自动修订过程非常复杂，并且无法始终产生 100% 符合要求的输出，因此，媒体分析提供了几种修改最终输出的方式。\r \r 除了完全自动模式外，还可使用双步工作流通过 ID 列表选择/取消选找到的面部。 此外，为了对每一帧进行任意调整，MP 使用 JSON 格式的元数据文件。 此工作流拆分为“分析”和“修订”模式。 可将这两个模式组合为在一个作业中运行两项任务的单个过程；此模式称为“组合”。\r \r ### <a name=\"combined-mode\"></a>组合模式\r \r 这自动生成经过修订的 mp4，而无需任何手动输入。\r \r | 阶段 | 文件名 | 说明 |\r | --- | --- | --- |\r | 输入资产 |foo.bar |WMV、MOV 或 MP4 格式的视频 |\r | 输入配置 |作业配置预设 |{'version':'1.0', 'options': {'mode':'combined'}} |\r | 输出资产 |foo_redacted.mp4 |进行了模糊处理的视频 |\r \r #### <a name=\"input-example\"></a>输入示例：\r \r [观看此视频](http://ampdemo.azureedge.net/?url=http%3A%2F%2Freferencestream-samplestream.streaming.mediaservices.windows.net%2Fed99001d-72ee-4f91-9fc0-cd530d0adbbc%2FDancing.mp4)\r \r #### <a name=\"output-example\"></a>输出示例：\r \r [观看此视频](http://ampdemo.azureedge.net/?url=http%3A%2F%2Freferencestream-samplestream.streaming.mediaservices.windows.net%2Fc6608001-e5da-429b-9ec8-d69d8f3bfc79%2Fdance_redacted.mp4)\r \r ### <a name=\"analyze-mode\"></a>分析模式\r \r 双步工作流的 **分析** 步骤使用视频输入，并生成表示面部位置的 JSON 文件，以及显示每个检测到的面部的 jpg 图像。\r \r | 阶段 | 文件名 | 说明 |\r | --- | --- | --- |\r | 输入资产 |foo.bar |WMV、MPV 或 MP4 格式的视频 |\r | 输入配置 |作业配置预设 |{'version':'1.0', 'options': {'mode':'analyze'}} |\r | 输出资产 |foo_annotations.json |JSON 格式的面部位置批注数据。 用户可编辑此数据，以修改模糊边界框。 请查看以下示例。 |\r | 输出资产 |foo_thumb%06d.jpg [foo_thumb000001.jpg, foo_thumb000002.jpg] |裁剪后的 jpg 文件，显示每个检测到的面部，其中的数字指示面部的标签 ID |\r \r #### <a name=\"output-example\"></a>输出示例：\r \r     {\r       \"version\": 1,\r       \"timescale\": 24000,\r       \"offset\": 0,\r       \"framerate\": 23.976,\r       \"width\": 1280,\r       \"height\": 720,\r       \"fragments\": [\r         {\r           \"start\": 0,\r           \"duration\": 48048,\r           \"interval\": 1001,\r           \"events\": [\r             [],\r             [],\r             [],\r             [],\r             [],\r             [],\r             [],\r             [],\r             [],\r             [],\r             [],\r             [],\r             [],\r             [\r               {\r                 \"index\": 13,\r                 \"id\": 1138,\r                 \"x\": 0.29537,\r                 \"y\": -0.18987,\r                 \"width\": 0.36239,\r                 \"height\": 0.80335\r               },\r               {\r                 \"index\": 13,\r                 \"id\": 2028,\r                 \"x\": 0.60427,\r                 \"y\": 0.16098,\r                 \"width\": 0.26958,\r                 \"height\": 0.57943\r               }\r             ],\r \r     … truncated\r \r ### <a name=\"redact-mode\"></a>修订模式\r 工作流的第二步使用更大数量的输入，这些输入必须合并为单个资产。\r \r 这包括要模糊处理的 ID 的列表、原始视频和批注 JSON。 此模式使用批注来对输入视频进行模糊处理。\r \r “分析”步骤的输出不包括原始视频。 需要将该视频上传到“修订”模式任务的输入资产中，并将其选作主文件。\r \r | 阶段 | 文件名 | 说明 |\r | --- | --- | --- |\r | 输入资产 |foo.bar |WMV、MPV 或 MP4 格式的视频。 与步骤 1 中相同的视频。 |\r | 输入资产 |foo_annotations.json |第一阶段中的批注元数据文件，包含可选的修改。 |\r | 输入资产 |foo_IDList.txt（可选） |要进行修订的可选面部 ID 列表，以新行进行分隔。 如果留空，则模糊所有面部。 |\r | 输入配置 |作业配置预设 |{'version':'1.0', 'options': {'mode':'redact'}} |\r | 输出资产 |foo_redacted.mp4 |基于批注进行了模糊处理的视频 |\r \r #### <a name=\"example-output\"></a>示例输出\r 这是来自选择了一个 ID 的 ID 列表的输出。\r \r [观看此视频](http://ampdemo.azureedge.net/?url=http%3A%2F%2Freferencestream-samplestream.streaming.mediaservices.windows.net%2Fad6e24a2-4f9c-46ee-9fa7-bf05e20d19ac%2Fdance_redacted1.mp4)\r \r 示例 foo_IDList.txt\r  \r      1\r      2\r      3\r \r ## <a name=\"blur-types\"></a>模糊类型\r \r 在“组合”或“修订”模式下，可通过 JSON 输入配置在 5 种不同的模糊模式中选择：“低”、“中”、“高”、“框”和“黑色”。 默认情况下使用“中”。\r \r 可以查找以下模糊类型的示例。\r \r ### <a name=\"example-json\"></a>示例 JSON：\r \r     {'version':'1.0', 'options': {'Mode': 'Combined', 'BlurType': 'High'}}\r \r #### <a name=\"low\"></a>低\r \r ![低](./media/media-services-face-redaction/blur1.png)\r  \r #### <a name=\"med\"></a>中\r \r ![中](./media/media-services-face-redaction/blur2.png)\r \r #### <a name=\"high\"></a>高\r \r ![高](./media/media-services-face-redaction/blur3.png)\r \r #### <a name=\"box\"></a>Box\r \r ![Box](./media/media-services-face-redaction/blur4.png)\r \r #### <a name=\"black\"></a>黑色\r \r ![黑色](./media/media-services-face-redaction/blur5.png)\r \r ## <a name=\"elements-of-the-output-json-file\"></a>输出 JSON 文件中的元素\r \r 修订 MP 提供高精确度的面部位置检测和跟踪功能，可在一个视频帧中检测到最多 64 张人脸。 正面的面部可提供最佳效果，而检测和跟踪侧面的面部和较小的面部（小于或等于 24x24 像素）可能具有一定难度。\r \r [!INCLUDE [media-services-analytics-output-json](../../includes/media-services-analytics-output-json.md)]\r \r ## <a name=\"net-sample-code\"></a>.NET 示例代码\r \r 以下程序演示如何：\r \r 1. 创建资产并将媒体文件上传到资产。\r 2. 基于包含以下 json 预设的配置文件创建含有面部修订任务的作业。 \r    \r         {'version':'1.0', 'options': {'mode':'combined'}}\r 3. 下载输出 JSON 文件。 \r \r #### <a name=\"create-and-configure-a-visual-studio-project\"></a>创建和配置 Visual Studio 项目\r \r 设置开发环境，并根据[使用 .NET 进行媒体服务开发](media-services-dotnet-how-to-use.md)中所述，在 app.config 文件中填充连接信息。 \r \r #### <a name=\"example\"></a>示例\r \r     using System;\r     using System.Configuration;\r     using System.IO;\r     using System.Linq;\r     using Microsoft.WindowsAzure.MediaServices.Client;\r     using System.Threading;\r     using System.Threading.Tasks;\r \r     namespace FaceRedaction\r     {\r         class Program\r         {\r         // Read values from the App.config file.\r         private static readonly string _AADTenantDomain =\r             ConfigurationManager.AppSettings[\"AADTenantDomain\"];\r         private static readonly string _RESTAPIEndpoint =\r             ConfigurationManager.AppSettings[\"MediaServiceRESTAPIEndpoint\"];\r \r         // Field for service context.\r         private static CloudMediaContext _context = null;\r \r         static void Main(string[] args)\r         {\r             var tokenCredentials = new AzureAdTokenCredentials(_AADTenantDomain, AzureEnvironments.AzureChinaCloudEnvironment);\r             var tokenProvider = new AzureAdTokenProvider(tokenCredentials);\r \r             _context = new CloudMediaContext(new Uri(_RESTAPIEndpoint), tokenProvider);\r \r             // Run the FaceRedaction job.\r             var asset = RunFaceRedactionJob(@\"C:\\supportFiles\\FaceRedaction\\SomeFootage.mp4\",\r                         @\"C:\\supportFiles\\FaceRedaction\\config.json\");\r \r             // Download the job output asset.\r             DownloadAsset(asset, @\"C:\\supportFiles\\FaceRedaction\\Output\");\r         }\r \r         static IAsset RunFaceRedactionJob(string inputMediaFilePath, string configurationFile)\r         {\r             // Create an asset and upload the input media file to storage.\r             IAsset asset = CreateAssetAndUploadSingleFile(inputMediaFilePath,\r             \"My Face Redaction Input Asset\",\r             AssetCreationOptions.None);\r \r             // Declare a new job.\r             IJob job = _context.Jobs.Create(\"My Face Redaction Job\");\r \r             // Get a reference to Azure Media Redactor.\r             string MediaProcessorName = \"Azure Media Redactor\";\r \r             var processor = GetLatestMediaProcessorByName(MediaProcessorName);\r \r             // Read configuration from the specified file.\r             string configuration = File.ReadAllText(configurationFile);\r \r             // Create a task with the encoding details, using a string preset.\r             ITask task = job.Tasks.AddNew(\"My Face Redaction Task\",\r             processor,\r             configuration,\r             TaskOptions.None);\r \r             // Specify the input asset.\r             task.InputAssets.Add(asset);\r \r             // Add an output asset to contain the results of the job.\r             task.OutputAssets.AddNew(\"My Face Redaction Output Asset\", AssetCreationOptions.None);\r \r             // Use the following event handler to check job progress.  \r             job.StateChanged += new EventHandler<JobStateChangedEventArgs>(StateChanged);\r \r             // Launch the job.\r             job.Submit();\r \r             // Check job execution and wait for job to finish.\r             Task progressJobTask = job.GetExecutionProgressTask(CancellationToken.None);\r \r             progressJobTask.Wait();\r \r             // If job state is Error, the event handling\r             // method for job progress should log errors.  Here we check\r             // for error state and exit if needed.\r             if (job.State == JobState.Error)\r             {\r             ErrorDetail error = job.Tasks.First().ErrorDetails.First();\r             Console.WriteLine(string.Format(\"Error: {0}. {1}\",\r                             error.Code,\r                             error.Message));\r             return null;\r             }\r \r             return job.OutputMediaAssets[0];\r         }\r \r         static IAsset CreateAssetAndUploadSingleFile(string filePath, string assetName, AssetCreationOptions options)\r         {\r             IAsset asset = _context.Assets.Create(assetName, options);\r \r             var assetFile = asset.AssetFiles.Create(Path.GetFileName(filePath));\r             assetFile.Upload(filePath);\r \r             return asset;\r         }\r \r         static void DownloadAsset(IAsset asset, string outputDirectory)\r         {\r             foreach (IAssetFile file in asset.AssetFiles)\r             {\r             file.Download(Path.Combine(outputDirectory, file.Name));\r             }\r         }\r \r         static IMediaProcessor GetLatestMediaProcessorByName(string mediaProcessorName)\r         {\r             var processor = _context.MediaProcessors\r             .Where(p => p.Name == mediaProcessorName)\r             .ToList()\r             .OrderBy(p => new Version(p.Version))\r             .LastOrDefault();\r \r             if (processor == null)\r             throw new ArgumentException(string.Format(\"Unknown media processor\",\r                                    mediaProcessorName));\r \r             return processor;\r         }\r \r         static private void StateChanged(object sender, JobStateChangedEventArgs e)\r         {\r             Console.WriteLine(\"Job state changed event:\");\r             Console.WriteLine(\"  Previous state: \" + e.PreviousState);\r             Console.WriteLine(\"  Current state: \" + e.CurrentState);\r \r             switch (e.CurrentState)\r             {\r             case JobState.Finished:\r                 Console.WriteLine();\r                 Console.WriteLine(\"Job is finished.\");\r                 Console.WriteLine();\r                 break;\r             case JobState.Canceling:\r             case JobState.Queued:\r             case JobState.Scheduled:\r             case JobState.Processing:\r                 Console.WriteLine(\"Please wait...\\n\");\r                 break;\r             case JobState.Canceled:\r             case JobState.Error:\r                 // Cast sender as a job.\r                 IJob job = (IJob)sender;\r                 // Display or log error details as needed.\r                 // LogJobStop(job.Id);\r                 break;\r             default:\r                 break;\r             }\r         }\r         }\r     }\r \r \r ## <a name=\"related-links\"></a>相关链接\r \r [Azure 媒体服务分析概述](media-services-analytics-overview.md)\r \r [Azure Media Analytics demos（Azure 媒体分析演示）](http://azuremedialabs.azurewebsites.net/demos/Analytics.html)\r \r <!--Update_Description: wording update-->\r "}