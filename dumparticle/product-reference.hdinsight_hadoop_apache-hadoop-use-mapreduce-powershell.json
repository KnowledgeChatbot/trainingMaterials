{"Title":"将 MapReduce 和 PowerShell 与 Hadoop 配合使用 - Azure HDInsight","Description":"了解如何使用 PowerShell 在 HDInsight 的 Hadoop 上远程运行 MapReduce 作业。","Content":"# <a name=\"run-mapreduce-jobs-with-hadoop-on-hdinsight-using-powershell\"></a>通过 PowerShell 使用 HDInsight 上的 Hadoop 运行 MapReduce 作业\r \r [!INCLUDE [mapreduce-selector](../../../includes/hdinsight-selector-use-mapreduce.md)]\r \r [!INCLUDE [azure-sdk-developer-differences](../../../includes/azure-sdk-developer-differences.md)]\r \r 本文档提供了一个示例，演示了使用 Azure PowerShell 在 HDInsight 的 Hadoop 群集中运行 MapReduce 作业。\r \r ## <a id=\"prereq\"></a>先决条件\r \r * **Azure HDInsight（HDInsight 上的 Hadoop）群集**\r \r   > [!IMPORTANT]\r   > Linux 是在 HDInsight 3.4 版或更高版本上使用的唯一操作系统。 有关详细信息，请参阅 [HDInsight 在 Windows 上停用](../hdinsight-component-versioning.md#hdinsight-windows-retirement)。\r \r * **配备 Azure PowerShell 的工作站**。\r \r ## <a id=\"powershell\"></a>使用 Azure PowerShell 运行 MapReduce 作业\r \r Azure PowerShell 提供 *cmdlet*，可在 HDInsight 上远程运行 MapReduce 作业。 从内部来讲，PowerShell 将对 HDInsight 群集上运行的 [WebHCat](https://cwiki.apache.org/confluence/display/Hive/WebHCat)（以前称为 Templeton）进行 REST 调用。\r \r 在远程 HDInsight 群集上运行 MapReduce 作业时，会使用以下 Cmdlet。\r \r * **Login-AzureRmAccount**：对 Azure 订阅进行 Azure PowerShell 身份验证。\r \r * **New-AzureRmHDInsightMapReduceJobDefinition**：使用指定的 MapReduce 信息创建新 *作业定义* 。\r \r * **Start-AzureRmHDInsightJob**：将作业定义发送到 HDInsight 并启动作业。 将返回作业对象。\r \r * **Wait-AzureRmHDInsightJob**：使用作业对象来检查作业的状态。 它等到作业完成或超出等待时间。\r \r * **Get-AzureRmHDInsightJobOutput**：用于检索作业输出。\r \r 以下步骤演示了如何使用这些 Cmdlet 在 HDInsight 群集上运行作业。\r \r 1. 使用编辑器将以下代码保存为 **mapreducejob.ps1**。\r \r     ```powershell\r     # Login to your Azure subscription\r     # Is there an active Azure subscription?\r     $sub = Get-AzureRmSubscription -ErrorAction SilentlyContinue\r     if(-not($sub))\r     {\r         Add-AzureRmAccount -EnvironmentName AzureChinaCloud\r     }\r \r     # Get cluster info\r     $clusterName = Read-Host -Prompt \"Enter the HDInsight cluster name\"\r     $creds=Get-Credential -Message \"Enter the login for the cluster\"\r \r     #Get the cluster info so we can get the resource group, storage, etc.\r     $clusterInfo = Get-AzureRmHDInsightCluster -ClusterName $clusterName\r     $resourceGroup = $clusterInfo.ResourceGroup\r     $storageAccountName=$clusterInfo.DefaultStorageAccount.split('.')[0]\r     $container=$clusterInfo.DefaultStorageContainer\r     #NOTE: This assumes that the storage account is in the same resource\r     #      group as the cluster. If it is not, change the\r     #      --ResourceGroupName parameter to the group that contains storage.\r     $storageAccountKey=(Get-AzureRmStorageAccountKey `\r         -Name $storageAccountName `\r     -ResourceGroupName $resourceGroup)[0].Value\r \r     #Create a storage context\r     $context = New-AzureStorageContext `\r         -StorageAccountName $storageAccountName `\r         -StorageAccountKey $storageAccountKey\r \r     #Define the MapReduce job\r     #NOTE: If using an HDInsight 2.0 cluster, use hadoop-examples.jar instead.\r     # -JarFile = the JAR containing the MapReduce application\r     # -ClassName = the class of the application\r     # -Arguments = The input file, and the output directory\r     $wordCountJobDefinition = New-AzureRmHDInsightMapReduceJobDefinition `\r         -JarFile \"/example/jars/hadoop-mapreduce-examples.jar\" `\r         -ClassName \"wordcount\" `\r         -Arguments `\r             \"/example/data/gutenberg/davinci.txt\", `\r             \"/example/data/WordCountOutput\"\r \r     #Submit the job to the cluster\r     Write-Host \"Start the MapReduce job...\" -ForegroundColor Green\r     $wordCountJob = Start-AzureRmHDInsightJob `\r         -ClusterName $clusterName `\r         -JobDefinition $wordCountJobDefinition `\r         -HttpCredential $creds\r \r     #Wait for the job to complete\r     Write-Host \"Wait for the job to complete...\" -ForegroundColor Green\r     Wait-AzureRmHDInsightJob `\r         -ClusterName $clusterName `\r         -JobId $wordCountJob.JobId `\r         -HttpCredential $creds\r     # Download the output\r     Get-AzureStorageBlobContent `\r         -Blob 'example/data/WordCountOutput/part-r-00000' `\r         -Container $container `\r         -Destination output.txt `\r         -Context $context\r     # Print the output of the job.\r     Get-AzureRmHDInsightJobOutput `\r         -Clustername $clusterName `\r         -JobId $wordCountJob.JobId `\r         -HttpCredential $creds\r     ```\r \r 2. 打开一个新的 **Azure PowerShell** 命令提示符。 将目录更改为 **mapreducejob.ps1** 文件所在位置，并使用以下命令来运行脚本：\r \r         .\\mapreducejob.ps1\r \r     运行脚本时，系统会提示输入 HDInsight 群集的名称和该群集的登录名。 还会提示针对 Azure 订阅进行身份验证。\r \r 3. 作业完成后，会收到类似于以下文本的输出：\r \r         Cluster         : CLUSTERNAME\r         ExitCode        : 0\r         Name            : wordcount\r         PercentComplete : map 100% reduce 100%\r         Query           :\r         State           : Completed\r         StatusDirectory : f1ed2028-afe8-402f-a24b-13cc17858097\r         SubmissionTime  : 12/5/2014 8:34:09 PM\r         JobId           : job_1415949758166_0071\r \r     此输出指示作业已成功完成。\r \r     > [!NOTE]\r     > 如果 **ExitCode** 的值不是 0，请参阅[故障排除](#troubleshooting)。\r \r     此示例还会将下载的文件存储到从中运行脚本的目录中的 **output.txt** 文件。\r \r ### <a name=\"view-output\"></a>查看输出\r \r 若要查看作业生成的单词和计数，请在文本编辑器中打开 output.txt 文件。\r \r > [!NOTE]\r > MapReduce 作业的输出文件是固定不变的。 因此，如果重新运行此示例，需要更改输出文件的名称。\r \r ## <a id=\"troubleshooting\"></a>故障排除\r \r 如果作业完成时未返回任何信息，请查看该作业的错误。 如果要查看此作业的错误信息，请将以下命令添加到 **mapreducejob.ps1** 文件的末尾，保存，并重新运行该文件。\r \r ```powershell\r # Print the output of the WordCount job.\r Write-Host \"Display the standard output ...\" -ForegroundColor Green\r Get-AzureRmHDInsightJobOutput `\r         -Clustername $clusterName `\r         -JobId $wordCountJob.JobId `\r         -HttpCredential $creds `\r         -DisplayOutputType StandardError\r ```\r \r 作业运行期间，此 cmdlet 返回写入到 STDERR 中的信息。\r \r ## <a id=\"summary\"></a>摘要\r \r Azure PowerShell 提供了一种简单方法，可让你在 HDInsight 群集上运行 MapReduce 作业、监视作业状态，以及检索输出。\r \r ## <a id=\"nextsteps\"></a>后续步骤\r \r 有关 HDInsight 中的 MapReduce 作业的一般信息：\r \r * [在 HDInsight Hadoop 上使用 MapReduce](hdinsight-use-mapreduce.md)\r \r 有关 HDInsight 上 Hadoop 的其他使用方法的信息：\r \r * [将 Hive 与 Hadoop on HDInsight 配合使用](hdinsight-use-hive.md)\r * [将 Pig 与 Hadoop on HDInsight 配合使用](hdinsight-use-pig.md)\r \r \r \r <!--Update_Description: update wording and link references-->"}