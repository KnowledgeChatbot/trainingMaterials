{"Title":"将 MapReduce 和 SSH 连接与 HDInsight 中的 Hadoop 配合使用 - Azure","Description":"了解如何在 HDInsight 上的 Hadoop 中使用 SSH 运行 MapReduce 作业。","Content":"# <a name=\"use-mapreduce-with-hadoop-on-hdinsight-with-ssh\"></a>通过 SSH 将 MapReduce 与 HDInsight 上的 Hadoop 配合使用\r \r [!INCLUDE [mapreduce-selector](../../../includes/hdinsight-selector-use-mapreduce.md)]\r \r 了解如何从安全外壳 (SSH) 将 MapReduce 作业提交到 HDInsight。\r \r > [!NOTE]\r > 如果已熟悉如何使用基于 Linux 的 Hadoop 服务器，但刚接触 HDInsight，请参阅[基于 Linux 的 HDInsight 提示](../hdinsight-hadoop-linux-information.md)。\r \r ## <a id=\"prereq\"></a>先决条件\r \r * 基于 Linux 的 HDInsight（HDInsight 上的 Hadoop）群集\r \r   > [!IMPORTANT]\r   > Linux 是在 HDInsight 3.4 版或更高版本上使用的唯一操作系统。 有关详细信息，请参阅 [HDInsight 在 Windows 上停用](../hdinsight-component-versioning.md#hdinsight-windows-retirement)。\r \r * SSH 客户端。 有关详细信息，请参阅 [Use SSH with HDInsight](../hdinsight-hadoop-linux-use-ssh-unix.md)（将 SSH 与 HDInsight 配合使用）\r \r ## <a id=\"ssh\"></a>使用 SSH 进行连接\r \r 使用 SSH 连接到群集。 例如，以下命令将连接到名为 **myhdinsight** 的群集：\r \r ```bash\r ssh admin@myhdinsight-ssh.azurehdinsight.cn\r ```\r \r **如果使用用于 SSH 身份验证的证书密钥**，则可能需要指定客户端系统上的私钥位置，例如：\r \r ```bash\r ssh -i ~/mykey.key admin@myhdinsight-ssh.azurehdinsight.cn\r ```\r \r **如果使用用于 SSH 身份验证的密码**，则需要根据提示提供密码。\r \r 有关将 SSH 与 HDInsight 配合使用的详细信息，请参阅[将 SSH 与 HDInsight 配合使用](../hdinsight-hadoop-linux-use-ssh-unix.md)。\r \r ## <a id=\"hadoop\"></a>使用 Hadoop 命令\r \r 1. 连接到 HDInsight 群集后，使用以下命令启动 MapReduce 作业：\r \r     ```bash\r     yarn jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar wordcount /example/data/gutenberg/davinci.txt /example/data/WordCountOutput\r     ```\r \r     此命令启动 `hadoop-mapreduce-examples.jar` 文件中包含的 `wordcount` 类。 它使用 `/example/data/gutenberg/davinci.txt` 文档作为输入，并将输出存储在 `/example/data/WordCountOutput` 中。\r \r     > [!NOTE]\r     > 有关此 MapReduce 作业和示例数据的详细信息，请参阅[在 HDInsight 上的 Hadoop 中使用 MapReduce](hdinsight-use-mapreduce.md)。\r \r 2. 作业在处理时提供详细信息，并在完成时返回类似于以下文本的信息：\r \r         File Input Format Counters\r         Bytes Read=1395666\r         File Output Format Counters\r         Bytes Written=337623\r \r 3. 作业完成后，使用以下命令列出输出文件：\r \r     ```bash\r     hdfs dfs -ls /example/data/WordCountOutput\r     ```\r \r     此命令显示两个文件（`_SUCCESS` 和 `part-r-00000`）。 `part-r-00000` 文件包含此作业的输出。\r \r     > [!NOTE]\r     > 某些 MapReduce 作业可能会将结果拆分成多个 **part-r-#####** 文件。 如果是这样，请使用 ##### 后缀指示文件的顺序。\r \r 4. 若要查看输出，请使用以下命令：\r \r     ```bash\r     hdfs dfs -cat /example/data/WordCountOutput/part-r-00000\r     ```\r \r     此命令会显示一个列表，其内容为 wasb://example/data/gutenberg/davinci.txt 文件中包含的单词以及每个单词出现的次数。 以下文本是文件中所含数据的示例：\r \r         wreathed        3\r         wreathing       1\r         wreaths         1\r         wrecked         3\r         wrenching       1\r         wretched        6\r         wriggling       1\r \r ## <a id=\"summary\"></a>摘要\r \r 如用户所见，Hadoop 命令提供简单的方法让用户在 HDInsight 群集上运行 MapReduce 作业，并查看作业输出。\r \r ## <a id=\"nextsteps\"></a>后续步骤\r \r 有关 HDInsight 中的 MapReduce 作业的一般信息：\r \r * [在 HDInsight Hadoop 上使用 MapReduce](hdinsight-use-mapreduce.md)\r \r 有关 HDInsight 上 Hadoop 的其他使用方法的信息：\r \r * [将 Hive 与 Hadoop on HDInsight 配合使用](hdinsight-use-hive.md)\r * [将 Pig 与 Hadoop on HDInsight 配合使用](hdinsight-use-pig.md)\r \r \r \r <!--Update_Description: update wording and link references-->"}