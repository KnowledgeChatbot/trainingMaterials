{"Title":"使用 Azure HDInsight 对 Storm 进行故障排除","Description":"获取有关在 Azure HDInsight 中使用 Apache Storm 时遇到的常见问题的解答。","Content":"# <a name=\"troubleshoot-storm-by-using-azure-hdinsight\"></a>使用 Azure HDInsight 对 Storm 进行故障排除\r \r 了解处理 Apache Ambari 中的 Apache Storm 有效负载时的最常见问题及其解决方法。\r \r ## <a name=\"how-do-i-access-the-storm-ui-on-a-cluster\"></a>如何在群集上访问 Storm UI？\r 可以使用两个选项从浏览器访问 Storm UI：\r \r ### <a name=\"ambari-ui\"></a>Ambari UI\r 1. 转到 Ambari 仪表板。\r 2. 在服务列表中，选择“Storm”。\r 3. 在“快速链接”菜单中，选择“Storm UI”。\r \r ### <a name=\"direct-link\"></a>直接链接\r 可通过以下 URL 访问 Storm UI：\r \r https://\\<群集 DNS 名称\\>/stormui\r \r 示例：\r \r  https://stormcluster.azurehdinsight.cn/stormui\r \r ## <a name=\"how-do-i-transfer-storm-event-hub-spout-checkpoint-information-from-one-topology-to-another\"></a>如何将 Storm 事件中心 Spout 检查点信息从一个拓扑传输到另一个拓扑？\r \r 开发可使用 HDInsight Storm 事件中心 Spout .jar 文件从 Azure 事件中心读取数据的拓扑时，必须在新群集上部署同名的拓扑。 但是，必须在旧群集上保留已提交到 Apache ZooKeeper 的检查点数据。\r \r ### <a name=\"where-checkpoint-data-is-stored\"></a>检查点数据的存储位置\r 事件中心 Spout 将偏移检查点数据存储在 ZooKeeper 中的两个根路径下：\r - 非事务 Spout 检查点存储在 /eventhubspout 中。\r - 事务 Spout 检查点数据存储在 /transactional 中。\r \r ### <a name=\"how-to-restore\"></a>如何还原\r 若要获取可用于将数据导出 ZooKeeper 并使用新名称将其导入回到 ZooKeeper 的脚本和库，请参阅 [HDInsight Storm 示例](https://github.com/hdinsight/hdinsight-storm-examples/tree/master/tools/zkdatatool-1.0)。\r \r lib 文件夹中有一些 .Jar 文件，其中包含导出/导入操作的实现。 bash 文件夹包含一个示例脚本，该脚本演示如何从旧群集上的 ZooKeeper 服务器导出数据，并将数据导入回到新群集上的 ZooKeeper 服务器。\r \r 在 ZooKeeper 节点中运行 [stormmeta.sh](https://github.com/hdinsight/hdinsight-storm-examples/blob/master/tools/zkdatatool-1.0/bash/stormmeta.sh) 脚本即可导出再导入数据。 需将该脚本更新为正确的 Hortonworks 数据平台 (HDP) 版本。 （我们正努力使这些脚本在 HDInsight 中通用化。 可以通过群集上的任何节点运行通用脚本，而无需用户进行修改。）\r \r 导出命令会将元数据写入所设置位置中的 Apache Hadoop 分布式文件系统 (HDFS) 路径（在 Azure Blob 存储中）。\r \r ### <a name=\"examples\"></a>示例\r \r #### <a name=\"export-offset-metadata\"></a>导出偏移元数据\r 1. 使用 SSH 在需要从中导出检查点偏移数据的群集上转到 ZooKeeper 群集。\r 2. （更新 HDP 版本字符串之后）运行以下命令，将 ZooKeeper 偏移数据导出到 /stormmetadta/zkdata HDFS 路径：\r \r     ```apache   \r     java -cp ./*:/etc/hadoop/conf/*:/usr/hdp/2.5.1.0-56/hadoop/*:/usr/hdp/2.5.1.0-56/hadoop/lib/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/lib/*:/etc/failover-controller/conf/*:/etc/hadoop/* com.microsoft.storm.zkdatatool.ZkdataImporter export /eventhubspout /stormmetadata/zkdata\r     ```\r \r #### <a name=\"import-offset-metadata\"></a>导入偏移元数据\r 1. 使用 SSH 在需要从中导出检查点偏移数据的群集上转到 ZooKeeper 群集。\r 2. （更新 HDP 版本字符串之后）运行以下命令，将 ZooKeeper 偏移数据从 HDFS 路径 /stormmetadata/zkdata 导入到目标群集上的 ZooKeeper 服务器：\r \r     ```apache\r     java -cp ./*:/etc/hadoop/conf/*:/usr/hdp/2.5.1.0-56/hadoop/*:/usr/hdp/2.5.1.0-56/hadoop/lib/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/lib/*:/etc/failover-controller/conf/*:/etc/hadoop/* com.microsoft.storm.zkdatatool.ZkdataImporter import /eventhubspout /home/sshadmin/zkdata\r     ```\r    \r #### <a name=\"delete-offset-metadata-so-that-topologies-can-start-processing-data-from-the-beginning-or-from-a-timestamp-that-the-user-chooses\"></a>删除偏移元数据，使拓扑能够从头开始或者从用户所选的时间戳开始处理数据\r 1. 使用 SSH 在需要从中导出检查点偏移数据的群集上转到 ZooKeeper 群集。\r 2. （更新 HDP 版本字符串之后）运行以下命令，删除当前群集中的所有 ZooKeeper 偏移数据：\r \r     ```apache\r        java -cp ./*:/etc/hadoop/conf/*:/usr/hdp/2.5.1.0-56/hadoop/*:/usr/hdp/2.5.1.0-56/hadoop/lib/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/*:/usr/hdp/2.5.1.0-56/hadoop-hdfs/lib/*:/etc/failover-controller/conf/*:/etc/hadoop/* com.microsoft.storm.zkdatatool.ZkdataImporter delete /eventhubspout\r     ```\r \r ## <a name=\"how-do-i-locate-storm-binaries-on-a-cluster\"></a>如何在群集上查找 Storm 二进制文件？\r 当前 HDP 堆栈的 Storm 二进制文件在 /usr/hdp/current/storm-client 中。 在头节点和工作节点上，此位置是相同的。\r  \r /usr/hdp 中可能包含特定 HDP 版本的多个二进制文件（例如 /usr/hdp/2.5.0.1233/storm）。 /usr/hdp/current/storm-client 文件与群集上运行的最新版本建立了符号链接。\r \r 有关详细信息，请参阅[使用 SSH 连接到 HDInsight 群集](../hdinsight-hadoop-linux-use-ssh-unix.md)和 [Storm](http://storm.apache.org/)。\r  \r ## <a name=\"how-do-i-determine-the-deployment-topology-of-a-storm-cluster\"></a>如何确定 Storm 群集的部署拓扑？\r 首先，请识别连同 HDInsight Storm 一起安装的所有组件。 Storm 群集由四个节点类别组成：\r \r * 网关节点\r * 头节点\r * ZooKeeper 节点\r * 辅助角色节点\r  \r ### <a name=\"gateway-nodes\"></a>网关节点\r 网关节点是一个网关和反向代理服务，可用于公开访问活动的 Ambari 管理服务。 它还处理 Ambari 群首选举。\r  \r ### <a name=\"head-nodes\"></a>头节点\r Storm 头节点运行以下服务：\r * Nimbus\r * Ambari 服务器\r * Ambari 指标服务器\r * Ambari 指标收集器\r  \r ### <a name=\"zookeeper-nodes\"></a>ZooKeeper 节点\r HDInsight 附带一个三节点 ZooKeeper 仲裁。 仲裁大小是固定的，不可重新配置。\r  \r 群集中的 Storm 服务配置为自动使用 ZooKeeper 仲裁。\r  \r ### <a name=\"worker-nodes\"></a>辅助角色节点\r Storm 工作节点运行以下服务：\r * 监督器\r * 用于运行拓扑的辅助角色 Java 虚拟机 (JVM)\r * Ambari 代理\r  \r ## <a name=\"how-do-i-locate-storm-event-hub-spout-binaries-for-development\"></a>如何查找用于开发的 Storm 事件中心 Spout 二进制文件？\r  \r 有关在拓扑中使用 Storm 事件中心 Spout .jar 文件的详细信息，请参阅以下资源。\r  \r ### <a name=\"java-based-topology\"></a>基于 Java 的拓扑\r [使用 Storm on HDInsight 从 Azure 事件中心处理事件 (Java)](./apache-storm-develop-java-topology.md)\r  \r ### <a name=\"c-based-topology-mono-on-hdinsight-34-linux-storm-clusters\"></a>基于 C# 的拓扑（HDInsight 3.4+ Linux Storm 群集上的 Mono）\r [使用 Storm on HDInsight 从 Azure 事件中心处理事件 (C#)](./apache-storm-develop-csharp-event-hub-topology.md)\r  \r ### <a name=\"latest-storm-event-hub-spout-binaries-for-hdinsight-35-linux-storm-clusters\"></a>HDInsight 3.5+ Linux Storm 群集的最新 Storm 事件中心 Spout 二进制文件\r 若要了解如何使用适用于 HDInsight 3.5+ Linux Storm 群集的最新 Storm 事件中心 Spout，请参阅 mvn-repo [自述文件](https://github.com/hdinsight/mvn-repo/blob/master/README.md)。\r  \r ### <a name=\"source-code-examples\"></a>源代码示例\r 参阅有关如何在 Azure HDInsight 群集上使用 Apache Storm 拓扑（以 Java 编写）从 Azure 事件中心读取和写入数据的[示例](https://github.com/Azure-Samples/hdinsight-java-storm-eventhub)。\r  \r ## <a name=\"how-do-i-locate-storm-log4j-configuration-files-on-clusters\"></a>如何在群集上查找 Storm Log4J 配置文件？\r  \r 识别 Storm 服务的 Apache Log4J 配置文件。\r  \r ### <a name=\"on-head-nodes\"></a>在头节点上\r 从 /usr/hdp/\\<HDP version\\>/storm/log4j2/cluster.xml 读取 Nimbus Log4J 配置。\r  \r ### <a name=\"on-worker-nodes\"></a>在工作节点上\r 从 /usr/hdp/\\<HDP version\\>/storm/log4j2/cluster.xml 读取监督器 Log4J 配置。\r  \r 从 /usr/hdp/\\<HDP version\\>/storm/log4j2/worker.xml 读取工作节点 Log4J 配置文件。\r  \r 示例：/usr/hdp/2.6.0.2-76/storm/log4j2/cluster.xml /usr/hdp/2.6.0.2-76/storm/log4j2/worker.xml\r \r ### <a name=\"see-also\"></a>另请参阅\r [使用 Azure HDInsight 进行故障排除](../hdinsight-troubleshoot-guide.md)\r \r \r \r <!--Update_Description: update wording and link references-->"}