{"Title":"使用 PowerShell 和 Azure HDInsight 运行 Sqoop 作业","Description":"了解如何使用工作站中的 Azure PowerShell 在 Hadoop 群集与 Azure SQL 数据库之间运行 Sqoop 导入和导出。","Content":"# <a name=\"run-sqoop-jobs-by-using-azure-powershell-for-hadoop-in-hdinsight\"></a>使用 HDInsight 中的用于 Hadoop 的 Azure PowerShell 运行 Sqoop 作业\r [!INCLUDE [sqoop-selector](../../../includes/hdinsight-selector-use-sqoop.md)]\r \r [!INCLUDE [azure-sdk-developer-differences](../../../includes/azure-sdk-developer-differences.md)]\r \r 了解如何使用 Azure PowerShell 运行 Azure HDInsight 中的 Sqoop 作业，以便在 HDInsight 群集与 Azure SQL 数据库或 SQL Server 数据库之间进行导入和导出。\r \r > [!NOTE]\r > 尽管可以对基于 Windows 或 Linux 的 HDInsight 群集使用本文中的步骤，但是，只能从 Windows 客户端执行这些步骤。 若要选择其他方法，使用本文顶部的选项卡选择器。 \r > \r > \r \r ### <a name=\"prerequisites\"></a>先决条件\r 要阅读本教程，必须具备以下项：\r \r * 配备 Azure PowerShell 的工作站。\r * HDInsight 中的 Hadoop 群集。 有关详细信息，请参阅[创建群集和 SQL 数据库](hdinsight-use-sqoop.md#create-cluster-and-sql-database)。\r \r ## <a name=\"run-sqoop-by-using-powershell\"></a>使用 PowerShell 运行 Sqoop\r 下面的 PowerShell 脚本预处理源文件，然后将它导出到 Azure SQL 数据库：\r \r     $resourceGroupName = \"<AzureResourceGroupName>\"\r     $hdinsightClusterName = \"<HDInsightClusterName>\"\r \r     $httpUserName = \"admin\"\r     $httpPassword = \"<Password>\"\r \r     $defaultStorageAccountName = $hdinsightClusterName + \"store\"\r     $defaultBlobContainerName = $hdinsightClusterName\r \r     $sqlDatabaseServerName = $hdinsightClusterName + \"dbserver\"\r     $sqlDatabaseName = $hdinsightClusterName + \"db\"\r     $sqlDatabaseLogin = \"sqluser\"\r     $sqlDatabasePassword = \"<Password>\"\r \r     #region - Connect to Azure subscription\r     Write-Host \"`nConnecting to your Azure subscription ...\" -ForegroundColor Green\r     try{Get-AzureRmContext}\r     catch{Login-AzureRmAccount -EnvironmentName AzureChinaCloud}\r     #endregion\r \r     #region - pre-process the source file\r \r     Write-Host \"`nPreprocessing the source file ...\" -ForegroundColor Green\r \r     # This procedure creates a new file with $destBlobName\r     $sourceBlobName = \"example/data/sample.log\"\r     $destBlobName = \"tutorials/usesqoop/data/sample.log\"\r \r     # Define the connection string\r     $defaultStorageAccountKey = (Get-AzureRmStorageAccountKey `\r                                     -ResourceGroupName $resourceGroupName `\r                                     -Name $defaultStorageAccountName)[0].Value\r     $storageConnectionString = \"DefaultEndpointsProtocol=https;AccountName=$defaultStorageAccountName;AccountKey=$defaultStorageAccountKey\"\r \r     # Create block blob objects referencing the source and destination blob.\r     $storageAccount = Get-AzureRmStorageAccount -ResourceGroupName $ResourceGroupName -Name $defaultStorageAccountName\r     $storageContainer = ($storageAccount |Get-AzureStorageContainer -Name $defaultBlobContainerName).CloudBlobContainer\r     $sourceBlob = $storageContainer.GetBlockBlobReference($sourceBlobName)\r     $destBlob = $storageContainer.GetBlockBlobReference($destBlobName)\r \r     # Define a MemoryStream and a StreamReader for reading from the source file\r     $stream = New-Object System.IO.MemoryStream\r     $stream = $sourceBlob.OpenRead()\r     $sReader = New-Object System.IO.StreamReader($stream)\r \r     # Define a MemoryStream and a StreamWriter for writing into the destination file\r     $memStream = New-Object System.IO.MemoryStream\r     $writeStream = New-Object System.IO.StreamWriter $memStream\r \r     # Pre-process the source blob\r     $exString = \"java.lang.Exception:\"\r     while(-Not $sReader.EndOfStream){\r         $line = $sReader.ReadLine()\r         $split = $line.Split(\" \")\r \r         # remove the \"java.lang.Exception\" from the first element of the array\r         # for example: java.lang.Exception: 2012-02-03 19:11:02 SampleClass8 [WARN] problem finding id 153454612\r         if ($split[0] -eq $exString){\r             #create a new ArrayList to remove $split[0]\r             $newArray = [System.Collections.ArrayList] $split\r             $newArray.Remove($exString)\r \r             # update $split and $line\r             $split = $newArray\r             $line = $newArray -join(\" \")\r         }\r \r         # remove the lines that has less than 7 elements\r         if ($split.count -ge 7){\r             write-host $line\r             $writeStream.WriteLine($line)\r         }\r     }\r \r     # Write to the destination blob\r     $writeStream.Flush()\r     $memStream.Seek(0, \"Begin\")\r     $destBlob.UploadFromStream($memStream)\r \r     #endregion\r \r     #region - export the log file from the cluster to the SQL database\r \r     Write-Host \"Exporting the log file ...\" -ForegroundColor Green\r \r     $pw = ConvertTo-SecureString -String $httpPassword -AsPlainText -Force\r     $httpCredential = New-Object System.Management.Automation.PSCredential($httpUserName,$pw)\r \r     # Connection string for Azure SQL Database.\r     # Comment if using SQL Server\r     $connectionString = \"jdbc:sqlserver://$sqlDatabaseServerName.database.chinacloudapi.cn;user=$sqlDatabaseLogin@$sqlDatabaseServerName;password=$sqlDatabasePassword;database=$sqlDatabaseName\"\r     # Connection string for SQL Server.\r     # Uncomment if using SQL Server.\r     #$connectionString = \"jdbc:sqlserver://$sqlDatabaseServerName;user=$sqlDatabaseLogin;password=$sqlDatabasePassword;database=$sqlDatabaseName\"\r \r     $tableName_log4j = \"log4jlogs\"\r     $exportDir_log4j = \"/tutorials/usesqoop/data\"\r     $sqljdbcdriver = \"/user/oozie/share/lib/sqoop/sqljdbc41.jar\"\r \r     # Submit a Sqoop job\r     $sqoopDef = New-AzureRmHDInsightSqoopJobDefinition `\r         -Command \"export --connect $connectionString --table $tableName_log4j --export-dir $exportDir_log4j --input-fields-terminated-by \\0x20 -m 1\" `\r         -Files $sqljdbcdriver\r \r     $sqoopJob = Start-AzureRmHDInsightJob `\r                     -ClusterName $hdinsightClusterName `\r                     -HttpCredential $httpCredential `\r                     -JobDefinition $sqoopDef #-Debug -Verbose\r \r     Wait-AzureRmHDInsightJob `\r         -ResourceGroupName $resourceGroupName `\r         -ClusterName $hdinsightClusterName `\r         -HttpCredential $httpCredential `\r         -JobId $sqoopJob.JobId\r \r     Write-Host \"Standard Error\" -BackgroundColor Green\r     Get-AzureRmHDInsightJobOutput -ResourceGroupName $resourceGroupName -ClusterName $hdinsightClusterName -DefaultStorageAccountName $defaultStorageAccountName -DefaultStorageAccountKey $defaultStorageAccountKey -DefaultContainer $defaultBlobContainerName -HttpCredential $httpCredential -JobId $sqoopJob.JobId -DisplayOutputType StandardError\r     Write-Host \"Standard Output\" -BackgroundColor Green\r     Get-AzureRmHDInsightJobOutput -ResourceGroupName $resourceGroupName -ClusterName $hdinsightClusterName -DefaultStorageAccountName $defaultStorageAccountName -DefaultStorageAccountKey $defaultStorageAccountKey -DefaultContainer $defaultBlobContainerName -HttpCredential $httpCredential -JobId $sqoopJob.JobId -DisplayOutputType StandardOutput\r     #endregion\r \r ## <a name=\"limitations\"></a>限制\r 基于 Linux 的 HDInsight 存在以下限制：\r \r * 批量导出：用于将数据导出到 Microsoft SQL Server 或 Azure SQL 数据库的 Sqoop 连接器目前不支持批量插入。\r \r * 批处理：如果在执行插入时使用 `-batch` 开关，Sqoop 将执行多次插入而不是批处理插入操作。 \r \r ## <a name=\"next-steps\"></a>后续步骤\r 现在你已了解如何使用 Sqoop。 若要了解详细信息，请参阅以下文章：\r \r * [将 Oozie 与 HDInsight 配合使用](../hdinsight-use-oozie.md)：在 Oozie 工作流中使用 Sqoop 操作。\r * [使用 HDInsight 分析航班延误数据](../hdinsight-analyze-flight-delay-data.md)：使用 Hive 分析航班延误数据，然后使用 Sqoop 将数据导出到 Azure SQL 数据库。\r * [将数据上传到 HDInsight](../hdinsight-upload-data.md)：了解将数据上传到 HDInsight 或 Azure Blob 存储的其他方法。\r \r [sqoop-user-guide-1.4.4]: https://sqoop.apache.org/docs/1.4.4/SqoopUserGuide.html\r \r \r <!--Update_Description: update wording and link references-->"}