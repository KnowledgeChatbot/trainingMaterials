{"Title":"Java for Android 人脸 API 教程","Description":"创建一个使用认知服务人脸 API 来检测和定格图像中的人脸的简单 Android 应用。","Content":"# <a name=\"getting-started-with-face-api-in-java-for-android-tutorial\"></a>Java for Android 中的人脸 API 入门教程\r \r 本教程介绍如何创建和开发一个调用人脸 API 来检测图像中的人脸的简单 Android 应用程序。 该应用程序通过定格所检测到的人脸来显示结果。     \r \r ![GettingStartedAndroid](../Images/android_getstarted2.1.PNG)\r \r ## <a name=\"preparation\"></a>准备工作\r \r 若要使用本教程，需要满足以下先决条件：\r \r - 已安装 Android Studio 和 SDK\r - Android 设备（可选，用于测试） \r \r ## <a name=\"step1\"></a>步骤 1：订阅人脸 API 并获取订阅密钥\r \r 在使用任何人脸 API 之前，必须在 Azure 门户中注册以订阅人脸 API。 在本教程中，可以使用主密钥和辅助密钥。\r \r ## <a name=\"step2\"></a>步骤 2：创建应用程序框架\r \r 此步骤创建一个 Android 应用程序项目，用于实现基本 UI 来拾取和显示图像。 只需遵照以下说明操作： \r \r 1. 打开 Android Studio。\r 2. 在“文件”菜单中，单击“新建项目...”\r 3. 将应用程序命名为 MyFirstApp，单击“下一步”。 \r \r     ![GettingStartAndroidNewProject](../Images/AndroidNewProject.png)\r \r 4. 根据需要选择目标平台，单击“下一步”。 \r \r     ![GettingStartAndroidNewProject2](../Images/AndroidNewProject2.png)\r \r 5. 选择“基本活动”，单击“下一步”。\r 6. 如下所示为活动命名，并单击“完成”。 \r \r     ![GettingStartAndroidNewProject4](../Images/AndroidNewProject4.png)\r \r 7. 打开 activity_main.xml，应会看到此活动的布局编辑器。\r 8. 查看源文本文件，按如下所示编辑活动布局：           \r \r     ```xml\r     <RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\r         xmlns:tools=\"http://schemas.android.com/tools\" android:layout_width=\"match_parent\"\r         android:layout_height=\"match_parent\" android:paddingLeft=\"@dimen/activity_horizontal_margin\"\r         android:paddingRight=\"@dimen/activity_horizontal_margin\"\r         android:paddingTop=\"@dimen/activity_vertical_margin\"\r         android:paddingBottom=\"@dimen/activity_vertical_margin\" tools:context=\".MainActivity\">\r      \r         <ImageView\r             android:layout_width=\"match_parent\"\r             android:layout_height=\"fill_parent\"\r             android:id=\"@+id/imageView1\"\r             android:layout_above=\"@+id/button1\" />\r     \r         <Button\r             android:layout_width=\"match_parent\"\r             android:layout_height=\"wrap_content\"\r             android:text=\"Browse\"\r             android:id=\"@+id/button1\"\r             android:layout_alignParentBottom=\"true\" />\r     </RelativeLayout>\r     ```  \r \r 9. 打开 MainActivity.java，在文件的开头插入以下 import 指令：           \r \r         import java.io.*; \r         import android.app.*; \r         import android.content.*; \r         import android.net.*; \r         import android.os.*; \r         import android.view.*; \r         import android.graphics.*; \r         import android.widget.*; \r         import android.provider.*;\r       \r     接下来，修改“浏览”按钮逻辑的 MainActivity 类的 onCreate 方法：  \r \r         private final int PICK_IMAGE = 1;\r         private ProgressDialog detectionProgressDialog;\r          \r         @Override\r         protected void onCreate(Bundle savedInstanceState) {\r             super.onCreate(savedInstanceState);\r             setContentView(R.layout.activity_main);\r             Button button1 = (Button)findViewById(R.id.button1);\r             button1.setOnClickListener(new View.OnClickListener() {\r                 @Override\r                 public void onClick(View v) {\r                     Intent gallIntent = new Intent(Intent.ACTION_GET_CONTENT);\r                     gallIntent.setType(\"image/*\");\r                     startActivityForResult(Intent.createChooser(gallIntent, \"Select Picture\"), PICK_IMAGE);\r                 }\r         });\r          \r         detectionProgressDialog = new ProgressDialog(this);\r         }\r         @Override\r         protected void onActivityResult(int requestCode, int resultCode, Intent data) {\r             super.onActivityResult(requestCode, resultCode, data);\r             if (requestCode == PICK_IMAGE && resultCode == RESULT_OK && data != null && data.getData() != null) {\r                 Uri uri = data.getData();\r                 try {\r                     Bitmap bitmap = MediaStore.Images.Media.getBitmap(getContentResolver(), uri);\r                     ImageView imageView = (ImageView) findViewById(R.id.imageView1);\r                     imageView.setImageBitmap(bitmap);\r                 } catch (IOException e) {\r                     e.printStackTrace();\r                 }\r             }\r         }  \r \r 现在，该应用可以浏览并在窗口中显示库中的照片，如下图所示：\r \r ![GettingStartAndroidUI](../Images/android_getstarted1.1.PNG)\r \r ## <a name=\"step3\"></a>步骤 3：配置人脸 API 客户端库\r \r 人脸 API 是可以使用 HTTPS 请求调用的云 API。 为了方便在 .NET 平台应用程序中使用人脸 API，我们还提供了一个客户端库用于封装 Web 请求。 此示例使用客户端库来简化操作。 \r \r 遵照以下说明配置客户端库： \r \r 1. 如示例中所示，从“项目”面板中找到项目的顶层 build.gradle 文件。 请注意，项目树中还有其他几个 build.gradle 文件，首先需要打开顶层的 build.gradle 文件。         \r 2. 将 mavenCentral() 添加到项目的存储库。 也可以使用 Android Studio 的默认存储库 jcenter()，因为 jcenter() 是 mavenCentral() 的超集。  \r \r         allprojects {\r             repositories {\r                 ...\r                 mavenCentral()\r             }\r         }\r \r 3. 打开“app”项目中的 build.gradle 文件。\r 4. 为 Maven 中心存储库中存储的客户端库添加一个依赖项：\r \r         dependencies {  \r             ...  \r             compile 'com.microsoft.projectoxford:face:1.0.0'  \r         }  \r \r 5. 打开“app”项目中的 MainActivity.java，并插入以下 import 指令： \r     \r         import com.microsoft.projectoxford.face.\\*;  \r         import com.microsoft.projectoxford.face.contract.\\*;  \r     \r    然后，在 MainActivity 类中插入以下代码：\r \r         private FaceServiceClient faceServiceClient =  \r                     new FaceServiceRestClient(\"your subscription key\");  \r \r    将上面的字符串替换为在步骤 1 中获取的订阅密钥。  \r 6. 打开“app”项目中名为 AndroidManifest.xml 的文件（在 app/src/main 目录中）。 在清单元素中插入以下元素：  \r \r         <uses-permission android:name=\"android.permission.INTERNET\" />  \r \r 7. 现在，可以从应用程序调用人脸 API。 \r \r ## <a name=\"step4\"></a>步骤 4：上传图像以检测人脸\r \r 检测人脸的最简便方法是上传图像文件后直接调用[人脸 - 检测](https://dev.cognitive.azure.cn/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236) API。 使用客户端库时，可以使用 FaceServiceClient 的异步方法 DetectAsync 实现此目的。 每个返回的人脸包含一个指示人脸位置的矩形，以及一系列可选人脸属性。 在本示例中，我们只需检索人脸位置。 此处，需在 MainActivity 类中插入一个方法才能检测人脸： \r \r     // Detect faces by uploading face images\r     // Frame faces after detection\r     \r     private void detectAndFrame(final Bitmap imageBitmap)\r     {\r         ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\r         imageBitmap.compress(Bitmap.CompressFormat.JPEG, 100, outputStream);\r         ByteArrayInputStream inputStream = \r             new ByteArrayInputStream(outputStream.toByteArray());\r         AsyncTask<InputStream, String, Face[]> detectTask =\r             new AsyncTask<InputStream, String, Face[]>() {\r                 @Override\r                 protected Face[] doInBackground(InputStream... params) {\r                     try {\r                         publishProgress(\"Detecting...\");\r                         Face[] result = faceServiceClient.detect(\r                                 params[0], \r                                 true,         // returnFaceId\r                                 false,        // returnFaceLandmarks\r                                 null           // returnFaceAttributes: a string like \"age, gender\"\r                         );\r                         if (result == null)\r                         {\r                             publishProgress(\"Detection Finished. Nothing detected\");\r                             return null;\r                         }\r                         publishProgress(\r                                 String.format(\"Detection Finished. %d face(s) detected\",\r                                         result.length));\r                         return result;\r                     } catch (Exception e) {\r                         publishProgress(\"Detection failed\");\r                         return null;\r                     }\r                 }\r                 @Override\r                 protected void onPreExecute() {\r                     //TODO: show progress dialog\r                 }\r                 @Override\r                 protected void onProgressUpdate(String... progress) {\r                     //TODO: update progress\r                 }\r                 @Override\r                 protected void onPostExecute(Face[] result) {\r                     //TODO: update face frames\r                 }\r             };\r         detectTask.execute(inputStream);\r     }\r \r ## <a name=\"step5\"></a>步骤 5：标记图像中的人脸\r \r 最后一个步骤是将上述所有步骤组合在一起，并在图像中使用框架来标记检测到的人脸。 首先，打开 MainActivity.java，在 MainActivity.java 中插入一个帮助器方法用于绘制矩形： \r \r     private static Bitmap drawFaceRectanglesOnBitmap(Bitmap originalBitmap, Face[] faces) {\r         Bitmap bitmap = originalBitmap.copy(Bitmap.Config.ARGB_8888, true);\r         Canvas canvas = new Canvas(bitmap);\r         Paint paint = new Paint();\r         paint.setAntiAlias(true);\r         paint.setStyle(Paint.Style.STROKE);\r         paint.setColor(Color.RED);\r         int stokeWidth = 2;\r         paint.setStrokeWidth(stokeWidth);\r         if (faces != null) {\r             for (Face face : faces) {\r                 FaceRectangle faceRectangle = face.faceRectangle;\r                 canvas.drawRect(\r                         faceRectangle.left,\r                         faceRectangle.top,\r                         faceRectangle.left + faceRectangle.width,\r                         faceRectangle.top + faceRectangle.height,\r                         paint);\r             }\r         }\r         return bitmap;\r     }\r \r 接下来，完成 detectAndFrame 方法中的 TODO 部分，以定格人脸并报告状态。   \r \r     @Override\r     protected void onPreExecute() {\r         \r         detectionProgressDialog.show();\r     }\r     @Override\r     protected void onProgressUpdate(String... progress) {\r         \r         detectionProgressDialog.setMessage(progress[0]);\r     }\r     @Override\r     protected void onPostExecute(Face[] result) {\r         \r         detectionProgressDialog.dismiss();\r         if (result == null) return;\r         ImageView imageView = (ImageView)findViewById(R.id.imageView1);\r         imageView.setImageBitmap(drawFaceRectanglesOnBitmap(imageBitmap, result));\r         imageBitmap.recycle();\r     }\r  \r 最后，如下所示，从 onActivityResult 方法添加对 detectAndFrame 方法的调用。 （请注意，星号只是为了突出显示新添加的内容。 在尝试生成代码之前，必须删除星号。）  \r \r     @Override\r     protected void onActivityResult(int requestCode, int resultCode, Intent data) {\r         super.onActivityResult(requestCode, resultCode, data);\r         if (requestCode == PICK_IMAGE && resultCode == RESULT_OK && data != null && data.getData() != null) {\r             Uri uri = data.getData();\r             try {\r                 Bitmap bitmap = MediaStore.Images.Media.getBitmap(getContentResolver(), uri);\r                 ImageView imageView = (ImageView) findViewById(R.id.imageView1);\r                 imageView.setImageBitmap(bitmap);\r      \r                 **detectAndFrame(bitmap);**\r      \r             } catch (IOException e) {\r                 e.printStackTrace();\r             }\r         }\r     }\r \r 运行此应用程序并浏览包含人脸的图像。 请等待几秒钟，让云 API 做出响应。 之后，会收到下图所示的结果： \r \r ![GettingStartAndroid](../Images/android_getstarted2.1.PNG)\r \r ## <a name=\"summary\"></a>摘要\r \r 本教程已介绍人脸 API 的基本使用过程，并创建了一个应用程序来显示图像中的人脸标记。 有关人脸 API 的详细信息，请参阅操作说明和 [API 参考](https://dev.cognitive.azure.cn/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236)。 \r \r ## <a name=\"related\"></a>相关教程\r \r - [CSharp 中的人脸 API 入门教程](FaceAPIinCSharpTutorial.md)\r - [Python 中的人脸 API 入门教程](FaceAPIinPythonTutorial.md)\r \r "}