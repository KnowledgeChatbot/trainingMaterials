{"Title":"使用 Azure HDInsight 中的 Apache Hive 分析和处理 JSON 文档","Description":"了解如何使用 JSON 文档，以及如何使用 Azure HDInsight 中的 Apache Hive 来分析这些文档","Content":"# <a name=\"process-and-analyze-json-documents-by-using-apache-hive-in-azure-hdinsight\"></a>使用 Azure HDInsight 中的 Apache Hive 分析和处理 JSON 文档\r \r 了解如何使用 Azure HDInsight 中的 Apache Hive 处理和分析 JavaScript 对象表示法 (JSON) 文件。 本教程使用以下 JSON 文档：\r \r     {\r         \"StudentId\": \"trgfg-5454-fdfdg-4346\",\r         \"Grade\": 7,\r         \"StudentDetails\": [\r             {\r                 \"FirstName\": \"Peggy\",\r                 \"LastName\": \"Williams\",\r                 \"YearJoined\": 2012\r             }\r         ],\r         \"StudentClassCollection\": [\r             {\r                 \"ClassId\": \"89084343\",\r                 \"ClassParticipation\": \"Satisfied\",\r                 \"ClassParticipationRank\": \"High\",\r                 \"Score\": 93,\r                 \"PerformedActivity\": false\r             },\r             {\r                 \"ClassId\": \"78547522\",\r                 \"ClassParticipation\": \"NotSatisfied\",\r                 \"ClassParticipationRank\": \"None\",\r                 \"Score\": 74,\r                 \"PerformedActivity\": false\r             },\r             {\r                 \"ClassId\": \"78675563\",\r                 \"ClassParticipation\": \"Satisfied\",\r                 \"ClassParticipationRank\": \"Low\",\r                 \"Score\": 83,\r                 \"PerformedActivity\": true\r             }\r         ]\r     }\r \r 可以在 wasb://processjson@hditutorialdata.blob.core.chinacloudapi.cn/上找到该文件。 有关如何将 Azure Blob 存储与 HDInsight 配合使用的详细信息，请参阅[将 HDFS 兼容的 Azure Blob 存储与 HDInsight 中的 Hadoop 配合使用](../hdinsight-hadoop-use-blob-storage.md)。 可以将该文件复制到群集的默认容器。\r \r 在本教程中，将使用 Hive 控制台。 有关如何打开 Hive 控制台的说明，请参阅[通过远程桌面将 Hive 与 Hadoop on HDInsight 配合使用](apache-hadoop-use-hive-remote-desktop.md)。\r \r ## <a name=\"flatten-json-documents\"></a>平展 JSON 文档\r 下一部分中所列的方法需要 JSON 文档在单一行中。 因此，必须将 JSON 文档平展成字符串。 如果 JSON 文档已平展，则可以跳过此步骤，直接转到有关分析 JSON 数据的下一部分。 若要平展 JSON 文档，请运行以下脚本：\r \r     DROP TABLE IF EXISTS StudentsRaw;\r     CREATE EXTERNAL TABLE StudentsRaw (textcol string) STORED AS TEXTFILE LOCATION \"wasb://processjson@hditutorialdata.blob.core.chinacloudapi.cn/\";\r \r     DROP TABLE IF EXISTS StudentsOneLine;\r     CREATE EXTERNAL TABLE StudentsOneLine\r     (\r       json_body string\r     )\r     STORED AS TEXTFILE LOCATION '/json/students';\r \r     INSERT OVERWRITE TABLE StudentsOneLine\r     SELECT CONCAT_WS(' ',COLLECT_LIST(textcol)) AS singlelineJSON\r           FROM (SELECT INPUT__FILE__NAME,BLOCK__OFFSET__INSIDE__FILE, textcol FROM StudentsRaw DISTRIBUTE BY INPUT__FILE__NAME SORT BY BLOCK__OFFSET__INSIDE__FILE) x\r           GROUP BY INPUT__FILE__NAME;\r \r     SELECT * FROM StudentsOneLine\r \r 原始 JSON 文件位于 **wasb://processjson@hditutorialdata.blob.core.chinacloudapi.cn/**。 *StudentsRaw* Hive 表指向未平展的原始 JSON 文档。\r \r **StudentsOneLine** Hive 表将数据存储在 HDInsight 默认文件系统中的 **/json/students/** 路径下。\r \r **INSERT** 语句使用平展的 JSON 数据填充 **StudentOneLine** 表。\r \r **SELECT** 语句只返回 1 行。\r \r 下面是 **SELECT** 语句的输出：\r \r ![平展 JSON 文档][image-hdi-hivejson-flatten]\r \r ## <a name=\"analyze-json-documents-in-hive\"></a>在 Hive 中分析 JSON 文档\r Hive 提供了三种不同的机制用于对 JSON 文档运行查询，你也可以编写自己的代码：\r \r * 使用 get_json_object 用户定义的函数 (UDF)。\r * 使用 json_tuple UDF。\r * 使用自定义序列化程序/反序列化程序 (SerDe)。\r * 使用 Python 或其他语言编写自己的 UDF。 有关如何使用 Hive 运行自己的 Python 代码的详细信息，请参阅[使用 Apache Hive 和 Pig 运行 Python UDF][hdinsight-python]。\r \r ### <a name=\"use-the-getjsonobject-udf\"></a>使用 get_json_object UDF\r Hive 提供名为 [get_json_object](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object) 的内置 UDF，它可以在运行时执行 JSON 查询。 此方法采用两个参数 - 表名称和方法名称，具有平展的 JSON 文档和需要进行分析的 JSON 字段。 让我们探讨一个示例，了解此 UDF 的工作原理。\r \r 以下查询返回每个学生的名字和姓氏：\r \r     SELECT\r       GET_JSON_OBJECT(StudentsOneLine.json_body,'$.StudentDetails.FirstName'),\r       GET_JSON_OBJECT(StudentsOneLine.json_body,'$.StudentDetails.LastName')\r     FROM StudentsOneLine;\r \r 这是在控制台窗口中运行此查询时的输出：\r \r ![get_json_object UDF][image-hdi-hivejson-getjsonobject]\r \r get_json_object UDF 有限制：\r \r * 由于查询中的每个字段都需要重新分析查询，因此会影响性能。\r * **GET\\_JSON_OBJECT()** 返回数组的字符串表示形式。 要将此数组转换为 Hive 数组，必须使用正则表达式来替换方括号“[”和“]”，然后调用拆分来获取数组。\r \r 正因如此，Hive wiki 建议使用 json_tuple。  \r \r ### <a name=\"use-the-jsontuple-udf\"></a>使用 json_tuple UDF\r Hive 提供的另一个 UDF 称为 [json_tuple](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-json_tuple)，其性能比 [get_ json _object](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object) 要高。 此方法采用一组键和一个 JSON 字符串，并使用一个函数返回值的元组。 以下查询将从 JSON 文档返回学生 ID 和年级：\r \r     SELECT q1.StudentId, q1.Grade\r       FROM StudentsOneLine jt\r       LATERAL VIEW JSON_TUPLE(jt.json_body, 'StudentId', 'Grade') q1\r         AS StudentId, Grade;\r \r 此脚本在 Hive 控制台中的输出：\r \r ![json_tuple UDF][image-hdi-hivejson-jsontuple]\r \r json_tuple UDF 在 Hive 中使用了[横向视图](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)语法，使 json\\_tuple 能够通过将 UDT 函数应用于原始表的每一行来创建虚拟表。 由于重复使用**横向视图**，复杂的 JSON 会变得过于庞大。 此外，**JSON_TUPLE** 无法处理嵌套的 JSONs。\r \r ### <a name=\"use-a-custom-serde\"></a>使用自定义 SerDe\r SerDe 是用于分析嵌套 JSON 文档的最佳选择。 使用它可以定义 JSON 架构，然后使用该架构来分析文档。 有关说明，请参阅[如何将自定义 JSON SerDe 与 Microsoft Azure HDInsight 配合使用](https://blogs.msdn.microsoft.com/bigdatasupport/2014/06/18/how-to-use-a-custom-json-serde-with-microsoft-azure-hdinsight/)。\r \r ## <a name=\"summary\"></a>摘要\r 总之，在 Hive 中选择 JSON 运算符类型取决于方案。 如果有一个简单的 JSON 文档，并只有一个要查找的字段，可以选择使用 Hive UDF get_json_object。 如果有多个键用于查找，则可以使用 json_tuple。 如果拥有嵌套文档，应该使用 JSON SerDe。\r \r ## <a name=\"next-steps\"></a>后续步骤\r \r 相关文章请参阅：\r \r * [将 Hive 和 HiveQL 与 HDInsight 中的 Hadoop 配合使用以分析示例 Apache log4j 文件](../hdinsight-use-hive.md)\r * [使用 HDInsight 中的 Hive 分析航班延误数据](../hdinsight-analyze-flight-delay-data.md)\r * [使用 Azure Cosmos DB 和 HDInsight 运行 Hadoop 作业](../../cosmos-db/run-hadoop-with-hdinsight.md)\r \r [hdinsight-python]:python-udf-hdinsight.md\r \r [image-hdi-hivejson-flatten]: ./media/using-json-in-hive/flatten.png\r [image-hdi-hivejson-getjsonobject]: ./media/using-json-in-hive/getjsonobject.png\r [image-hdi-hivejson-jsontuple]: ./media/using-json-in-hive/jsontuple.png\r [image-hdi-hivejson-jdk]: ./media/hdinsight-using-json-in-hive/jdk.png\r [image-hdi-hivejson-maven]: ./media/hdinsight-using-json-in-hive/maven.png\r [image-hdi-hivejson-serde]: ./media/hdinsight-using-json-in-hive/serde.png\r [image-hdi-hivejson-addjar]: ./media/hdinsight-using-json-in-hive/addjar.png\r [image-hdi-hivejson-serde_query1]: ./media/hdinsight-using-json-in-hive/serde_query1.png\r [image-hdi-hivejson-serde_query2]: ./media/hdinsight-using-json-in-hive/serde_query2.png\r [image-hdi-hivejson-serde_query3]: ./media/hdinsight-using-json-in-hive/serde_query3.png\r [image-hdi-hivejson-serde_result]: ./media/hdinsight-using-json-in-hive/serde_result.png\r \r <!--Update_Description: update wording and link references-->"}