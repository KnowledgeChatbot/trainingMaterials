{"Title":"在 Azure HDInsight 中将 Apache Spark 结构化流与事件中心配合使用","Description":"构建一个 Apache Spark 流式处理示例，用于演示如何向 Azure 事件中心发送数据流，然后使用 scala 应用程序在 HDInsight Spark 群集中接收这些事件。","Content":"# <a name=\"apache-spark-structured-streaming-on-hdinsight-to-process-events-from-event-hubs\"></a>使用 HDInsight 中的 Apache Spark 结构化流处理事件中心的事件\r \r 本文介绍如何使用 Spark 结构化流处理实时遥测数据。 为此，请执行以下概要步骤：\r \r 1. 编译并在本地工作站上运行一个示例事件生成者应用程序，用于生成要发送到事件中心的事件。\r 2. 使用 [Spark Shell](apache-spark-shell.md) 定义并运行一个简单的 Spark 结构化流应用程序。\r \r ## <a name=\"prerequisites\"></a>先决条件\r \r * Azure 订阅。 请参阅[获取 Azure 试用版](https://www.azure.cn/pricing/1rmb-trial/)。\r \r * HDInsight 上的 Apache Spark 群集。 有关说明，请参阅[在 Azure HDInsight 中创建 Apache Spark 群集](apache-spark-jupyter-spark-sql.md)。\r \r * Azure 事件中心命名空间。 有关详细信息，请参阅[创建 Azure 事件中心命名空间](apache-spark-eventhub-streaming.md#create-an-azure-event-hub)。\r \r * Oracle Java 开发工具包。 可以从 [此处](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)安装它。\r \r * Apache Maven。 可以从[此处](https://maven.apache.org/download.cgi)下载它。 [此处](https://maven.apache.org/install.html)提供了有关安装 Maven 的说明。\r \r ## <a name=\"build-configure-and-run-the-event-producer\"></a>生成、配置和运行事件生成者\r 此任务克隆一个可创建随机事件并将其发送到配置的事件中心的示例应用程序。 GitHub 中提供了此示例应用程序，网址为：[https://github.com/hdinsight/eventhubs-sample-event-producer](https://github.com/hdinsight/eventhubs-sample-event-producer)。\r \r 1. 确保已安装 git 工具。 可以从 [GIT 下载](http://www.git-scm.com/downloads)页下载。 \r 2. 打开命令提示符或终端 shell，从所选的目录运行以下命令以克隆项目。\r         \r         git clone https://github.com/hdinsight/eventhubs-sample-event-producer.git eventhubs-client-sample\r \r 3. 这会创建名为 eventhubs-client-sample 的新文件夹。 在 shell 或命令提示符中，导航到此文件夹。\r 4. 运行 Maven，使用以下命令生成该应用程序：\r \r           mvn package\r \r 5. 在 shell 或命令提示符中，导航到所创建的、包含文件 ``com-microsoft-azure-eventhubs-client-example-0.2.0.jar`` 的目标目录。\r 6. 接下来，需要生成命令行来针对事件中心运行事件生成者。 为此，请按如下所示替换命令中的值：\r \r         java -cp com-microsoft-azure-eventhubs-client-example-0.2.0.jar com.microsoft.azure.eventhubs.client.example.EventhubsClientDriver --eventhubs-namespace \"<namespace>\" --eventhubs-name \"hub1\" --policy-name \"RootManageSharedAccessKey\" --policy-key \"<policyKey>\" --message-length 32 --thread-count 1 --message-count -1\r \r 7. 例如，完整的命令如下所示：\r \r         java -cp com-microsoft-azure-eventhubs-client-example-0.2.0.jar com.microsoft.azure.eventhubs.client.example.EventhubsClientDriver --eventhubs-namespace \"sparkstreaming\" --eventhubs-name \"hub1\" --policy-name \"RootManageSharedAccessKey\" --policy-key \"2P1Q17Wd1rdLP1OZQYn6dD2S13Bb3nF3h2XZD9hvyyU=\" --message-length 32 --thread-count 1 --message-count -1\r \r 8. 该命令将会启动，如果配置正确，则在几分钟后，可以看到该命令发送到事件中心的事件相关输出，如下所示：\r \r         Map('policyKey -> 2P1Q17Wd1rdLP1OZQYn6dD2S13Bb3nF3h2XZD9hvyyU, 'eventhubsName -> hub1, 'policyName -> RootManageSharedAccessKey, 'eventhubsNamespace -> sparkstreaming, 'messageCount -> -1, 'messageLength -> 32, 'threadCount -> 1)\r         Events per thread: -1 (-1 for unlimited)\r         10 > Sun Jun 18 11:32:58 PDT 2017 > 1024 > 1024 > Sending event: ZZ93958saG5BUKbvUI9wHVmpuA2TrebS\r         10 > Sun Jun 18 11:33:46 PDT 2017 > 2048 > 2048 > Sending event: RQorGRbTPp6U2wYzRSnZUlWEltRvTZ7R\r         10 > Sun Jun 18 11:34:33 PDT 2017 > 3072 > 3072 > Sending event: 36Eoy2r8ptqibdlfCYSGgXe6ct4AyOX3\r         10 > Sun Jun 18 11:35:19 PDT 2017 > 4096 > 4096 > Sending event: bPZma9V0CqOn6Hj9bhrrJT0bX2rbPSn3\r         10 > Sun Jun 18 11:36:06 PDT 2017 > 5120 > 5120 > Sending event: H2TVD77HNTVyGsVcj76g0daVnYxN4Sqs\r \r 9. 让事件生成者保持运行，同时继续执行后续步骤。\r \r ## <a name=\"run-spark-shell-on-your-hdinsight-cluster\"></a>在 HDInsight 群集上运行 Spark Shell\r 在此任务中，需通过 SSH 连接到 HDInsight 群集的头节点，启动 Spark Shell，并运行一个可检索和处理事件中心的事件的 Spark 流应用程序。 \r \r 此时，HDInsight 群集应已准备就绪。 如果未就绪，则需要等到其完成预配。 就绪后，请继续执行以下步骤：\r \r 1. 使用 SSH 连接到 HDInsight 群集。 有关说明，请参阅[使用 SSH 连接到 HDInsight](../hdinsight-hadoop-linux-use-ssh-unix.md)。\r \r 5. 生成的应用程序需要 Spark 流事件中心包。 若要运行 Spark Shell 以便自动从 [Maven 中心](https://search.maven.org)检索此依赖项，请务必按如下所示提供 packages 开关和 Maven 坐标：\r \r         spark-shell --packages \"com.microsoft.azure:spark-streaming-eventhubs_2.11:2.1.0\"\r \r 6. Spark Shell 完成加载后，应会看到：\r \r         Welcome to\r             ____              __\r             / __/__  ___ _____/ /__\r             _\\ \\/ _ \\/ _ `/ __/  '_/\r         /___/ .__/\\_,_/_/ /_/\\_\\   version 2.1.0.2.6.0.10-29\r             /_/\r                 \r         Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_131)\r         Type in expressions to have them evaluated.\r         Type :help for more information.\r \r         scala> \r \r 7. 将以下代码片段复制到文本编辑器并对其进行修改，以便适当地为事件中心设置策略密钥和命名空间。\r \r         val eventhubParameters = Map[String, String] (\r             \"eventhubs.policyname\" -> \"RootManageSharedAccessKey\",\r             \"eventhubs.policykey\" -> \"<policyKey>\",\r             \"eventhubs.namespace\" -> \"<namespace>\",\r             \"eventhubs.name\" -> \"hub1\",\r             \"eventhubs.partition.count\" -> \"2\",\r             \"eventhubs.consumergroup\" -> \"$Default\",\r             \"eventhubs.progressTrackingDir\" -> \"/eventhubs/progress\",\r             \"eventhubs.sql.containsProperties\" -> \"true\"\r             )\r \r 8. 将修改后的代码片段粘贴到等待中的 scala> 提示符，然后按回车键。 应看到如下输出：\r \r         scala> val eventhubParameters = Map[String, String] (\r             |       \"eventhubs.policyname\" -> \"RootManageSharedAccessKey\",\r             |       \"eventhubs.policykey\" -> \"2P1Q17Wd1rdLP1OZQYn6dD2S13Bb3nF3h2XZD9hvyyU\",\r             |       \"eventhubs.namespace\" -> \"sparkstreaming\",\r             |       \"eventhubs.name\" -> \"hub1\",\r             |       \"eventhubs.partition.count\" -> \"2\",\r             |       \"eventhubs.consumergroup\" -> \"$Default\",\r             |       \"eventhubs.progressTrackingDir\" -> \"/eventhubs/progress\",\r             |       \"eventhubs.sql.containsProperties\" -> \"true\"\r             |     )\r         eventhubParameters: scala.collection.immutable.Map[String,String] = Map(eventhubs.sql.containsProperties -> true, eventhubs.name -> hub1, eventhubs.consumergroup -> $Default, eventhubs.partition.count -> 2, eventhubs.progressTrackingDir -> /eventhubs/progress, eventhubs.policykey -> 2P1Q17Wd1rdLP1OZQYn6dD2S13Bb3nF3h2XZD9hvyyU, eventhubs.namespace -> hdiz-docs-eventhubs, eventhubs.policyname -> RootManageSharedAccessKey)\r \r 9. 接下来，通过指定源来创作 Spark 结构化流查询。 将以下内容粘贴到 Spark Shell，然后按回车键。\r \r         val inputStream = spark.readStream.\r         format(\"eventhubs\").\r         options(eventhubParameters).\r         load()\r \r 10. 应看到如下输出：\r \r         inputStream: org.apache.spark.sql.DataFrame = [body: binary, offset: bigint ... 5 more fields]\r \r 11. 接下来创作查询，以便将其输出写入控制台。 为此，请将以下内容粘贴到 Spark Shell 并按回车键。\r \r         val streamingQuery1 = inputStream.writeStream.\r         outputMode(\"append\").\r         format(\"console\").start().awaitTermination()\r \r 12. 此时，应会看到一些以如下所示输出开头的批\r \r         -------------------------------------------\r         Batch: 0\r         -------------------------------------------\r         [Stage 0:>                                                          (0 + 2) / 2]\r \r 13. 此内容后接处理每个事件微批后生成的输出结果。 \r \r         -------------------------------------------\r         Batch: 0\r         -------------------------------------------\r         17/06/18 18:57:39 WARN TaskSetManager: Stage 1 contains a task of very large size (419 KB). The maximum recommended task size is 100 KB.\r         +--------------------+------+---------+------------+---------+------------+----------+\r         |                body|offset|seqNumber|enqueuedTime|publisher|partitionKey|properties|\r         +--------------------+------+---------+------------+---------+------------+----------+\r         |[7B 22 74 65 6D 7...|     0|        0|  1497734887|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|   112|        1|  1497734887|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|   224|        2|  1497734887|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|   336|        3|  1497734887|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|   448|        4|  1497734887|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|   560|        5|  1497734887|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|   672|        6|  1497734887|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|   784|        7|  1497734888|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|   896|        8|  1497734888|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|  1008|        9|  1497734888|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|  1120|       10|  1497734888|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|  1232|       11|  1497734888|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|  1344|       12|  1497734888|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|  1456|       13|  1497734888|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|  1568|       14|  1497734888|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|  1680|       15|  1497734888|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|  1792|       16|  1497734888|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|  1904|       17|  1497734888|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|  2016|       18|  1497734889|     null|        null|     Map()|\r         |[7B 22 74 65 6D 7...|  2128|       19|  1497734889|     null|        null|     Map()|\r         +--------------------+------+---------+------------+---------+------------+----------+\r         only showing top 20 rows\r \r 14. 当事件生成者发送的新事件抵达时，此结构化流查询会处理这些事件。\r 15. 完成运行此示例后，请务必删除 HDInsight 群集。\r \r \r \r ## <a name=\"see-also\"></a>另请参阅\r \r * [Spark 流概述](apache-spark-streaming-overview.md)\r \r \r \r \r \r \r \r \r \r \r \r \r \r "}