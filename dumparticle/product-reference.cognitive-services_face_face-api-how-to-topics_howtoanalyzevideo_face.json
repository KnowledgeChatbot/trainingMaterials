{"Title":"使用人脸 API 执行实时视频分析","Description":"使用认知服务中的人脸 API 针对从实时视频流中提取的帧执行接近实时的分析。","Content":"# <a name=\"how-to-analyze-videos-in-real-time\"></a>如何实时分析视频\r 本指南将演示如何针对从实时视频流中提取的帧执行接近实时的分析。 此类系统中的基本组件包括：\r - 从视频源中获取帧\r - 选择要分析的帧\r - 将这些帧提交到 API\r - 使用 API 调用返回的每个分析结果\r \r 这些示例是使用 C# 编写的，可在以下 GitHub 网页上找到代码：[https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis](https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis/)。\r \r ## <a name=\"the-approach\"></a>方法\r 有多种方法可以解决针对视频流运行接近实时分析的问题。 首先，我们从易到难概述三种方法。\r \r ### <a name=\"a-simple-approach\"></a>简单方法\r 接近实时分析系统的最简单设计是无限循环，我们通过其中的每次迭代抓取帧，然后使用结果：\r ```CSharp\r while (true)\r {\r     Frame f = GrabFrame();\r     if (ShouldAnalyze(f))\r     {\r         AnalysisResult r = await Analyze(f);\r         ConsumeResult(r);\r     }\r }\r ```\r 如果分析包括轻量客户端算法，则适合使用此方法。 但是，如果分析是在云中发生的，则出现的延迟会导致 API 调用可能需要花费几秒钟，在此期间，我们无法捕获图像，并且线程基本上不会执行任何操作。 最大帧速率受到 API 调用延迟的限制。\r \r ### <a name=\"parallelizing-api-calls\"></a>并行化 API 调用\r 尽管简单的单线程循环适合轻量客户端算法，但却无法很好地适应云 API 调用存在的延迟。 此问题的解决方法是让长时间运行的 API 调用与抓帧操作并行执行。 在 C# 中，可以使用基于任务的并行度来实现此目的，例如：\r ```CSharp\r while (true)\r {\r     Frame f = GrabFrame();\r     if (ShouldAnalyze(f))\r     {\r         var t = Task.Run(async () => \r         {\r             AnalysisResult r = await Analyze(f);\r             ConsumeResult(r);\r         }\r     }\r }\r ```\r 这会在单独的任务中启动每项分析，而该任务可在后台运行，同时我们可以继续抓取新帧。 这可以避免在阻塞主线程的同时等待 API 调用返回，但是，我们会失去简单版本所提供的某些保证 - 多个 API 调用可能会并行发生，结果可能按错误的顺序返回。 这还可能导致多个线程同时进入 ConsumeResult() 函数，如果该函数不是线程安全的，则可能会造成危险。 最后，此简单代码不会跟踪所创建的任务，异常会以无提示方式消失。 因此，我们要添加的最终成分是“使用者”线程，它会跟踪分析任务，引发异常，终止长时间运行的任务，并确保按正确的顺序逐个使用结果。\r \r ### <a name=\"a-producer-consumer-design\"></a>生成者-使用者设计\r 在最终的“生成者-使用者”系统中，有一个生成者线程非常类似于前面所述的无限循环。 但是，生成者不会在分析结果可用后立即使用这些结果，而仅仅是将任务放入队列，以对其进行跟踪。\r ```CSharp\r // Queue that will contain the API call tasks. \r var taskQueue = new BlockingCollection<Task<ResultWrapper>>();\r      \r // Producer thread. \r while (true)\r {\r     // Grab a frame. \r     Frame f = GrabFrame();\r  \r     // Decide whether to analyze the frame. \r     if (ShouldAnalyze(f))\r     {\r         // Start a task that will run in parallel with this thread. \r         var analysisTask = Task.Run(async () => \r         {\r             // Put the frame, and the result/exception into a wrapper object.\r             var output = new ResultWrapper(f);\r             try\r             {\r                 output.Analysis = await Analyze(f);\r             }\r             catch (Exception e)\r             {\r                 output.Exception = e;\r             }\r             return output;\r         }\r         \r         // Push the task onto the queue. \r         taskQueue.Add(analysisTask);\r     }\r }\r ```\r 此外还有一个使用者线程，它会将任务取出队列，等待任务完成，然后显示结果或者激发已引发的异常。 使用队列可以保证按正确的顺序逐个使用结果，而不会限制系统的最大帧速率。\r ```CSharp\r // Consumer thread. \r while (true)\r {\r     // Get the oldest task. \r     Task<ResultWrapper> analysisTask = taskQueue.Take();\r  \r     // Await until the task is completed. \r     var output = await analysisTask;\r      \r     // Consume the exception or result. \r     if (output.Exception != null)\r     {\r         throw output.Exception;\r     }\r     else\r     {\r         ConsumeResult(output.Analysis);\r     }\r }\r ```\r \r ## <a name=\"implementing-the-solution\"></a>实现解决方案\r ### <a name=\"getting-started\"></a>入门\r 为了尽快启动并运行应用，我们已实现上述系统，目的是让它足够灵活地实现多种方案并保持易用性。 若要访问代码，请转到 [https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis](https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis)。\r \r 库中包含 FrameGrabber 类，该类实现上述生成者-使用者系统来处理网络摄像头中的视频帧。 用户可以指定确切的 API 调用格式，该类使用事件来告知调用代码何时获取了新帧，或者有新的分析结果可用。\r \r 为了演示某些可行方案，我们提供了两个使用该库的示例应用。 第一个应用是简单的控制台应用，下面再现了此应用的简化版本。 此应用从默认网络摄像头抓帧，并将其提交给人脸 API 进行人脸检测。\r ```CSharp\r using System;\r using VideoFrameAnalyzer;\r using Microsoft.ProjectOxford.Face;\r using Microsoft.ProjectOxford.Face.Contract;\r      \r namespace VideoFrameConsoleApplication\r {\r     class Program\r     {\r         static void Main(string[] args)\r         {\r             // Create grabber, with analysis type Face[]. \r             FrameGrabber<Face[]> grabber = new FrameGrabber<Face[]>();\r             \r             // Create Face API Client. Insert your Face API key here.\r             FaceServiceClient faceClient = new FaceServiceClient(\"<subscription key>\");\r \r             // Set up our Face API call.\r             grabber.AnalysisFunction = async frame => return await faceClient.DetectAsync(frame.Image.ToMemoryStream(\".jpg\"));\r \r             // Set up a listener for when we receive a new result from an API call. \r             grabber.NewResultAvailable += (s, e) =>\r             {\r                 if (e.Analysis != null)\r                     Console.WriteLine(\"New result received for frame acquired at {0}. {1} faces detected\", e.Frame.Metadata.Timestamp, e.Analysis.Length);\r             };\r             \r             // Tell grabber to call the Face API every 3 seconds.\r             grabber.TriggerAnalysisOnInterval(TimeSpan.FromMilliseconds(3000));\r \r             // Start running.\r             grabber.StartProcessingCameraAsync().Wait();\r \r             // Wait for keypress to stop\r             Console.WriteLine(\"Press any key to stop...\");\r             Console.ReadKey();\r             \r             // Stop, blocking until done.\r             grabber.StopProcessingAsync().Wait();\r         }\r     }\r }\r ```\r 第二个示例应用更有趣，允许选择要对视频帧调用哪个 API。 此应用在左侧显示实时视频的预览，在右侧显示叠加在相应帧上的最新 API 结果。\r \r 在大多数模式下，左侧的实时视频与右侧的可视化分析之间存在明显的延迟。 这种延迟是发出 API 调用所花费的时间。 “EmotionsWithClientFaceDetect”模式则例外，它在将任何图像提交到认知服务之前，会使用 OpenCV 在客户端计算机本地执行人脸检测。 通过执行此操作，我们可以立即将检测到的人脸可视化，然后在 API 调用返回后更新情感。 此示例演示了“混合”方法的可行性，其中的一些简单处理可在客户端上执行，然后，可以使用认知服务 API 并根据需要配合更高级的分析来增强这种处理。\r \r ![HowToAnalyzeVideo](../../Video/Images/FramebyFrame.jpg)\r \r ### <a name=\"integrating-into-your-codebase\"></a>集成到代码库中\r 若要开始使用此示例，请遵循以下步骤：\r \r 1. 从 [Azure 门户](https://portal.azure.cn)获取视觉 API 的 API 密钥。 对于视频帧分析，适用的 API 包括：\r     - [计算机视觉 API](/cognitive-services/computer-vision/home)\r     - [情感 API](/cognitive-services/emotion/home)\r     - [Face API]/cognitive-services/face/overview)\r 2. 克隆 [Cognitive-Samples-VideoFrameAnalysis](https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis/) GitHub 存储库\r \r 3. 在 Visual Studio 2015 中打开示例，生成并运行示例应用程序：\r     - 对于 BasicConsoleSample，人脸 API 密钥已在 [BasicConsoleSample/Program.cs](https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis/blob/master/Windows/BasicConsoleSample/Program.cs) 中直接进行硬编码。\r     - 对于 LiveCameraSample，应在应用的“设置”窗格中输入密钥。 在切换不同的会话后，这些密钥将持久保存为用户数据。\r         \r \r 如果已做好集成的准备，**只需从自己的项目引用 VideoFrameAnalyzer 库。** \r \r \r \r ## <a name=\"developer-code-of-conduct\"></a>开发人员行为准则\r 与使用所有认知服务时一样，使用我们的 API 和示例进行开发的开发人员必须遵守 [Microsoft 认知服务开发人员行为准则](https://azure.microsoft.com/en-us/support/legal/developer-code-of-conduct/)。 \r \r \r VideoFrameAnalyzer 的图像、语音、视频或文本识别功能使用 Microsoft 认知服务。 Microsoft 将会接收通过此应用上传的图像、音频、视频和其他数据，并可能会使用这些内容来改进服务。 对于应用会将其数据发送到 Microsoft 认知服务的人员，我们请求你帮助保护他们的隐私。 \r \r \r ## <a name=\"summary\"></a>摘要\r 本指南介绍了如何使用人脸 API、 计算机视觉 API 和情感 API 针对实时视频流运行接近实时的分析，以及如何使用示例代码来入门。  \r \r 欢迎在 [GitHub 存储库](https://github.com/Microsoft/Cognitive-Samples-VideoFrameAnalysis/)中提供反馈和建议，或者在 [UserVoice 站点](https://cognitive.uservoice.com/)上提供更广泛的 API 反馈。\r \r \r \r ## <a name=\"related\"></a>相关主题\r - [如何识别图像中的人脸](HowtoIdentifyFacesinImage.md)\r - [如何检测图像中的人脸](HowtoDetectFacesinImage.md)\r \r "}