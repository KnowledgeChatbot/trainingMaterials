{"Title":"解决 Azure HDInsight 中的 Hive 内存不足错误","Description":"解决 HDInsight 中的 Hive 内存不足错误。 客户方案为跨多个大型表运行查询。","Content":"# <a name=\"fix-a-hive-out-of-memory-error-in-azure-hdinsight\"></a>解决 Azure HDInsight 中的 Hive 内存不足错误\r \r 了解处理大型表时如何通过配置 Hive 内存设置解决 Hive 内存不足错误。\r \r ## <a name=\"run-hive-query-against-large-tables\"></a>针对大型表运行 Hive 查询\r \r 客户运行了 Hive 查询：\r \r     SELECT\r         COUNT (T1.COLUMN1) as DisplayColumn1,\r         …\r         …\r         ….\r     FROM\r         TABLE1 T1,\r         TABLE2 T2,\r         TABLE3 T3,\r         TABLE5 T4,\r         TABLE6 T5,\r         TABLE7 T6\r     where (T1.KEY1 = T2.KEY1….\r         …\r         …\r \r 此查询有一些繁琐之处：\r \r * T1 是大型表 TABLE1 的别名，其中包含多个 STRING 列类型。\r * 其他表没有那么大，但包含许多列。\r * 所有表都彼此联接，在某些情况下，TABLE1 和其他表中的多个列也相互联接。\r \r Hive 查询在 24 节点 A3 HDInsight 群集上用了 26 分钟才完成。 客户注意到以下警告消息：\r \r     Warning: Map Join MAPJOIN[428][bigTable=?] in task 'Stage-21:MAPRED' is a cross product\r     Warning: Shuffle Join JOIN[8][tables = [t1933775, t1932766]] in Stage 'Stage-4:MAPRED' is a cross product\r \r 通过使用 Tez 执行引擎， 相同的查询运行了 15 分钟，然后引发以下错误：\r \r     Status: Failed\r     Vertex failed, vertexName=Map 5, vertexId=vertex_1443634917922_0008_1_05, diagnostics=[Task failed, taskId=task_1443634917922_0008_1_05_000006, diagnostics=[TaskAttempt 0 failed, info=[Error: Failure while running task:java.lang.RuntimeException: java.lang.OutOfMemoryError: Java heap space\r         at\r     org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:172)\r         at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:138)\r         at\r     org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:324)\r         at\r     org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:176)\r         at\r     org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable$1.run(TezTaskRunner.java:168)\r         at java.security.AccessController.doPrivileged(Native Method)\r         at javax.security.auth.Subject.doAs(Subject.java:415)\r         at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)\r         at\r     org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.call(TezTaskRunner.java:168)\r         at\r     org.apache.tez.runtime.task.TezTaskRunner$TaskRunnerCallable.call(TezTaskRunner.java:163)\r         at java.util.concurrent.FutureTask.run(FutureTask.java:262)\r         at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\r         at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\r         at java.lang.Thread.run(Thread.java:745)\r     Caused by: java.lang.OutOfMemoryError: Java heap space\r \r 使用更大的虚拟机（例如，D12）时，也出现了该错误。\r \r ## <a name=\"debug-the-out-of-memory-error\"></a>调试内存不足错误\r \r 我们的支持团队和工程团队合作发现了造成内存不足错误的原因之一是 [Apache JIRA 中所述的已知问题](https://issues.apache.org/jira/browse/HIVE-8306)：\r \r     When hive.auto.convert.join.noconditionaltask = true we check noconditionaltask.size and if the sum  of tables sizes in the map join is less than noconditionaltask.size the plan would generate a Map join, the issue with this is that the calculation doesnt take into account the overhead introduced by different HashTable implementation as results if the sum of input sizes is smaller than the noconditionaltask size by a small margin queries will hit OOM.\r \r hive-site.xml 文件中的 **hive.auto.convert.join.noconditionaltask** 已设置为 **true**：\r \r     <property>\r         <name>hive.auto.convert.join.noconditionaltask</name>\r         <value>true</value>\r         <description>\r               Whether Hive enables the optimization about converting common join into mapjoin based on the input file size.\r               If this parameter is on, and the sum of size for n-1 of the tables/partitions for a n-way join is smaller than the\r               specified size, the join is directly converted to a mapjoin (there is no conditional task).\r         </description>\r       </property>\r \r 映射联接很可能是 Java 堆空间内存不足错误的原因。 如博客文章 [HDInsight 中的 Hadoop Yarn 内存设置](http://blogs.msdn.com/b/shanyu/archive/2014/07/31/hadoop-yarn-memory-settings-in-hdinsigh.aspx)所述，使用 Tez 执行引擎时，所用的堆空间事实上属于 Tez 容器。 请参阅下图，其中描述了 Tez 容器内存。\r \r ![Tez 容器内存示意图：Hive 内存不足错误](./media/hdinsight-hadoop-hive-out-of-memory-error-oom/hive-out-of-memory-error-oom-tez-container-memory.png)\r \r 如该博客文章中所述，以下两项内存设置定义了堆的容器内存：**hive.tez.container.size** 和 **hive.tez.java.opts**。 从我们的经验来看，内存不足异常并不意味着容器太小， 而是表示 Java 堆大小 (hive.tez.java.opts) 太小。 因此，每当看到内存不足时，可尝试增大 **hive.tez.java.opts**。 必要时，可能需要增大 **hive.tez.container.size**。 **java.opts** 设置应该大约为 **container.size** 的 80%。\r \r > [!NOTE]\r > **hive.tez.java.opts** 设置必须始终小于 **hive.tez.container.size**。\r > \r > \r \r 由于 D12 计算机具有 28GB 内存，因此我们决定使用 10GB (10240MB) 的容器大小并将 80% 分配给 java.opts：\r \r     SET hive.tez.container.size=10240\r     SET hive.tez.java.opts=-Xmx8192m\r \r 使用新设置，查询可在 10 分钟内成功运行。\r \r ## <a name=\"next-steps\"></a>后续步骤\r \r 遇到 OOM 错误不一定表示容器太小。 相反地，应该配置内存设置，以便将堆大小增加为至少是容器内存大小的 80%。 有关优化 Hive 查询，请参阅[在 HDInsight 中优化 Hadoop 的 Hive 查询](hdinsight-hadoop-optimize-hive-query.md)。\r \r <!--Update_Description: update wording and link references-->"}