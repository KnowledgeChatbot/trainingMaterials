{"Title":"在 HDInsight 中的 Hadoop 上将 C# 与 Hive 和 Pig 配合使用 - Azure","Description":"了解在 Azure HDInsight 中如何将 C# 用户定义的函数 (UDF) 与 Hive 和 Pig 流式处理配合使用。","Content":"# <a name=\"use-c-user-defined-functions-with-hive-and-pig-streaming-on-hadoop-in-hdinsight\"></a>在 HDInsight 中的 Hadoop 上将 C# 用户定义函数与 Hive 和 Pig 流式处理配合使用\r \r [!INCLUDE [azure-sdk-developer-differences](../../../includes/azure-sdk-developer-differences.md)]\r \r 了解如何在 HDInsight 中将 C# 用户定义函数 (UDF) 与 Apache Hive 和 Pig 配合使用。\r \r > [!IMPORTANT]\r > 本文档中的各个步骤适用于基于 Linux 和基于 Windows 的 HDInsight 群集。 Linux 是 HDInsight 3.4 或更高版本上使用的唯一操作系统。 有关详细信息，请参阅 [HDInsight 组件版本控制](../hdinsight-component-versioning.md)。\r \r Hive 和 Pig 都可以将数据传递到外部应用程序以进行处理。 此过程称为_流式处理_。 使用 .NET 应用程序时，数据将传递到 STDIN 上的应用程序，该应用程序也会在 STDOUT 上返回结果。 若要从 STDIN 和 STDOUT 读取和写入数据，可以使用控制台应用程序中的 `Console.ReadLine()` 和 `Console.WriteLine()`。\r \r ## <a name=\"prerequisites\"></a>先决条件\r \r * 熟悉编写和生成面向 .NET Framework 4.5 的 C# 代码。\r \r     * 使用任何需要的 IDE。 我们建议使用 [Visual Studio](https://www.visualstudio.com/vs) 2015、2017 或 [Visual Studio Code](https://code.visualstudio.com/)。 本文档中的各个步骤都使用 Visual Studio 2017。\r \r * 将 .exe 文件上传到群集以及运行 Pig 和 Hive 作业的方法。 建议使用针对 Visual Studio 的 Data Lake 工具、Azure PowerShell 和 Azure CLI。 本文档中的各个步骤都使用针对 Visual Studio 的 Data Lake 工具上传文件和运行 Hive 查询示例。\r \r     有关运行 Hive 查询和 Pig 作业的其他方法的信息，请参阅以下文档：\r \r     * [将 Apache Hive 和 HDInsight 配合使用](hdinsight-use-hive.md)\r \r     * [将 Apache Pig 和 HDInsight 配合使用](hdinsight-use-pig.md)\r \r * HDInsight 群集上的 Hadoop。 有关创建群集的详细信息，请参阅[创建 HDInsight 群集](../hdinsight-hadoop-provision-linux-clusters.md)。\r \r [!INCLUDE [azure-visual-studio-login-guide](../../../includes/azure-visual-studio-login-guide.md)]\r \r ## <a name=\"net-on-hdinsight\"></a>HDInsight 上的 .NET\r \r * __基于 Linux 的 HDInsight__ 群集使用 [Mono (https://mono-project.com)](https://mono-project.com) 运行 .NET 应用程序。 Mono 版本 4.2.1 包含在 HDInsight 版本 3.5 中。\r \r     有关 Mono 与 .NET Framework 版本的兼容性的详细信息，请参阅 [Mono 兼容性](http://www.mono-project.com/docs/about-mono/compatibility/)。\r \r     若要使用 Mono 的特定版本，请参阅[安装或更新 Mono](../hdinsight-hadoop-install-mono.md) 文档。\r \r * __基于 Windows 的 HDInsight__ 群集使用 Microsoft .NET CLR 运行 .NET 应用程序。\r \r 有关包含在 HDInsight 版本中的 .NET framework 和 Mono 版本的详细信息，请参阅 [HDInsight 组件版本](../hdinsight-component-versioning.md)。\r \r ## <a name=\"create-the-c-projects\"></a>创建 C\\# 项目\r \r ### <a name=\"hive-udf\"></a>Hive UDF\r \r 1. 打开 Visual Studio 并创建一个解决方案。 对于项目类型，选择“控制台应用(.NET Framework)”，并将新项目命名为“HiveCSharp”。\r \r     > [!IMPORTANT]\r     > 如果使用的是基于 Linux 的 HDInsight 群集，请选择“.NET Framework 4.5”。 有关 Mono 与 .NET Framework 版本的兼容性的详细信息，请参阅 [Mono 兼容性](http://www.mono-project.com/docs/about-mono/compatibility/)。\r \r 2. 将 Program.cs 的内容替换为以下代码：\r \r     ```csharp\r     using System;\r     using System.Security.Cryptography;\r     using System.Text;\r     using System.Threading.Tasks;\r \r     namespace HiveCSharp\r     {\r         class Program\r         {\r             static void Main(string[] args)\r             {\r                 string line;\r                 // Read stdin in a loop\r                 while ((line = Console.ReadLine()) != null)\r                 {\r                     // Parse the string, trimming line feeds\r                     // and splitting fields at tabs\r                     line = line.TrimEnd('\\n');\r                     string[] field = line.Split('\\t');\r                     string phoneLabel = field[1] + ' ' + field[2];\r                     // Emit new data to stdout, delimited by tabs\r                     Console.WriteLine(\"{0}\\t{1}\\t{2}\", field[0], phoneLabel, GetMD5Hash(phoneLabel));\r                 }\r             }\r             /// <summary>\r             /// Returns an MD5 hash for the given string\r             /// </summary>\r             /// <param name=\"input\">string value</param>\r             /// <returns>an MD5 hash</returns>\r             static string GetMD5Hash(string input)\r             {\r                 // Step 1, calculate MD5 hash from input\r                 MD5 md5 = System.Security.Cryptography.MD5.Create();\r                 byte[] inputBytes = System.Text.Encoding.ASCII.GetBytes(input);\r                 byte[] hash = md5.ComputeHash(inputBytes);\r \r                 // Step 2, convert byte array to hex string\r                 StringBuilder sb = new StringBuilder();\r                 for (int i = 0; i < hash.Length; i++)\r                 {\r                     sb.Append(hash[i].ToString(\"x2\"));\r                 }\r                 return sb.ToString();\r             }\r         }\r     }\r     ```\r \r 3. 生成项目。\r \r ### <a name=\"pig-udf\"></a>Pig UDF\r \r 1. 打开 Visual Studio 并创建一个解决方案。 对于项目类型，选择“控制台应用程序”，并将新项目命名为“PigUDF”。\r \r 2. 将 **Program.cs** 文件的内容替换为以下代码：\r \r     ```csharp\r     using System;\r \r     namespace PigUDF\r     {\r         class Program\r         {\r             static void Main(string[] args)\r             {\r                 string line;\r                 // Read stdin in a loop\r                 while ((line = Console.ReadLine()) != null)\r                 {\r                     // Fix formatting on lines that begin with an exception\r                     if(line.StartsWith(\"java.lang.Exception\"))\r                     {\r                         // Trim the error info off the beginning and add a note to the end of the line\r                         line = line.Remove(0, 21) + \" - java.lang.Exception\";\r                     }\r                     // Split the fields apart at tab characters\r                     string[] field = line.Split('\\t');\r                     // Put fields back together for writing\r                     Console.WriteLine(String.Join(\"\\t\",field));\r                 }\r             }\r         }\r     }\r     ```\r \r     此代码分析发送自 Pig 的行，并对以 `java.lang.Exception` 开头的行重新设置格式。\r \r 3. 保存 **Program.cs**，并生成项目。\r \r ## <a name=\"upload-to-storage\"></a>上传到存储\r \r 1. 在 Visual Studio 中，打开“服务器资源管理器”。\r \r 2. 依次展开“Azure”和“HDInsight”。\r \r 3. 如果出现提示，请输入 Azure 订阅凭据，并单击“登录”。\r \r 4. 展开要将此应用程序部署到的 HDInsight 群集。 列出带有文本“（默认存储帐户）”的条目。\r \r     ![显示群集存储帐户的服务器资源管理器](./media/apache-hadoop-hive-pig-udf-dotnet-csharp/storage.png)\r \r     * 如果此条目可以展开，则在使用 __Azure 存储帐户__作为该群集的默认存储。 如果要查看该群集的默认存储上的文件，请展开该条目，并双击“（默认容器）”。\r \r 6. 若要上传 .exe 文件，请使用以下方法之一：\r \r     * 如果使用的是 __Azure 存储帐户__，请单击“上传”图标，并浏览到“HiveCSharp”项目的“bin\\debug”文件夹。 最后，选择 **HiveCSharp.exe** 文件并单击“确定”。\r \r         ![上传图标](./media/apache-hadoop-hive-pig-udf-dotnet-csharp/upload.png)\r \r     上传“HiveCSharp.exe”完成后，请为“PigUDF.exe”文件重复该上传过程。\r \r ## <a name=\"run-a-hive-query\"></a>运行 Hive 查询\r \r 1. 在 Visual Studio 中，打开“服务器资源管理器”。\r \r 2. 依次展开“Azure”和“HDInsight”。\r \r 3. 右键单击已将 **HiveCSharp** 应用程序部署到的群集，并选择“编写 Hive 查询”。\r \r 4. 请使用以下文本执行 Hive 查询：\r \r     ```hiveql\r     -- Uncomment the following if you are using Azure Storage\r     -- add file wasb:///HiveCSharp.exe;\r \r     SELECT TRANSFORM (clientid, devicemake, devicemodel)\r     USING 'HiveCSharp.exe' AS\r     (clientid string, phoneLabel string, phoneHash string)\r     FROM hivesampletable\r     ORDER BY clientid LIMIT 50;\r     ```\r \r     > [!IMPORTANT]\r     > 取消注释与用于群集的默认存储类型相匹配的 `add file` 语句。\r \r     此查询将从 `hivesampletable` 中选择 `clientid`、`devicemake` 和 `devicemodel` 字段并将这些字段传递到 HiveCSharp.exe 应用程序。 该查询预期应用程序返回三个字段，它们存储为 `clientid`、`phoneLabel` 和 `phoneHash`。 该查询还预期在默认存储容器的根目录中找到 HiveCSharp.exe。\r \r 5. 单击“提交”将作业提交到 HDInsight 群集。 此时会打开“Hive 作业摘要”窗口  。\r \r 6. 单击“刷新”以刷新摘要，直到“作业状态”更改为“已完成”。 若要查看作业输出，请单击“作业输出”。\r \r ## <a name=\"run-a-pig-job\"></a>运行 Pig 作业\r \r 1. 使用以下方法之一连接到 HDInsight 群集：\r \r     * 如果使用的是__基于 Linux__ 的 HDInsight 群集，请使用 SSH。 例如，`ssh sshuser@mycluster-ssh.azurehdinsight.cn`。 有关详细信息，请参阅[将 SSH 与 HDInsight 配合使用](../hdinsight-hadoop-linux-use-ssh-unix.md)\r \r     * 如果使用的是__基于 Windows__ 的 HDInsight 群集，请[使用远程桌面连接到群集](../hdinsight-administer-use-management-portal.md#connect-to-clusters-using-rdp)\r \r 2. 使用以下命令之一启动 Pig 命令行：\r \r         pig\r \r     > [!IMPORTANT]\r     > 如果使用的是基于 Windows 的群集，请改用以下命令：\r     > ```\r     > cd %PIG_HOME%\r     > bin\\pig\r     > ```\r \r     此时显示 `grunt>` 提示。\r \r 3. 输入以下命令以运行使用 .NET Framework 应用程序的 Pig 作业：\r \r         DEFINE streamer `PigUDF.exe` CACHE('/PigUDF.exe');\r         LOGS = LOAD '/example/data/sample.log' as (LINE:chararray);\r         LOG = FILTER LOGS by LINE is not null;\r         DETAILS = STREAM LOG through streamer as (col1, col2, col3, col4, col5);\r         DUMP DETAILS;\r \r     `DEFINE` 语句为 pigudf.exe 应用程序创建别名 `streamer`，`CACHE` 将从群集的默认存储中加载它。 以后，可以将 `streamer` 与 `STREAM` 运算符配合使用来处理 LOG 中包含的单一行，并将数据返回为一系列的列。\r \r     > [!NOTE]\r     > 用于流式处理的应用程序名称在使用别名时必须用 \\`（反斜杠引号）字符括起来，当与 `SHIP` 一起使用时必须用 ' （单引号）括起来。\r \r 4. 在输入最后一行后，该作业应该启动。 它返回类似于以下文本的输出：\r \r         (2012-02-03 20:11:56 SampleClass5 [WARN] problem finding id 1358451042 - java.lang.Exception)\r         (2012-02-03 20:11:56 SampleClass5 [DEBUG] detail for id 1976092771)\r         (2012-02-03 20:11:56 SampleClass5 [TRACE] verbose detail for id 1317358561)\r         (2012-02-03 20:11:56 SampleClass5 [TRACE] verbose detail for id 1737534798)\r         (2012-02-03 20:11:56 SampleClass7 [DEBUG] detail for id 1475865947)\r \r ## <a name=\"next-steps\"></a>后续步骤\r \r 在本文档中，已了解了如何在 HDInsight 上通过 Hive 和 Pig 使用 .NET Framework 应用程序。 如果希望了解如何将 Python 与 Hive 和 Pig 配合使用，请参阅[在 HDInsight 中将 Python 与 Hive 和 Pig 配合使用](python-udf-hdinsight.md)。\r \r 若要了解使用 Pig 和 Hive 的其他方式以及如何使用 MapReduce，请参阅以下文档：\r \r * [将 Hive 与 HDInsight 配合使用](hdinsight-use-hive.md)\r * [将 Pig 与 HDInsight 配合使用](hdinsight-use-pig.md)\r * [将 MapReduce 与 HDInsight 配合使用](hdinsight-use-mapreduce.md)\r \r \r <!--Update_Description: update wording and link references-->"}